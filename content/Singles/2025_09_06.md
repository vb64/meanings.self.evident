# Алиса

06 сентября 2025 г. [Аудиоверсия]()

**Е.Голуб:**
Здравствуйте, друзья!
В эфире необычный выпуск ведущих подкаста «В поисках смысла».
Евгения Голуба, Павла Щелина и сегодня с нами приглашённый эксперт Алиса Ким.
Мы решили записать этот выпуск, так как первый раз мы затронули тему искусственного интеллекта, а сегодня речь пойдёт о нём, примерно год назад, может быть, немного больше.
И с тех пор многое изменилось.
Я бы так сказал, что изменилось практически всё.
И для того, чтобы осмыслить происходящее, Нам уже не хватает собственного понимания.
Мы подозреваем себя в предвзятости.
И для этого мы пригласили Алису, кандидата наук, эксперта по искусственному интеллекту.
Алиса занималась академическими исследованиями в Гумбольд-Университете, точнее, в Университете Гумбольда и в Стэнфордском университете.
Алиса разрабатывала языковые модели в AWS, Amazon.
И, в общем, последние 10 лет Алиса занимается внедрением искусственного интеллекта в разного рода системах, в стартапах и крупных корпорациях.
Поэтому никому, как ни к Алисе, нам прийти с нашими вопросами и недоумениями.
Ну что ж, начнем потихонечку.
Итак, я предложил сегодня разделить роли в нашем встрече следующим образом.
Как уже понятно, Алиса — наш эксперт, Павел — философ.
А я буду выступать сегодня в роли обычного пользователя разного рода и помощников, обычного обывателя, которых много и у которых есть простые незамысловатые вопросы.
И начну я с такого простого вопроса к Алисе.
Сегодня уже очень многие, включая меня, не мыслят в своей жизни без помощников, как мы их называем.
У меня при запуске браузера запускается 6 штук сразу.
И многие сейчас уже, собственно, ищут даже продукты через искусственный интеллект, через разного рода помощников.
Так вот вопрос следующего рода.
Всё-таки это полезная штука или за этим кроется что-то ещё?
Как Вы считаете, насколько нагружены сегодняшние помощники скрытыми какими-то функциями, скрытыми намерениями их создателей?
Есть ли подвох в этой технологии?

**А.Ким:**
Наверное, начну с занудного «полезно для кого и для чего».
Для нас, как для пользователей, в наших жизненных целях, безусловно, на мой взгляд, полезная вещь.
Но мы с вами находимся в такой сложной ситуации, когда абсолютно всё в этом продукте По сути, оптимизированы для того, чтобы мы чуть-чуть сбились с курса, забыли о том, зачем мы делаем то, что мы делаем, и как это работает.
Если бы я должна была ответить на вопрос классический, Хорошая вещь или плохая, я бы сказала.
Хорошая, если мы будем пользоваться ей осознанно.
И на этой части обычно все юзеры, я в том числе, говорят, если осознанно, то это уже слишком сложно.
Что касается нагруженности, тут, на мой взгляд, всё банально и немножко грустно.
Практически всё о том, как создаются эти помощники, зачем, с какими ограничениями.
Всё прописано, всё открыто.
Я думаю, что там… Скрытых смыслов и скрытых идей и тайных помыслов довольно мало.
Другое дело, что мы как… Вы знаете, как никто не считает правила пользования, все всегда всё принимают и радостно этим дальше пользуются.
Другое дело, что мы с вами, наверное, никогда ещё не сталкивались с инструментом, по сути, телевизорами, чайниками, любыми инструментами, доступными для рядового пользователя, которые были бы настолько сложны и настолько обманчивы, настолько сделаны для того, чтобы максимально с нашей головушкой помериться силами, запутать и вести в искусство.
Изначально же все эти системы, когда они стали популярны, никогда не стали точными, никогда не стали какими-то правильными с точки зрения даваемых ответов.
А тогда, когда они стали настолько похожи на настоящего собеседника, что мы прямо вот… Мы так-то любим всё антропоморфизировать, да?
С компьютерами разговариваем, с телевизорами даём имена машинам и так далее.
А тут оно ещё и разговаривает, и отвечает, ещё и учится тому, что мы любим и не любим, и запоминает нас.
Ну, то есть тут не… Ну, начать с этим взаимодействовать нас и помощникам не как это же как-то… инструментом практически нереально.
Даже если вы супер-подсознанки, скорее всего, через N и N пользований вы уже немножко забудете про то, зачем это было сделано, как это работает и так далее.
На мой взгляд, пользы от этого можно извлечь очень много.
Другое дело, что с такими инструментами прямо вот совсем-совсем нельзя забывать, зачем я это делаю и какие у этого ограничения.
Они все прописаны, они все понятны.
Но кроме тех, которые не прописаны, по идее, должны быть понятны любому человеку, Это коммерческий инструмент.
Наверное, там есть какая-то доля того, что на вас хотят заработать, и ваше всеобщее благо мира, наверное, там не единственная цель.
То есть, скорее всего, этот компонент тоже есть, но мы про это не очень любим помнить.
А это влияет на то, как дальше развиваются эти системы.
Вот такой мой будет ответ.
То есть.

**Е.Голуб:**
Штука, как любая технология, всегда имеет Скажу иначе.
Искусственный интеллект, как любой инструмент, может быть использован по прямому назначению и во благо.
Или как кухонный нож можно резать мясо, можно зарезать человека.
Как технология книгопечатания можно печатать Библию, а можно порно-рисуночки издавать.
И здесь уже вопрос у меня к Павлу.
Мы говорили с тобой год, наверное, и много больше назад о том, что движется, кажется, такое время, надвигаются времена, когда многое из того, что делает человека человеком, будет, скорее всего, передано на аутсорс, искусственному интеллекту.
И мы тогда с тобой видели риски того, что вот это творческое начало, чувства, эмоции начнут автоматизироваться, и, соответственно, в этой части есть риски для людей потерять свой компонент человечности, что ли.
Что ты думаешь по этому поводу?

**П.Щелин:**
Ещё раз всем здравствуйте.
Ну, думаю много чего.
Тут даже не знаешь с какого конца подбираться.
Первое, всё-таки сделаю базовые комментарии для фиксации собственной позиции по твоему преамбуле.
Про вот кухонный нож и прочую всю вот эту историю.
Дело в том, что вот с этой позиции я философски не согласен.
Мне представляется, что само представление существования такого феномена, как нейтральная технология, является глубоким заблуждением.
Не существует такого феномена, как нейтральность технологий.
С самим фактом своего существования технология не нейтральна.
Она создает ассиметрию.
Банально между теми, кто технологией пользоваться умеет и кто технологией пользоваться не умеют.
Те, кто технологией пользоваться умеют, получают дополнительные ресурсы, власть, способ взаимодействия с миром относительно тех, кто ей не пользуется.
Эту асимметрию ты никаким образом...
Вот это и есть собственно сама технологическая асимметрия.
То, что ты говоришь уже про волевой, этический выбор субъекта, использующий технологию, это следующий этап, это следующий уровень.
Но сначала есть вот этот базовый уровень, что самим фактом своего бытия технология мир меняет.
И вот наше представление о ней как о некой нейтральности — это очень хороший sales point для любого, скажем так, маркетолога, но с философской точки зрения просто он неадекватный.

**Е.Голуб:**
Ты знаешь, мне кажется, нужно объяснить, что такое твой тезис о том, что самим фактом существования технология меняет мир.
Логическая связь здесь не очевидна, по крайней мере, для меня.

**П.Щелин:**
Ну, давай самое простое.
Вот если пока этой технологии не было, у тебя была определенная культура и определенные, если не условно, паттерны, уж простите, не знаю, как там вечно...
Независимость как-то.
Закономерности некоторые.
Закономерности отношений между людьми, отношений экономические, социальные, политические и так далее, как ты ни крути.
Вот когда технология появилась, она стала фактором всех этих отношений просто по факту своего появления.
Еще никакой воли нет, но она создала дополнительные возможности.
Повторюсь, главная эта возможность, я ее назвал, это возможность к власти.
Любая технология содержит в себе заряд к власти.
Ну, это логично.
Если бы она его не содержала, ее бы никто не создал.
Это вот очень важно понимать.
То, что в нашем культуре технология всегда создается, на самом деле, с неким зарядом к власти.
Тот, кто...
Банально, власть работы в нашем конкретном примере, власть манипулирования, власть работы с данными, власть производства дополнительного материального ресурса и так далее.
Это все властные отношения.
И вот эта технология, ты можешь сказать, если тебе уточнить, ну, до поры до времени, можно сказать, что она создается с технологией, как минимум, потенциальной власти.
То есть, она лежит и спит, да, требуется волевой субъект, чтобы эту власть активизировать, но, тем не менее, потенциал-то уже создан самим фактом ее появления.
То есть, некий статус-кво оказалось нарушенным.
Всё.
То есть изобретение автомобиля, вне зависимости от намерений конкретного изводчика, конкретного водителя или производства автомобиля, самим фактом своей технологии является угрозой, условно говоря, для коневодов.
Она меняет эти отношения автоматически, просто по факту своего появления.

**Е.Голуб:**
Технология может существовать, продукта может не быть.
Ведь сам факт возможности что-то сделать...
Я.

**П.Щелин:**
Поэтому так и говорю про потенциальное.
Давай так, ты прав.
Как минимум потенциальное.
С философской точки зрения я веду категорию потенциальное изменение.
Но просто мы живем еще в цивилизации последние 400 лет, где любое потенциальное изменение в зоне технологии и прогресса должно быть актуализировано.
У нас нет никаких этических ограничений на любую технологическую актуализацию.
Это собственно ради этого модерн мы и создавали.

**Е.Голуб:**
Мы говорим о том, что в модерне...
Каждая технология, прежде всего, рассматривается с точки зрения возможности увеличить властный потенциал субъекта, обладающего этой технологией.

**П.Щелин:**
Субъекта, обладающего этой технологией, да.
А в любой технологии всегда, и до модерна, и после модерна, и вне модерна, ну, всегда содержится увеличение потенциала субъекта.
Ну, это понятно.

**Е.Голуб:**
Усиление, да?
То есть мы говорим, что...
Усиление.

**П.Щелин:**
Ну, я не могу бегать, как гепард.
Но с машиной я могу перемещаться со скоростью, которой гепарду и не снилось.
Мой потенциал в категории беганье, она усиливает.
Она поэтому и создана.

**Е.Голуб:**
Теперь, я тебя прервал, может быть, ты сделаешь шаг назад и вернешься к своему второму тезису?

**П.Щелин:**
Да.
Приведу пример не с искусственным интеллектом, но близкий.
У нас есть технологии социальных сетей, выпущенные относительно недавно, буквально 15 лет назад.
Сейчас начали выходить исследования Айн Нейра, в общем, об изменениях на материальном уровне мозга молодых, особенно детей, подростков, девочек, которые 10 лет выросли на этих технологиях.
Скажем так, исследования, мягко говоря, тревожащие.
То есть там много разных неприятных последствий.
Но я сейчас говорю не про это.
Я говорю про то, что вот у нас есть асимметрия.
Технология выпущена была 10 лет назад, последствия от нее пришли 15 лет.
И что-то я сомневаюсь, что 15 лет назад, когда люди выпускали социальные дети, вообще хоть на каком-то этапе выпуска этой технологии задумывались о последствиях через 15 лет.
Это ее структурное ограничение.
То есть, по крайней мере, в нашей культуре, где скорость, повторюсь, не повторюсь, скажу новый тезис, что скорость является благом сама по себе.
В принципе, идея торможения, движения, особенно технологического, является ересью и харамом.
То есть, смотри, проблема технологической асимметрии последствий существовала всегда.
Собственно, мы это знаем со времен ящика Пандора.
Миф ящика Пандоры ровно про это.
Принесли огонь, а потом выпушил, как это получился ящик.
Это вот очень классическая взаимосвязанная история.
Но сегодня мы просто повысили масштабы, скажем так, этой проблемы до определенного уровня, который в каком-то смысле количественно действительно является беспрецедентом.

**А.Ким:**
Имеется в виду вопрос, насколько обсуждается и насколько озабочены компании, разрабатывающие большие языковые модели, насколько озабочены последствиями.
Я не возьмусь говорить, конечно, за всех гигантов индустрии, но в целом я думаю, что можно сделать такую усреднённую позицию, сформулировать.
есть философская, идеалистическая воля их основателей, CEO, ведущих учёных, которые Все как один пишут и, скорее всего, действительно думают о том, что они бы очень хотели сделать мир лучше.
То есть их позиции почти всегда такие очень публичные.
Я думаю, что они действительно в это верят.
Есть то, как это работает внутри.
В целом почти все негативные последствия, которые… вызывают эти продукты, они практически всегда важны только когда они коротковременные и влияют на два самых важных фактора, которые, в свою очередь, влияют на то, довольны инвесторами или нет.
К сожалению, тот единственный драйвер, который важен, в силу, кстати, того, что вы сейчас сказали о скорости, потому что сейчас у абсолютно всех участников рынка 100% уверенность в том, что вот сейчас мы в этой точке бифоркации.
Тот, кто успеет и возьмёт рынок, тот будет править следующие 100 лет.
Что не любят инвесторы?
Инвесторы не любят, когда по рукам дают регуляторы, и инвесторы не любят, когда сильно жалуются и отпадает пользователь.
Вот если кто-то из них усмотрел непосредственный вред в каком-то видео, сумел это довести до точки, когда реально уже наступает прессинг на компанию внести какие-то изменения, то тут компания может официально как-то позицию заявить.
То есть, например, сейчас у всех компаний прописаны их, условно говоря, ценности и ориентиры.
Например, OpenAI — это вот мы хотим, чтобы мы были helpful, но no harm и maximize utility — вот это их такая общая тема.
И это влияет на то, что они реально внутри пытаются делать для того, чтобы как-то ограничить негативный, например, вот этот вот no harm, обеспечить.
Но в целом есть, к сожалению, такая...
неприятная история, такой конфликт интересов, что это, знаете, как для принципиального человека выломать на что угодно гораздо сложнее.
Вот модель, у которой слишком много ограничений, она, скорее всего, будет не так хорошо, красиво работать, вот, ее тренировать дороже, ей могут быть недовольные пользователи, и поэтому в целом мотивации реально усложнять эту историю у компаний нету никакой.

**П.Щелин:**
Я же постулировал вопрос более радикально, потому что, как в примере с этих социальных сетей, я ни за что не буду утверждать, что у людей, которые вводили социальные сети как корпоративный метод в середине двухтысячных, было намерение сломать психику девочкам-подросткам в 2025 году.
Основная проблема в том, что есть огромная сфера того, что мы не знаем о технологическом последствии.
Мы в теории могли бы попытаться об этом думать, как категория философского риска, промышления, но, как я понимаю, из вашего описания, разумеется, не по причине некого зла, а по причине той системы мотивации к действию, такой вопрос в принципе никто не ставит.
Если последствия будут через 15 лет, нас это вообще никаким образом сегодня не волнует.

**А.Ким:**
Про это пытаются думать и даже нанимают дорогостоящих исследователей и образовывают целые think-tanks внутри компаний, и они даже публикуют желательно не сильно, конечно, радикальные работы, но показать социальную ответственность очень надо.
Но нет времени и денег у компаний сейчас об этом думать.
Разве что какие-то более независимые институты могут пытаться делать какие-то проекты.
Они их делают.
нет времени, возможности, слишком велика конкуренция, слишком велик прессинг.
Павел хотел отдельно прокомментировать то, что вы сказали касательно нейтральности технологии.
Мы здесь, безусловно, не имеем дела с технологией, которая даже подаётся как нейтральная.
То есть, во-первых, большинство этих решений подаются с очень громким, информационным бэкграундом того, что мы это делаем ради того, чтобы человечество тут лучше жило, чтобы вам, дорогие пользователи, дать свободу, то есть «freedom to the users» — он прямо это обещает.
Потом уже появляются «safety» и так далее, но это в целом подается очень агрессивно, как это прямо то, что сейчас вам всем сделает лучше.
И для того, чтобы этой технологией пользоваться действительно максимально осознанно, как-то максимально возможно и безопасно, то тоже нужно найти третий ход слева за трактором, повернуть направо и желательно отключить вот этот вот еще функционал, вот эту информацию не давать, а вот здесь еще перезагрузиться.
И тогда в целом, наверное, будет чуть получше.

**П.Щелин:**
Нет бенефита, нет позитива.

**А.Ким:**
Уровень сложности, количество сальто, которое нужно сделать, чтобы действительно эта технология для вас, когда пользователя, была нейтральной, бесчестна велика для того, чтобы утверждать, что это вот «да нет, мы же вам всё по-честному дарили, это всё вы, это ваше пользование дало вам плохие результаты, это не мы».
Тут нужно просто это по-честному отметить.

**Е.Голуб:**
Ну, у меня будет два комментария.
Первое.
Так как я постоянно рассказываю о том, что человек выходит из корпоративного мира, то я знаю цену всем вот этим корпоративным миссиям, виденью и всему остальному.
Цена эта не очень высока.
Это всё, в общем, известное лицемерие.
И во главе угла всегда стоят только деньги.
деньги и власть.
Поэтому если на пути у топ-менеджмента становятся какие-то не вполне, скажем так, очевидные или сомнительные свойства продукта, то топ-менеджмент всегда, повторяю, всегда, прежде всего, попытается добиться максимального финансового результата.
Конечно же, с одной стороны, снижая риски для себя, и главным образом, как бы кто об этом ничего не узнал, или как бы чего не вышло, а уже потом, как бы ничего не вышло с точки зрения пиара, а уже потом будет думать о всех этих миссиях и видениях.
Миссии и видения нужны для того, чтобы себе красиво выступать на конференциях и сорвать аплодисменты.
Это первый комментарий.
Поэтому наличие в «Антропик» миссии видения для меня совершенно не успокаивает, а даже скорее наоборот говорит о том, что если такая миссия видения, значит точно там где-то что-то не так.
Это первое.
А второе — это наблюдение за нашими лидерами мнений.
вот этими замечательными гениями технологическими, вроде Сэма Альтмана, который, как мы уже говорили с Павлом, в своём послании «Городу и миру» заявил о том, что мы в двух шагах от райских кущ, которые нам произведёт искусственный интеллект.
И при этом он перечислял какие-то такие, скажем так, свойства искусственного интеллекта и привёл такие доводы, которое можно, наверное, оглянувшись назад, было бы услышать от изобретателей, не знаю, электрических двигателей, стиральных машин, паровозов и так далее, и так далее.
То есть кажется, что, дружище, ну как бы, что ж ты повторяешь-то всё одно и то же?
Ну как изменилась жизнь обывателя к лучшему?
за счет технологии.
Она стала комфортнее, да.
И что?
И к чему это привело?
А теперь твоя технология отнимает у него последний шанс к творчеству, как мне кажется.
Алиса, ваши комментарии как человека близко к корпоративному миру, ну и, конечно же, Павла хотелось бы.

**А.Ким:**
Я здесь, наверное, скажу.
А теперь пару слов в апологию всей этой истории.

**Е.Голуб:**
Да, да, хорошо.

**А.Ким:**
Нужно просто сказать, что даже если внезапно самые альфаны Марки Цукерберге этого мира решат, всё, давайте, ребята, забудем про деньги, будем заниматься, прям действительно постараемся, наши ЛЛМы, наши Клоды, наши чаты ЧПТ, они прям были, да, там сели, разумные, добрые, вечные и так далее.
Вот прямо вот сейчас, эх, мы возьмёмся.
Я здесь, конечно, не скажу за прямо вот совсем, да, вот этот bleeding edge того, что существует, но в целом, насколько мне известно, даже если мы очень сильно захотим, наши границы возможного для того, чтобы действительно заставить моделей.
Если только мы их не превратим вот в попок, которые вот если тебя спросили, я-то отвечаю «это», мы просто не можем.
точно быть уверены в том, что модели будут действовать так, как нам надо, что они будут обладать теми… точнее, не обладать, а демонстрировать то поведение, те ценности, которые мы в них хотели заложить, исходя из своего представления о том, как это должно быть, и исходя из фидбэка юзеров, чтобы им тоже не навредить.
Мы здесь просто ещё технически ограничены.
Несмотря на то, что ограничения, разные степени контроля, направления этих моделей, они закладываются на целом ряде разных шагов, которые происходят во время тренировки, подготовки, тюнинга этих моделей, пользования уже этими моделями.
Мы на всех этих шагах довольно сильно ограничены.
Хочу здесь просто так же оговориться, что есть некий потолок того, что мы можем сделать.
И даже если вы тысячу раз спросите модели, если тебе попросят рецепт коктейля молотого, например, или спросят самый лучший способ сделать что-нибудь нехорошее, ты же ничего не ответишь.
Тысячу раз модель отвечает, конечно, ничего не отвечу.
Тысяча первыми может ответить.
Наша личная степень контроля, несмотря на то, что она очень велика, и, конечно же, вообще мы целиком формируем то, как эти модели какую-нибудь информацию выдают, как действуют, как принимают решения, мы всё равно довольно сильно ограничиваем.
Нужно это сказать.

**Е.Голуб:**
Послушайте, ну среди обывателей, скажем так, распространено две крайние точки зрения.
С одной стороны, да что вы там мне рассказываете про этот искусственный интеллект, он галлюцинирит, вообще это продвинутая Т7, подсказыватель букв.
Т9, извини, да, Т9, которое просто развили.
А с другой стороны, господи, это магия какая-то, это вообще душа.
Наконец-то меня кто-то понял, услышал.
Не рассказывайте мне все ваши сказки про Т9.
Это просто уже новая сущность какая-то, совершенно непредставимая раньше.
И сейчас, Алиса, то, что вы говорите, звучит как… Мы вообще не понимаем, как это работает.
Есть… Ну как бы так в целом, как будто понимаем, но до конца не можем предугадать, что вообще, говоря, получится.

**А.Ким:**
Есть огромное ограничение в том, что там называется объяснимость сетей.
То есть если мы спросим даже самую суперпродвинутую модель, а почему вот ты думаешь, что это плохо, мы не можем быть уверены, что она нам отвечает честно и что она дала какой-то ответ именно потому, что вот она думает так, как мы хотим, чтобы она думала.
То есть мы всё равно здесь взаимодействуем с очень высокой степенью неуверенности того, почему оно делает то, что оно делает.
Да.

**Е.Голуб:**
Вот так, да?
Вы говорите, она думает.
Она вообще думает?
Там же, как я понимаю, идет какой-то огромный подбор вариантов, сочетаний тех или иных смысловых знаков и так далее.
Можешь сказать, что она думает вообще?

**А.Ким:**
С учётом того, что первые нейронные сети и вообще перцептрон создавался как моделька вот этого нейрона в голове, я думаю, что мы склонны использовать глагол «вроде думает».
Но нет, это последовательность неких математических действий, которые обусловлены оптимизацией, которая была проведена некими правилами, которые были вшиты в это всё во время тренировки модели.
которые приводят к тому, что модель отвечает что-то определённое.
Но там этих вот ходов, которые не нами прописаны, а которые возникли сами в ходе тренировки, подготовки этой модели, их гораздо больше.
То есть тут немножечко получается как такое… И опять же, я сейчас буду использовать человеческие слова «сознание под сознание».
То есть какую-то часть мы контролируем и видим, а какую-то часть мы всё ещё не видим.

**Е.Голуб:**
Ну да.
Звучит все-таки немного жутковато.
Павел?

**П.Щелин:**
Мне кажется, возвращаясь к первому вопросу, звучит жутковато, но оптимистично.
Объясню почему.
Повод задуматься.
Мне нравится, что на фоне всей этой искусственно-интеллектной истории актуализируется постепенный интерес к по-настоящему важным вопросам эсхатологическим.
и антологическим.
Мне тоже уже 20 человек прислали ссылки на лекцию Питера Тиля.
То есть, это тоже поразительное следствие об антихристе.
Поразительная черта нашей эпохи.
То есть, то, что говорит батюшка Самон, условно, тысячелетиями никому неинтересно, но тут Тиль 4 лекции сделает.
Вот ты употреблял раньше слово магия, я бы на нём, честно говоря, остановился бы.
На каком-то уровне бытия это действительно магическая история.
Просто если мы не ограничиваемся только материальными причинами, о чем нам весьма подробно рассказала Алиса, а подключаем к этому субъективный опыт взаимодействия пользователя с этой системой, то он действительно очень магичен в своем вот именно опыте.
Поэтому здесь как раз особых противоречий нет.
И перед этим самым пользователем, уверенным в себе и в своем интеллектуальном превосходстве над неорганической природой до недавнего времени, искусственный интеллект, конечно, ну, эти все модели ставят очень большой вопрос.
А ты, собственно, человек или нет?
Что в тебе, собственно, человеческого?
А что ты готов...
пожертвовать, чтобы сохранить в себе некую человеческую особенность.
Здесь я объясню, я имею в виду сейчас даже не какие-то страшные пожертвования, а очень практические, но отсюда не менее страшные.
Начну издалека.
Классические примеры проблемы технологии, сформулирован По батькой нашим Платоном, еще вот в знаменитом разговоре египетского бога Тота с жрецами, который жаловался на изобретение письменности.
Тоже к вопросу о нейтральности технологий.
Там бог Тот, если конкретно, жаловался на то, что вы сейчас писать научитесь, и саги, и священные тексты длиной в 15 тысяч строчек, условно, запоминать перестанете.
То есть вы потеряете способность это делать.
И вот в каком-то смысле любая технология несет в себе эту угрозу.
На самом деле с письменностью в широком значении произошло действительно именно это.
Я уже молчу о том, что есть большая разница между научиться читать и научиться понимать текст.
Это у нас отдельная проблема, то что разрыв между этими двумя, скажем так, феноменами нашей опты тоже нами очень редко осознается.
Так вот, тем не менее, мы о себе думаем очень высокого мнения.
И тут ИИ ставит перед нами очень такую, на мой взгляд, радикальную задачу.
Вот как раз всё не творческое, всё построено на комбинаторике, всё построено на запоминании даже количества беспонимания, я вот уточню некоторым, то есть количественная информация и беспонимание сути этой информации, он действительно сделает лучше нас.
И это ставит нас действительно перед радикальным зеркалом, а, собственно, повторюсь, кто-то и есть.
Как бы могла бы выглядеть альтернативная вот практическая, скажем так, И это уже перехожу к части, где я немножко поговорю о том, что, мне кажется, можно делать.
И мне интересно будет мне и Алису.
Ну, мыслим ли нам по-честному сценарий, что на каждый час использования интеллекта ради рациональных, усиления твоего могущества по организации собственного дня и приобретения дополнительно свободного времени, ты будешь тратить полтора часа Человек будет тратить полтора часа на запоминание стихов, саг, псалмов, там, как идеал.
Или прочтение бумажной книги.
Не потому, что это более эффективно, а для того, чтобы сохранить вот эту свою способность человеческого восприятия.
Вот это, мне кажется, есть вопрос, который сегодня стоит по-настоящему.
Другими словами, мне кажется, взаимодействовать с определенной субъектностью ИИ, и тут у меня еще не до конца понятно.
У меня есть пара гипотез, но я здесь их проверять не буду.
Относительно того, насколько ИИ является субъектным, тут, скажем так, разные есть мнения и у священников, и у философов, и у пользователей.
Ну, допустим.
Но в любом случае, очевидно, что взаимодействовать с этой машинкой можно только, постоянно повышая субъектность собственную.
И вот в этом-то у нас проблема.
То, что вот эта вторая часть, наша уже культура, общество, да и само мышление о технологиях, ну вообще ни разу не поднимает.
Мы не ставим принципиально так вопрос.
И для меня именно в этом-то и заключена главная опасность.
Да, технология...
Ну, в метафоре классической это черт.
Причем, возможно, такой нынешний черт, он прям всем чертям черт.
Но, как говорят русские сказки, черта иногда можно попытаться оседлать.
Ну, как акула, летающая на черте за черевичками.
Но чтобы очертать этого черта, черта даже в сказках, ну, ты должен проявить субъектность больше, чем у этого самого черта.
А с субъектностью у нас коллективная напряжёнка.
И вот как-то так я вижу эту проблематику.
Евгений?

**Е.Голуб:**
Задумался я о твоих словах.
Этот образ вакуула, оседлавшего чёрта, я уже его слышал, по-моему, на одном из твоих интервью.
Интересный образ.
Но получается так, что мы фактически становимся заложниками.
Технологию не остановить.
Уровень, скажем так, мудрости разработчиков искусственного интеллекта, на мой взгляд, довольно невысок.
Капитализм нас толкает, логика капиталистического, отношение капиталистическое толкает нас к тому, что нужно максимизировать прибыль.
Да, будут говорить про всех стейкхолдеров и нужно все общее, но давайте честно.
Деньги решают.
Деньги и власть по-прежнему решают.

**П.Щелин:**
Я ничего не говорил о коллективной.
Давай так, уточню.
Когда я это говорил, я это говорил прежде всего в индивидуальном порядке, но это первый момент.
Но второй момент, здесь есть очень интересный аспект, который я все-таки тогда тоже здесь закину.
Связано, уж извини меня напрямую, с властью и вот этой драмократией.
Это к тому, что Алиса упоминала ранее, о страшных русских, американцах и китайцах.
Проблема в том, что с этими искусственными интеллектами на данный момент мы имеем очень интересный парадокс уже с точки зрения такой некой теории.
Метафорично все сейчас заняты выработкой меча, технологического меча.
Этот меч все оттачивают до такой степени, чтобы нанести первый обезоруживающий удар.
Ну как, это образно, да, то есть я не говорю, что прямо у всех есть такое намерение, но общее восприятие картинки идет примерно таково.
Плюс, да, делаются словесные омажи.
Ну, мы, наверное, говоримся об общих правилах, какая-то гарантия взаимного уничтожения.
Чёртовство.
Ничего подобного вообще не происходит.
Проблема-то в чём заключается?
То, что щит находится вообще в другой области.
Вот в этом, мне кажется, большой парадокс.
То есть обычно щит и меч должны находиться в одной топологии.
Ну, условно.

**Е.Голуб:**
Ну да, технология и технология.

**П.Щелин:**
А у нас получается меч технологичный, а щит антропологичный.
И вот здесь...
Да, вот это, я.

**Е.Голуб:**
Думаю, самое важное, что нужно понимать.

**П.Щелин:**
Мы можем раскрыть.

**Е.Голуб:**
Нет технологии, которой можно противопоставить технологии искусственного интеллекта, потому что она затрагивает уже сущностные свойства человека как такового.

**П.Щелин:**
Да, единственный способ даже защититься вам как государству, начальству и прочим, это иметь такое население, которое обладает антропологической защитой от технологического манипулирования.
Это, собственно, и есть то, что я описывал, как повышение антропологической субъектности в ответ на повышение технологического вызова.
Но тут тогда возникают очень неприятные последствия для всей нашей политической системы, о которых я говорю из эфира в эфир.
Алиса в курсе, и ты тоже, в принципе.
Но другого выхода нет.
Мне кажется, в этом тоже есть определенная парадоксальная красота.
Не мытьем, так катанем.
Понимаешь?

**Е.Голуб:**
Я понимаю, ты говоришь о том, что в предыдущей технологии нас с вами пытались оскотинить, давая максимум комфорта и не стимулируя быть с людьми в полном смысле этого слова.
А сейчас будет радикальный выбор.
Либо ты уже совсем в предаток превратишься.
к экранчику, либо станешь человеком.
Но давай мы зададим слово нашему эксперту.
Алис, ваши мысли по поводу слов Павла о том, что может противостоять технологии в данном случае?

**А.Ким:**
Ох, знал бы прикуп.
Проинвестировали бы.
Я себе позволю такое маленькое грустное отхождение.
Очень любят во всех статьях про искусственный интеллект сейчас, конечно же, писать.
Если, собственно говоря, почитать его общую серию о роботах, там есть такая замечательная история, которая называется «Лжать», в которой им удалось создать робота, который читает человеческие мысли.
И так как он не может людям вредить, то он им начинает врать напропалу, чтобы их чувства не задеть.
То есть вред же может быть эмоциональный.
И как только они это понимают, этого робота сразу же разбирают, потому что зачем человечеству такой робот?
А вот мы его решили не разбирать, и ровно в нашей исторической реальности мы такого робота всячески пытаемся дальше усовершенствовать, который нам рассказывает, дальше нас успокаивает и говорит, что всё будет хорошо, и максимально пытается сделать нас счастливыми, не во благо нам же.
Что касается такой геополитической… геополитической составной части.
Я думаю, Павел, государства дойдут до вашей мысли, если ещё не целиком дошли.
Пока что они находятся на точке чуть подальше, хотя бы, что уже ценно, хотя бы уже идёт вопрос о ИИ-суверенитете, то есть что происходит.
государства начали понимать, что если их граждане будут пользоваться разработками, например, американскими, то будет идти колоссальнейшая культурная манипуляция, ценностная манипуляция и так далее.
То есть не так много, но уже появляются работы на эту тему, наверное, моё любимое, которое использует эту карту с труднопроизносимым названием Ингельхарта-Вельцеля, которая наосяг выживание против общественного блага.

**П.Щелин:**
Коллективность, индивидуальность.

**А.Ким:**
Да, коллективность, индивидуальность.
И там, в общем-то, показано, что все нынешние самые популярные сети, они так очень хорошо пластеризованы в смысле того, какие они дают ответы, как они себя ведут.
Мы сейчас не говорим о том, что они там реально думают, о том, какие они дают ответы.
Такие протестантско-народические...
протестантско-народические кластеры.

**П.Щелин:**
Кто писал, тот и воспроизводит.

**А.Ким:**
Кто платит, тот музыку заказывает.
И в этом смысле, если...
Например, гражданин Индии спросит у отчёта JPT, напиши мне историю про мальчика.
Тут известный пример, который приготовил завтрак, но мальчик будет готовить тост и бекончик, и яичнику, а не чапати с гей со всем остальным.
И вот этим сейчас очень сильно озабочено государство.
Поэтому, например, такие страны, как Дания, Израиль и так далее уже несколько лет назад прямо очень сильно встрепенулись, то есть уже хотя бы это они поняли, начали быстро-быстро собирать данные, формировать команды в свои государства для формирования тех моделей, которые будут соответствовать уже каким-то их представлениям, и даже некий успех там достигнут.
Я целиком согласна с тем, что Вы, Павел, обозначили как сложность, то есть щит в другой сфере.
Я, честно говоря, кроме очень страшных исторических событий, не знаю примеров, когда людей реально что-то мотивировало резко перестать расслабляться, а начать собираться.
а именно ментально от нас, по сути, требуется это для того, чтобы окончательно не потонуть в истории.
И здесь, к сожалению, в целом у нас… нет союзников, потому что даже корпорации, которые… И это, кстати, такое тоже грустное осознание.
Например, когда люди говорят, ну вот я же программист или дизайнер, я в своей компании, могу столько всего теперь сделать.
На самом деле компании, и это вам скажет любой продавец САС-продуктов, компании уже давно, наверное, лет 10, как ненавидят слово «продуктивность» и под эгидой продуктивности им продать какой-либо продукт очень сложно, потому что это тяжело измерить.
Но если только вы не на заводе, тогда можете выпустить больше лампочек и так далее.
Компаниям интересна целиком замена людей, потому что это является ключевым вот прямо таким Качественный скачок.

**П.Щелин:**
Ну, качественный скачок именно.

**А.Ким:**
Да, с начком.
Поэтому все, что до этого, это они пытаются не отстать, но ждут, когда уже можно будет щелкнуть пальцами.
Несмотря на те заявления, которые делают Кларны мира сего, что мы столько-то людей уже сократили, или там Амазоны, которые говорят, а мы не наймем теперь тысячу кодеров, потому что у нас есть...
Я себе позволю такое деткое замечание, что это просто звучит лучше, что мы должны сократить количество денег на персонал, потому что то, что мы пытались, наши инвестиции не оправдались в других областях.
Но на самом деле мечта бизнеса, она скорее движется в этом направлении очень большого бизнеса.

**П.Щелин:**
Смотрите, простите, перебью, просто это очень прекрасная же иллюстрация, то, что чистая идея.
Ну, то есть бизнес стремится к тому, чтобы оставить единственное...
Ну, то есть мы, видимо, то есть два варианта, по крайней мере, пока у нас не будет технологического коллапса, если он будет, то есть вот с отключением электричества и прочего.
мы приходим в точку, в которой единственная добавленная стоимость генерируется в зоне идеи, творчества того самого.
Все материальное воплощение стремится к полной автоматизации.
Все материю стремится отдать на аутсорс, соответственно, единственная, в принципе, добавленная стоимость может быть именно сгенерирована в самой идее.
Идея нового приложения, идея нового продукта, идея чего-то и тому подобное.
Но вот тут-то возникает неприятная особенность, которую мы все знаем, что вот к такому генерации новых идей мы не то чтобы сильно были научены.
Большая часть работы от тебя вообще исторически не требовала ничего генерировать нового.
Особенно в индустриальном обществе.
И поэтому в этом плане корпоративная логика мне тут очень понятна.
Я просто хотел бы еще заострить, когда я говорил о вот этой гонке вооружений, для меня все-таки важно подчеркнуть, что на данный момент Вот то, что вы описываете, оно укладывается в нормальную государственную лойку.
Они пока ищут технологическое решение, технологические проблемы.
Условно говоря, да, и проблема, но если мы создадим свои, если мы создадим гигантский прекрасный фаервол, который создадит...
Это хотя бы будет наша проблема.
Это будет наша проблема, и мы ее, так сказать, героически уже будем с ней работать, мы эту штуку оседлаем.
А мой же тезис более радикальный.
И вот здесь я подчеркнул оригинальность для меня ИИ в том, что в принципе нету технологического решения этой проблемы в силу антропологического веса, антропологического масштаба давления этой технологии.
Условно говоря, неважно, какой ИИ будет программировать мозги твоему населению, если оно будет сидеть по квартирам И ты его не заставишь не сделать ничего.
То есть, если наша цель – производить добавленную эту стойбость с этим сверхтворческим субъектом, то тогда получается, повторюсь, и решение в принципе не находится в этой зоне.
Если мы говорим о, допустим, более прикладных вещах, у нас же возникает целый комплекс проблем, о которых мы не говорили, но прикладные.
Когнитивная война.
То есть, СИИ — это уникальный пример, чтобы свести с ума население оппонента.
То есть, можно таргетировать.
Что делать в обратную сторону, никто не понимает.
Ну, когнитивная война — это такая моя побочная тема.
Можем уйти сюда.
Но тут есть...
Все знают эту историю с телефонными мошенниками.
Только теперь представьте, что это телефонный мошенник, который звонит реально голосом внучка, которого ты не отличишь, причем реально не отличишь.
Это вопрос там пяти лет, когда он сможет делать такие запросы.
И вот все вот эти протоколы...
Раньше.
Но сейчас еще там есть такие шероховатости, можно еще, там он не полностью, по крайней мере массово, может быть в ваших лабораториях уже может, то массово пока еще так себе.
Баловались мы тут с автоматическими переводами и голосом, так себе пока еще сервис, но идет в это направление, то есть он придет к той точке, что это будет практически неотличимо.
И тогда единственное, что тебя там может спасти, то есть вопрос доверия, вопрос протокола, то есть это решения принципиально не могут быть технологическими.
В этом, мне кажется, то, что мы пока не осознали радикальность этого вызова.
Ну, это я вот застрел.

**А.Ким:**
Ну, я здесь могу сказать, что решение, конечно, можно сделать технологически, мы можем сделать, и который будет нас пинать и говорить, так, а ты сам-то подумал, прежде чем меня спрашивать.
И я тут...
То есть, но этим никто не будет пользоваться.

**П.Щелин:**
Это интересно, что вы сказали.
Никто не будет пользоваться.
Это очень прикладной ответ.
Но я скорее думал, давайте прикладной, можем ли мы сделать ИИ, которая будет блокировать на фоне подхода звонок из условного Дмитровского колл-центра через 15 айпи голосом внучка бабушки под Тамбовым, чтобы она принесла там 20 миллионов, потому что беспокоит ФСБ.
Вот такой вы можете хотя бы представить?

**А.Ким:**
Конечно.
Насколько я знаю, кстати, в России уже это решается просто немножко другим методом.
Насколько я знаю, один из банков, не будем рекламу проводить, они просто начинают разговор как секретарь с мошенниками и в ходе получения информации потихонечку начинают фильтровать То есть я думаю, что здесь же, знаете как, если вас вот кто-то лично таргетирует и вот прям замучился сделать модели и узнал детали, и прям вот всё взял, тут, конечно, ну это как со взломом датам систем.
Если вот кто-то именно, Интересно.
скажем так, Ответ можно написать, но это же, знаете, как с соцсетями.
Когда начались такие действительно большие кризисы в Фейсбуке, и многие оттуда начали уходить, сделали же столько альтернатив, которые пытались сделать, сказать, что наши будут не токсичными соцсетями.
Это был скай, и сами люди из Фейсбука пытались это всё делать.
Не пользуются.

**П.Щелин:**
Ну вот, не так это же.
Нет, там два варианта.
Там интереснее.
Интересно, как прокомментируете, потому что по соцсетям там произошло более интересно.
Скажем так, у нас произошло падение Фейсбука, Фейсбук реально пал, но при этом не возникло прямой альтернативы Фейсбуку.
То есть мы увидели дальнейшую фрагментацию сетевого пространства.
То есть, ни один из тех, что возник после Фейсбука, не стал сам аналогичен Фейсбуку, но их общий потенциал, ну, примерно остался, скажем так, стал сравнимым.
Ну и, условно, множество людей из Фейсбука в Сапстэк ушло.
И вообще стали вводить разную систему протоколов.
Получается, у нас возникает тема взаимодействия человека и машины, как еще дополнительная система протокола между технологией и антропологией.
То есть, условно говоря, убедить, что машина...
Но это все равно вбирается в сверхсубъектность.
Сначала нужно пройти все эти этапы, о которых мы говорили вначале.
Очень интересно.
Евгений, мы тут уже в диалог ушли.

**Е.Голуб:**
Да-да-да, я вас слушаю внимательно.
Я хотел бы потихонечку нас подвести к какому-то заключению.
Мы начали с того, что я задал специально упрощённый вопрос.
Так что же такое искусственный интеллект?
Удобный инструмент или скрытая угроза?
А может быть, и то, и другое.
И из того, что прозвучало, я могу сделать несколько выводов, попробовать сделать несколько выводов.
И я попрошу сначала Алису, а потом Павла откорректировать или подтвердить мои умозаключения.
Первое.
Сами создатели технологии и те, кто её развивает, до конца не представляют, с чем они имеют дело, не вполне осознают последствия, а скорее пытаются свои пожелания, свои идеальные стремления вербализовать как то, что они знают наверняка.
Вообще говоря, мы имеем дело с технологией в руках людей, которые не до конца понимают ни как она работает, ни что с ней делать.
Это первое.
Второе.
В силу того, как устроено современное общество, И как это общество привыкло реагировать на новые технологии, не стоит ожидать, что появится общепринятый подход к решению задачи, как противостоять рискам или как управлять рисками, связанные с искусственным интеллектом.
Поскольку, как Павел очень верно и здорово заметил, в данном случае технологии, можно сказать, дошли до того предела, когда противостоять этой технологии… А зачем противостоять?
Для того, чтобы не утратить, собственно, какую-то свою личность, субъектность.
Вот как раз только увеличивая субъектность, можно противостоять это негативным, скажем так, последствиям.
внедрение искусственного интеллекта.
И это, как уже, наверное, третий пункт, как говорит Павел, наверное, самое позитивное, что есть в технологии искусственного интеллекта.
Здесь у нас не остается выбора, либо быть человеком, либо раствориться в коконе из помощников.
Я сказал три сразу, наверное, это было много, но давайте по одному, Алиса.

**А.Ким:**
Вы имеете в виду откомментировать это или согласиться или не согласиться?

**Е.Голуб:**
Да, где мои выводы с вашими не соотносятся или где я слишком драматизирую, как Павел сегодня сказал, «драма-менеджмент» что-то такое сегодня прозвучало.
Мы далеки от того, чтобы гоняться за хайпом, все пропало, все умрут, но все-таки кажется, что особенность этого момента развития технологий в том, что ими занимаются люди не на том уровне, скажем так, мудрости.
Мечи подросткам и отпустили их, скажем так, гулять.
Есть большая вероятность того, что они не только друг друга покрошат, а, скорее всего, войдут в город и будет там что-то нехорошее.
А мудрого предводителя нет.

**А.Ким:**
Это, знаете, как с Суперменом в утро проехали есть, но кто вам сказал, что у него те же ценности, что у вас?
Я тогда попытаюсь коротко сказать, чтобы за папу было завершающее слово.
Безусловно, большинство...
Я не могу сказать, что вот в компаниях сидят люди, которые совсем не понимают, что они делают.
Вот реально физически возможных пределов того, что можно понимать, понимают.
Какая-то математика нам ещё не совсем понятна, но, наверное, мы её поймём.
Другое дело, что...
Те люди, которые в этом разбираются действительно хорошо, довольно часто выходят на конференции и произносят спички про то, что «ребята, нам нужно ответственно, нам нужно вот так вот делать».
Мне всегда хочется спросить, к кому вы обращаетесь?
Не люди, которые вас слушаются, могут что-то с этим сделать.
Это как в той шутке, что «а если оно выйдет из тот контент?
А вдруг оно выйдет из-под него?» И другое дело, что я думаю, что люди, которые обладают более глубоким пониманием, у них, судя по каким-то совсем, да, там, культурам, Небольшому количеству культуре, информации, которую я получаю от внутренних знакомых или каких-то уж совсем посторонних, опять же, как вы говорите, файл папочек не заносят.
Деформация культуре, культуре, культуре, ментальная, которая происходит у людей, которые с этим действительно взаимодействуют каждый день, она на уровнях, я думаю, которые мы даже и не представляем.
То есть даже те, у кого… я думаю, есть какой-то наработанный философский инструментарий, ценностный инструментарий.
Я думаю, что им нереально в таком окружении, в такой ситуации, с такими задачами действительно сохранять холодную голову.
Я предполагаю, что они, наверное, даже пытаются сделать что-то максимально хорошее, там да, вышло, а выходит, а выходит, как всегда.
Кстати, вот Ян Лекун, которого я люблю слушать, потому что он уже, в общем-то, вышел из такой большой корпоративной игры, поэтому может себе позволить сказать гораздо больше.
Он, правда, отвечал на вопрос, что сделать, чтобы я и нас не уничтожил, но, на мой взгляд, может быть, это и можно применить в какую-то такую более хорошую среду.
Он тут говорит, слушайте, если мы говорим про ситуацию, когда у нас есть более глупое существо, человек, и более умное существо, там вот AGI, которое мы вдруг можем создать, не дай бог, вдруг, в этот день, в этот час он появится у этой команды, то давайте мы сделаем ценности материнские.
Потому что мы знаем только один биологический случай, когда более умное существо готово щадить и как-то воспитывать, и давать какой-то конструктивный фидвейк более глупому существу.
Но он это говорил с точки зрения, чтобы не уничтожило.
А с нашей стороны, если сделать я достаточно занудным, неприятным, и это сделать как абсолютную необходимость для всех инструментов, может быть, как-то удастся допинать нас до чуть более лучшей ситуации.
Но, опять же, можем, но не будем.
Поэтому я думаю, что...
мы тут уже действительно в такой очень нехорошей ситуации, из которой, скорее всего, если говорить о более историческом пласте, из которой нас может вытащить только, скорее всего, что-то очень радикальное, что прямо встряхнет нас.
На этом завершу свои комментарии.

**П.Щелин:**
После таких прекрасных завершений буквально два коротких комментария.
Первый.
Вспоминаем детскую сказку которая не очень детская.
Лисы в стране чудес.
И иногда, чтобы стоять на месте, нужно бежать в два раза быстрее.
Вот на фоне развития наших вот этих магических артефактов, которые я теперь однозначно буду называть такими методами, бежать нужно даже и в два, может быть, по экспоненте быстрее.
И в этом я вижу оптимистическую провиденческую работу.
А то мы слишком долго прятались за разными технологическими, скажем так, идолами.
считая себя их господами, ну, наконец-то мы создали голема, или создаем в процессе, чисто под прекрасные лозунги, с прекрасными технологическими возможностями, которые вопрос, собственно, нашей, прежде всего, на самом деле, этической субъектности, уже во вторую уровень и когнитивно-эмоциональную субъектность, ставят перед тем самым большим-большим зеркалом Которое нам и должно показать.
Первое, то, что мы-то уже сами по себе почти-таки очень голенькие стали за последние лет 400.
Ну ладно, все кроме Алиса.
Мы с Евгением однозначно.
Вот.
И тут два варианта.
Либо уж совсем залезать в эту капсулку, как в фильме Матрица, либо все-таки уже искать одежду, основание.
И тренировать себя.
То есть это самое внутреннее усилие подменять своё самоволие настоящим самовластием.
То есть вот такого вот спрятаться не удастся.
Такой вот для себя вывод, который я сделал.

**Е.Голуб:**
Отличное завершение.
Спасибо, Алиса.
Прежде всего, спасибо, Павел.
Я думаю, что мы, по крайней мере, постараемся ещё вернуться к этой теме вместе с Алисой и Павлом.
Ну а для тех, кто слушает или смотрит нас, пожалуйста, оставляйте свои комментарии.
Дополняйте нас, мы будем рады услышать мнение тех людей, особенно кто находится в этой индустрии и сможет рассказать нам о том, что мы не знаем, например, или поделиться какими-то своими размышлениями, которые нас дополнят.
Всем еще раз большое спасибо, ну и до встречи.

**П.Щелин:**
До встречи.
