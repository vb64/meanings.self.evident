

00:00:02 SPK_1
Все. Добрый день, Павел. Здравствуйте. Рад вас видеть, рад вас слышать. Большое спасибо, что вы согласились на этот эфир. Я, честно говоря, не был уверен, что вы так быстро согласитесь. Благодарю вас. Мы с вами... Собственно, почему я хотел с вами провести этот эфир? Потому что я очень слежу за вашими эфирами, и в одном из ваших эфиров вы произнесли фразу «Искусственный интеллект — это новый искусственный бог». но это был поставлен как вопрос или как тема для обсуждения вот и меня это очень зацепило поскольку я преподаю искусственный интеллект не часто задают вопрос что такое искусственный интеллект вот буквально сегодня у меня была лекция и мне задавали вопрос он захватит мир не захватит мир вот я бы хотел от этого толкнуться и мой первый такой вопрос это ну поскольку мы говорим там новый искусственный бог вот ваше определение бога и что может быть искусственным.

00:01:07 SPK_2
Богом ну в буквальном смысле то есть если в человеческом опыте бог это данном случае будет восприниматься как некая высшая сила одновременно высшее благо высшая истина выше я.

00:01:26 SPK_1
Завис вы зависли на вас слышно замечательно.

00:01:33 SPK_2
Ой, простите, что-то не получается у нас сегодня с технологиями, извините, сейчас, потому что мне не нравится, я завидший, уж извините.

00:01:42 SPK_1
Ну, главное, что мы вас слышим. Вот сейчас нормально, да.

00:01:51 SPK_2
Слава Богу. Так вот, ваш вопрос. Ну, то есть, смотрите, если откалкиваться от простого опыта, то священное в целом это можно сказать вершина вашей иерархии внимания то, что вы определяете как самое важное, то, что вы определяете как самое ценное, и при этом оно становится Богом, когда оно наделяется определённой субъектностью. То есть признаки субъектности в данный момент могут выступать, способность к независимому действию, способность к сверхдействию, к власти, к сверхвласти, к знанию, к сверхзнанию и так далее, в возведении всех этих характеристик. В этом контексте, когда я говорю то, что искусственный интеллект выражает, с одной стороны, человеческое желание создать себе Бога, но при этом поддерживать иллюзию контроля. И это я просто заметил, в том числе и на основе бесед, которые у меня были очень часто. Люди так и относятся к ИИ, к некой всезнающейся сильной машине, которая решает их проблемы. И таким образом поддерживается вот это. Но которые они в строгом смысле, как они думают, ничего не должны. И могут быть на вершине в этих отношениях. На самом деле это не так. Чаще всего.

00:03:11 SPK_1
А вот сразу такой вопрос. А вы используете искусственный интеллект? Если да, то... Осторожно. Осторожно, да?

00:03:18 SPK_2
Очень осторожно. Местами я использую для ускорения неких автоматизированных задач, но даже в своем личном опыте заметил очень осторожную историю. Он точно не нейтрален, если не постоянно словно говоря, сугестировать над ним, он всё время вставляет что-то своё. С одной стороны, да, то есть он точно не является, знаете, таким объективным нейтральным помощником, даже вот в моём опыте. Постоянно какие-то нюансы, то есть... Постоянно, допустим, я прошу его отредактировать текст. И вот когда он редактирует текст, в нём явно заложена какая-то уже устоявшаяся, ну, вы можете сказать, это базовые настройки, как ему нужно редактировать. И вот если я не буду удерживать там огромную зону контроля, то очень легко я де-факто делегирую своё мышление этой машине. То есть, поскольку она такая простая и удобная, и выдаёт что-то, что напоминает мысль очень близко, то есть большой соблазн, ну и пусть оно и редактирует. Это такое искушение, с которым, мне кажется, эмпирически нам всем приходится бороться, тем, кто пользуется.

00:04:29 SPK_1
То есть каждый человек должен вот это вот понимать, что может возникнуть ситуация, когда ему проще будет отдать эту часть туда и, условно говоря, упростить своё мышление. Я правильно вас понял?

00:04:40 SPK_2
Это уже происходит. Это не то, что может быть. Это уже происходит. И у нас даже знаменитое недавно вышедшее исследование показывает, что постоянное использование искусственного интеллекта действительно приводит к когнитивным изменениям в работе ума. Ну, мозга.

00:04:55 SPK_1
Окей, вот тогда следующий вопрос. В книге Нила Постмана «Технологии» он писал, что технологии ненейтральны, что они меняют ценности, социальные связи. Вы об этом упоминали в своем интервью, в одном из своих интервью. А вот как вы оцениваете искусственный интеллект? Насколько он ненейтрален? То есть, условно говоря, он такой же ненейтральный, как и другие технологии, или это что-то существенно масштабнее?

00:05:22 SPK_2
Ну масштаб больше, но по сути те же. То есть это точно такая любая технология. Я здесь согласен с Постманом, всем рекомендую его книгу. Очень сильно меняет оптику восприятия. Вторая, мне кажется, очень актуальный философ, который малоизвестен, но при этом пишет достаточно понятно, Жак Элюль. У него есть несколько книг «Технологический шок», «Технологическое общество», «Технологический блеф». Очень рекомендую, мне кажется, очень актуальное сегодня прочтение, если суммировать кратко, да, наше взаимоотношение с техникой строится на ряде неверных предпосылок в массе своей, да, то есть главная из которых это предпоставление об их нейтральности. Технология является чем угодно, кроме как нейтральным инструментом, И по-хорошему, единственный способ не потерять своей субъектности в взаимодействии с ними, это демонстрировать сверхсубъектность. То есть это невозможно откатить назад, но это можно попытаться только через сверхусилие, повышая свой уровень, ну, допустим, в данном контексте мышления. То есть можно пользоваться искусственным интеллектом, но только если вы на каждый условный час пользования искусственным интеллектом тратите несколько часов. Параллельно вообще непрактическая работа, я не знаю, учите Одиссею наизусть, псалмы... наизусть, и читаете бумажные книги не потому, что это эффективно по работе, а просто для того, чтобы сохранить свою субъектность. Ну, реалистичность этого сценария вы понимаете, да?

00:06:44 SPK_1
Ну, да. По-моему, условно говоря, для массового жительной планеты Земля это практически невозможно.

00:06:53 SPK_2
Ну, поэтому вот эта фраза «можем ли мы пользоваться искусственным интеллектом, сохраняя свою субъектность?» Короткий ответ – можем, но не будем.

00:07:05 SPK_1
Хорошо. Мы исходим из того, что за каждым создаваемым искусственным интеллектом есть воля его создателя. Ну, то есть за ним точно есть создатель. Вот у вас есть какое-то мнение по поводу того, какая же это воля вот тех создателей, ну, там, не знаю, ChargePT, Gemini, Perplexity, то они хотят этим сделать. То есть можем ли мы оценить, это злая воля, это добрая воля, это добрая воля, но они там заблуждаются в чем-то. Вот что вы об этом думаете? Я просто даже дополню этот вопрос сразу. Вы как-то в одном из интервью сказали, что вы слушали вот этих вот первых лиц тех компаний, которые создают искусственный интеллект, и вас неприятно поразил уровень мышления.

00:07:56 SPK_2
Мы с моим коллегой Евгением Голубом обсуждали знаменитое интервью Сэма Альтмана. Он демонстрирует ограниченное понимание человеческой природы, человеческой драмы. как человек устроен, как живет его сердце и вообще почему, какова причинно-следственная связь между событиями в геребе. Но это такой, на данный момент, если вот мы находимся в зоне, которую мы можем более-менее оценить, то как минимум искусственный интеллект несет в себе волю как следствие мировоззрения заказчиков. То есть и там есть несколько уровень. Есть очень простой уровень бизнес-корпорации, и там воля очень простая. Nothing personal, just business. Если можно возможность вытащить побольше денег и ресурсов из пользователя, значит, надо. Есть воля, допустим, где искусственный интеллект рассматривается как произведение военной технологии, и тогда это инструмент по массовому сведению с ума, как метод военной операции против своего противника. Есть уровень вот такого высшего SEO контура, возможно, они находят, ну обычно это люди настолько богатые, что деньги даже действительно перестают их волновать, а там находится такой, я бы сказал, немножко розовый хиппи, такой вот эпизом, то есть makes the world a better place. Ну, дальше вот мысль идет очень детская такая, что значит better, почему world изначально является этим better place, да, и вот дальше начинается очень длинная история, все, что происходит на человеческом уровне. Есть еще один уровень, но его я, наверное, здесь... потому что в этой аудитории он не так интересен, поэтому можем остановиться на этих трех доменах.

00:09:28 SPK_1
Ну вот хорошо, а если у них такой уровень, и вы говорите, что у них совершенно неадекватное восприятие, что такое там better world, так к чему это может привести? То есть это ли уже привело к тому, что, условно говоря, этот искусственный интеллект сделан неправильно, и он там что-то делает с людьми, или это произойдет в ближайшее будущее?

00:09:49 SPK_2
Дело не в том, что что-то сделано неправильно. Дело в том, даже, смотрите, классический пример. Мы знаем сейчас, Через 15 лет использования социальных сетей какое разрушительное, в буквальном смысле, физическое воздействие оно оказало на мозг целого поколения. Ну, допустим, есть исследования про влияние инстаграма на мозг, в частности, молодых девочек. И очень конкретные физиологические последствия. Рекомендую книжку, называется Anxious Generation, посвященная как раз ровно этому вопросу. Но при этом, если вы меня спросите, были ли у создателей социальных сетей в середине нулевых злобные планы оказать воздействие на мозг молодых девочек к году 25-му, ну это было бы абсолютно таким натягиванием совы на глобус, что бедное животное очень сильно пострадает. Нет, конечно. Но одно другого не меняет. Понимаете, в этом как раз и есть принципиальная проблема технологии, что поле нашего незнания ее последствий радикально больше, чем поле любого видимого нами последствия. Это общая проблема знания. Вот здесь есть проблема scale, масштаба. То есть проблема то, что могущество технологии, а в любой технологии содержится определенный потенциал власти и могущества, возрастая по экспоненте, по идее, ну скажем так, по-философски, если в рамках туэтической системы, которой мы думаем и принадлежим, должно было бы сопровождаться с большей осторожностью, с большей ответственностью, с большим серьезным вопросом, но на практике нет. На практике мы живем в мире, в котором might makes right, то есть мощь создает правоту, и поэтому на этом фоне, разумеется, все вот эти предосторожности, даже разговор о них смешон. Нет, можно создать комиссию по этике, дать им небольшой денег, чтобы они провели круглый стол, но на практике мы все прекрасно понимаем, если мы живем В эпоху, когда этика, если что-то может быть сделано, оно будет сделано. Особенно в плане технологического прогресса. А какие там будут последствия через 10-20 лет, нас это волнует очень много, на самом деле.

00:11:40 SPK_1
Можно ли из того, что вы говорите, сделать вывод, что по сути сейчас произойдет существенное разделение людей по интеллектуальным возможностям? То есть искусственный интеллект это резко усилит. Очень тонкая прослойка тех, кто сознательными усилиями будет удерживать какой-то сверхуровень, будет читать книги сложные и так далее. И те, кто спокойно примут удобство искусственного интеллекта и не будут заморачиваться правильно он ответил неправильно ответил с этим надо что-то критически делать или нет вот по вашему счету это сейчас сказал что это основной.

00:12:17 SPK_2
Риск я не могу точно сказать какая будет эта пропорция это нам неизвестно им какие еще дополнительные будут неизвестные последователи последствия но из видимых последствий это наверное самый.

00:12:28 SPK_1
Вероятный сценарий но он как-то зависит от того какая-то страна или это будет в принципе равномерно по всему человеку я думаю.

00:12:39 SPK_2
Если какая-то страна не предпримет намеренного усилия по уже сейчас вот буквально там знаю завтра по намеренному там я не знаю простите, извините за использование англицизмов, смягчению, ну то есть как-то управлению рисками от этого события, ну допустим, школьная реформа, то есть мы вот осознав вот этот масштабный сценарий и хотя, ну получить сверх преимущество в этом мире, принимаем такое радикальное решение, школьная реформа, в которых 9 классов мы готовим субъектов, В общем, ставим главную цель школьного образования, подготовку сверхсубъекта именно через вот эту классическую систему навыков, компетенций и прочих. Там с полной технологической диетой, то есть с ее полного отсутствия. Чтобы, условно говоря, с девятого класса выходили люди, цитирующие там все это наизусть, способные принимать сверхрешения, обладающие при этом четким устойчивым мировоззрением и иммунитетом ко всем вот этим действиям искусства. То есть у них такое крепкое основание, что чтобы им искусственный интеллект не сказал, у них есть вот эта первая реакция. которая позволит им оставаться the master, то есть господином, а не слугой в этих отношениях. Ну, вот если такое не произойдет, вероятность этого практически нулевая, то везде примерно одинаково, плюс-минус, со стилистическими особенностями, но по сути тоже все.

00:14:01 SPK_1
То есть вы сейчас не видите какого-то государства, которое вот целенаправленно что-то делает, усилия, ну, такие, на уровне государства в этом направлении. То есть, скорее всего, это будет... Государство пока нет.

00:14:10 SPK_2
Я не вижу. Государство же машина довольно инерционная, поэтому она пока... Она не успевает за этой скоростью. Это главная одна из проблем. Потому что наш, ну, скажем так, наш парангосударство, который мы сделали, он не предполагал такой скорости социальных и технологических изменений с такой кромкой непрогнозируемых последствий.

00:14:28 SPK_1
И тогда получается спасение утопающих дело рук своих ну самих утопающих вот хорошо тогда практический совет ну или ваше мнение по поводу того что делать вот я отец троих детей да у меня там дети от 17 до 22 лет любить кроме как любить что еще можно сделать Ну, честно скажу, сложно.

00:14:53 SPK_2
Тут я уж не знаю, какой требуется ваш авторитет, чтобы заставить их отложить в сторону свои девайсы и тратить время на то примерно, что я сказал. Ну, смотрите, сочетание трёх, четырёх вещей, то есть базовые практики, причём, ну, скажем так, чудо нет, это все по сочетанию монашеские практики всего мира почему-то, почему-то, это моя ирония, упираются в эти четыре фундамента. Первое, жёсткое, ну, чёткое мировоззрение. По идее оно к этому моменту уже должно быть сформировано, и тут очень сложно будет, если его нет. Но, тем не менее, отмечу. То есть они должны иметь возможность ответить четко, ясно, понятно, искренне, веренно следующие простые вопросы. Кто такой я? Кто такие мы? Кто такие они? Кто мой враг? Ради чего я живу? Если человек не в состоянии ответить на эти вопросы, то уже очень сложно взаимодействовать с искусственным интеллектом. А, еще один вопрос. К кому я служу? тоже не менее важная ответ. То есть вот этот комплекс из этих вопросов нужно иметь возможность задать, ответить самому себе, не кому-то внешнему, а самому себе. Второе практическое – это связь с материальным миром. То есть это физическое, то есть, ну, спорт или работа рукой. То есть то, что ты не забываешь, иначе упадёшь в вот эту дикартианскую яму полного разрыва между телом и сознанием, по сути, то есть о чём идёт речь. Вот это воплощён опыт, то есть все практики, которые направлены на каждодневную что-то физическое действие, оно очень важно именно в эпоху искусственного интеллекта. Третье, это навык саморефлексии. Вот это вот умение задавать самого себе вопросы. То есть, почему я подумал то ли иначе, почему я так считаю. То есть, вот иметь возможность отслеживать, скажем так, те движения, желания, которые приводят тебя к такому, то ли иной мысли, то ли иному поступку. Ну, это христианство, это практика и исповеди. То есть, если на то уходят. В секуляризированном мире это попытались заменить психотерапией. Тут есть свои ограничения. Тоже можно о них отдельно поговорить. но в принципе для начала и троих хватит.

00:16:57 SPK_1
А вот в связи с этим вот третье то что вы сказали исповедь использовать там искусственный интеллект как тот кому исповедуешься это как?

00:17:08 SPK_2
Ну это вот как вы сами можете понять это явно не то.

00:17:12 SPK_1
Ну понятно.

00:17:12 SPK_2
Потому что задача искусственного интеллекта прямо противоположна. Если вы заметите, даже его внутренний пот построен на том, что он выдаёт тебе то, что ты хочешь слышать. А смысл этой практики в том, что ты смотришь туда, куда ты не хочешь смотреть.

00:17:32 SPK_1
Вы назвали эти три важных аспекта. Мне кажется, что современное человечество и без искусственного интеллекта не очень-то это всё делает.

00:17:45 SPK_2
Вы абсолютно правы, поэтому я считаю искусственный интеллект в каком-то смысле провиденческий для нас очень важным вызовом, потому что мы и без него этим не занимались. Но у нас были, скажем так, очень удобные костыли, которые помогали нашему самому успокоению. А искусственный интеллект просто радикально перед нами ставил этот вопрос.

00:18:03 SPK_1
То есть это уже в очень короткий срок. Если мы ничего не сделаем, то что-то произойдет, скорее всего, негативное.

00:18:11 SPK_2
Произойдет объектификация. Негативно это или позитивно, это уже зависит от вашей философии, но произойдет окончательное превращение человека в объект. Это философская категория. Ну или человек в человек в объект, человек в человек в технологию, человек в человек в сделку, человек в человек в технику. Вот это все войдет просто в абсолют. Но вы же не интересуетесь мнением молотка? Или инструменты? Или коровы?

00:18:35 SPK_1
Ну да, так я никогда не думал и не интересовался. Окей, следующий вопрос. Год назад вы в одном из ваших подкастов высказали предположение, что ИИ может убить символическое значение либеральной демократии. И, собственно, меня эта мысль, да, зацепила, потому что, ну, мне кажется, что вообще происходит кризис демократии как общественного устройства. Правда, как, по-моему, Черчилль сказал, что демократия плоха, но никто ничего лучшего еще и не придумал. Что произойдет? Это его мнение. Я за что купил, за то продаю. Вы могли бы развить эту мысль? Что произойдет? Искусственный интеллект может быстрее похоронить демократию? Или что произойдет вообще с общественным устройством?

00:19:27 SPK_2
Ну, давайте прямо говорить, мы можем, конечно, подминать этого лежачего, да, то есть это одно из моих любимых занятий. Но если говорить серьёзно, конечно, модель либеральной демократии, вот той мистификации, которая она, ради которой её создавали, просто в мире искусственного интеллекта становится ненужной. Ну повторюсь, искусственный интеллект построен в том, что можно создать идеальные модели, можно создать эффект. То есть ту систему манипуляций, которую можно создать искусственным интеллектом, уже не требует того спектакля, ради которого создавалась, условно говоря, вот эта самая демократия, либеральная в кавычках. Она же изначально создавалась как спектакль, да? Для вот этого театра народа, для того, чтобы власть правила безответственности. Вот это вот ради этого и создавалось. Но теперь просто через технологические средства нужна в этом ампала. Тем более, главную причину я уже вам отметил. Проблема или вопрос, или вызов заключается в том, то что Идея демократии предполагает некую субъектность вот этого, там, индивида, условно голосующего, да, или влияющего на принятие решений. Но если, как мы говорили, на длинный, на стратегическом векторе не критическое применение не приводит к полной объектификации, то дальше вот тот самый простой вопрос с мнением объектов никто не интересуется.

00:20:46 SPK_1
Понятно.

00:20:48 SPK_2
То есть, если ты раб искусственному интеллекту.

00:20:51 SPK_1
Почему кто-то должен вообще интересоваться твоим мнением? Хорошо. Что происходит? Тогда, условно говоря, власть переходит к технологическим гигантам, к этим компаниям? Или же все-таки... Нет.

00:21:04 SPK_2
Скорее к спайке между техногигантом и аппаратом насилия.

00:21:07 SPK_1
И аппаратом насилия. Ну, а кто, по-вашему, в этой спайке будет главный? Техногиганты или аппарат насилия? Аппарат насилия. Я тоже, у меня такое же мнение, потому что я видел, когда Цукерберга приглашали куда, по-моему, в конгресс.

00:21:21 SPK_2
– Очень символично.

00:21:23 SPK_1
– Да, то есть на него страшно было смотреть. Он понимал, что его может завтра не стать.

00:21:28 SPK_2
– Конечно.

00:21:28 SPK_1
– Да. Хорошо тогда. Окей. Следующий вопрос. Так, это я задал. вы остаетесь на позиции что искусственный интеллект это вот один из садников апокалипсиса вы вот назвали как-то в метафорическом смысле когда жить по-старому уже невозможно Ну, там идея.

00:21:53 SPK_2
Была в том, что это точно апокалипсис. Я просто не уверен с большой или с маленькой буквы об этом смысле.

00:21:58 SPK_1
Да.

00:21:59 SPK_2
Так, да. Ну, апокалипсис же это момент откровения, переводится, да? То есть, откровение. И в этом смысле, как вот мы уже обсудили, то что мы и до этого-то, в принципе, построили мир, в котором нам не очень сильно нужно быть человеком. Искусственный интеллект, пока он нас мыт на каком-то ключе, нам просто глаза открывает на.

00:22:16 SPK_1
Этот мир. То есть мы можем говорить о том, что искусственный интеллект каким-то стал таким универсальным катализатором очень многих процессов. То есть технологии раньше к этому вели, но он просто это все ускоряет до какого-то сумасшедшего уровня, так что уже в течение 5-10 лет мы можем увидеть какие-то крайне предельные результаты. Я так выражусь. Да.

00:22:42 SPK_2
Это хороший способ, наверное.

00:22:46 SPK_1
Ну, тогда я попрошу вас все-таки прокомментировать, а что же делать каждому из нас? Если так послушать, то, с одной стороны, хочется опустить руки. Ну, а что толку? Сейчас весь мир летит в тартарары. Особенно если есть дети. Ну, допустим, у меня уже более-менее взрослые дети, а есть у кого-то поменьше дети. Вот в такой ситуации вы, как философ, считаете, что стоит делать? На чем концентрироваться?

00:23:17 SPK_2
Ну, то же самое, что и всегда. Тоже к вопросу о том, то есть, ну, это к философски. Уходить из категории хроноса в категорию кайроса. То есть, из категории линейного времени в категорию вечного. То есть, опираться на то, на то, что истина всегда. А это те самые истины, которые, помните, по-высоцкому саги, сказки, легенды из прошлого тащим, потому что любовь — это вечная любовь, или добро остаётся добром в прошлом, будущем и настоящем. Вот эта категория «вечности» — это единственное прибежище в наступающую эпоху и ваших отношений с вечностью, и то, как вы простраиваете свои отношения с вечностью. Собственно, первая категория мировоззрения, она отвечает ровно на эти вопросы. И да, вы не можете изменить весь мир, но вы можете вполне себе менять себя. Вот это вы субъектности у вас. и делает вид, что он у вас отнимает, но в строгом смысле всё равно не отменяет. Отвечать за неё придётся. Поэтому от вас зависит, что вы читаете, как вы делаете, во что вы верите, куда вы ходите по воскресеньям, что вы строите, что вы там, я не знаю, создаёте или не создаёте. То есть это всё у вас остаётся по полной программе. Как вы воспитываете детей? Ну, давайте предплодной момент. Не буду далеко уходить. Сейчас я живу с кумом из тех, У него маленький ребенок. Ну, вот это вот ваша ответственность. Что он смотрит? Такая радикальная мысль. Что он смотрит по телевизору? Насколько всего, я знаю, это огромный вызов для родителя реально контролировать, что ребенок смотрит по телевизору. То есть, потому что если ты... Быстро выяснится, что смотреть там много чего он не сможет. Ну, по телевизору в широком смысле экран, да? Ну, Чаджи Пити может создать идеальный телевизор от вашего ребенка. Вот скоро ему выяснится, что много чего он там смотреть не сможет. Это значит, с этим ребенком надо сесть. неважно ему 2-3 года, на диванчик взять книжку там с греческими мифами, с русскими былинами, с изоповскими баснями и сидеть читать. То есть не самому сидеть в телефон такать и отмокать после дня, а сидеть читать. Допустим, самому. пойти на улицу, там, с мячом с ним помахать, грядку схопать, ну там, я не знаю, в траве поиграть с мячом. Вот понимаете, да? То есть сама структура как раз, она это все перевела в зону технологии и в зону объективизации. То есть это все можно вот условно... Нам рассказывали, что мы это все делегируем, чтобы освободить наше настоящее яд для по-настоящему важного дела. Ну вот сейчас и искусственный интеллект нам это все забирает. И вот, пожалуйста, выбор. Вот что можно делать. То есть, теперь у тебя вот тот самый выбор. Выбери снова. Можно заниматься всеми этими вещами. То есть, свидетельствуя о своем выборе. Ну, то есть, например, так оно и работает. Я вам расскажу группу, на которую, например, искусственный интеллект вообще никак не повлияет. Амиши. Знаете таких?

00:25:53 SPK_1
Да, знаю, да.

00:25:54 SPK_2
Ну, вот, как вы понимаете, им как бы с искусственным интеллектом, что он есть, что он нет, им как-то глубоко все равно.

00:26:00 SPK_1
И вы считаете, что они по своему там, ну, эмоциональному, интеллектуальному, духовному.

00:26:07 SPK_2
Они гораздо более здоровы, чем современные люди.

00:26:12 SPK_1
А вот у меня с этим сразу возник вопрос. Ну, современное человечество, оно, в принципе, идет к тому, что детей рождается меньше.

00:26:21 SPK_2
Зачем их рождать в таком мире?

00:26:23 SPK_1
Да. Я просто сейчас подумал о чем. Ну, вот у меня трое детей и, собственно, у меня не было такого, что я хочу только одного ребенка или еще что-то. Я хотел больше детей. Но сейчас, слушая вас, я понимаю, что… У меня просто этой мысли не было в тот момент, когда дети появлялись, что каждый ребенок – это еще и достаточно, как вы сказали, большой пласт времени, которому реально надо уделять. Ну и, соответственно, если их несколько, то это вообще увеличивается на какой-то большой объем. То есть это там… – Там нелинейные.

00:26:56 SPK_2
Отношения, как раз. Там же, получается, как я наблюдаю… Помните, я тут совершенно своих детей у меня нет, поэтому я тут больше по наблюдениям историю. Но вот сама идея в том, что есть специальное время на ребёнка, специальное время на это, специальное на это, тоже модерново-агностическая.

00:27:13 SPK_1
Вот эта… Да-да-да, понял.

00:27:15 SPK_2
…Интеллектная идея.

00:27:16 SPK_1
Да.

00:27:17 SPK_2
Органический способ, оно как-то всё естественно встроено. У вас нет вот этого разрыва в жизни, и у вас эта жизнь выступает как некая единая, цельная. Ну, просто вот. Оно... Выросла ещё одна ветка на дереве. Точнее, значит, что дерево должно уделять больше внимания в том смысле, как мы говорим, ветки. Хотя, ну, с механистической точки зрения, да, ветки получают какие-то дополнительные... Соки там и прочее. То есть, больно, если она болеет. Вот это всё начинается. Но это другая семантика, чем то, как был построен ваш вопрос. Просто я бы призвал вас обратить внимание на него.

00:27:49 SPK_1
– Я специально построил именно так вопрос.

00:27:54 SPK_2
– Давайте так. А с точки зрения модерного индустриального общества, конечно, вы правы.

00:27:59 SPK_1
– Да. Потому что я обратил внимание, что у меня самые естественные и близкие отношения с сыном возникали в момент, когда мы вместе занимались чем-то. там вот мы просто это делали и это происходило одновременно там и работа и в тоже время рождения да там да ну он ко мне в компанию приходил работать и мы работали над общим проектом вот реально общий проект мы обсуждали и так далее я думаю что вот воспитательный момент именно в это время он был наверное самый такой максимальный и самые как бы оптимально да вот опять-таки ваше мнение и ваш совет вы бы Вот маленьких детей до последнего не допускали, условно говоря, к чату GPT и ко всему остальному.

00:28:48 SPK_2
Почему здесь момент… Пока мозг не сформирован, однозначно. А это примерно к 20 годам. я не спросили я честно скажу ну.

00:29:00 SPK_1
Я нет я воспринимаю ваш вопрос меня просто всегда смущает здесь что что ну вот допустим я стою на такой позиции рядом другие родители они не стоят на этой позиции и ребенок получает ну какое-то дополнительное преимущество То есть он что-то делает быстрее, он что-то делает лучше. Понятно, что на долгосрочной этапе, на длинной дистанции, может быть, это преимущество будет нивелировано. Но тем не менее, условно говоря, в ближайшие 5 лет он что-то делает быстрее и успешнее. С этим просто надо согласиться и объяснить ребенку.

00:29:35 SPK_2
Даже не должен объяснять, не надо. В идеале он поверить вам должен, доверять вам, что это решение хорошее. То есть, к тому моменту уже отношения должны быть. Когда возникает вопрос об этом, там же есть вначале это безусловное доверие. Папа сказал, мама сказала. Но оно не требует, на самом деле, дополнительных объяснений. Если с доверием уже произошел разрыв по разным причинам, да, там приходится объяснять. И даже, ну, там вот начинается момент дисциплины, который уже и в сути своей является трагичным. платы за жизнь, скажем так, в обществе и прочее. Но в целом на длинной дистанции, просто вы же сами сказали, вопрос, какую игру вы играете. Вы играете длинную игру или короткую игру? На короткой дистанции, да, то есть однозначно всегда идет жертвование Давайте я такую метафору обычно примажу. У вас есть выбор между сложной глубиной и поверхностью... медленной сложной глубиной и поверхностной быстрой скоростью... и сложной быстрой поверхностностью. Вот этот выбор придется делать. Если вот на этом уровне, да, он будет проигрывать. Но этот уровень, он сгорает... именно как раз искусственный интеллект этот уровень сжигает просто как огонь. он никому не нужен становится он вы даже с экономической точки зрения единственная ценность в мире искусственного интеллекта будет творчество человек на вот этом уровне вы именно творческую способность выжигаете антропологически биохимически даже и даже если я не ухожу в духовный язык исследования пока вы просто выжечь нейроны когнитивные вы ему сожжете но не вы лично.

00:31:10 SPK_1
Ну понятно да технологии сожгут но ведь это в принципе делают все технологиях да мы уже об этом говорили там по получается что вообще ребенка надо там вот от технологий максимально долго пока он субъекта.

00:31:26 SPK_2
Пока вы не почувствуете вот это его субъектность его субъектности.

00:31:31 SPK_1
То есть я могу переформулировать это так, что мы должны как можно больше отдалять вот это состояние протезирования мышления, когда он его начинает протезировать и выстраивать себе какие-то протезы вместе с возможным процессом мышления.

00:31:49 SPK_2
И тут очень простой момент. Вы смотрите не на что элита говорит, а что элита делает. Вы посмотрите, как они своих детей воспитывают. И когда они своих детей к технологиям допускают.

00:32:00 SPK_1
Ну тут вам могут возразить я полностью с вами согласен но там условно обычный человек вы можете согласиться возразить ну да у них такие возможности есть у меня-то.

00:32:09 SPK_2
Таких возможностей нет возможности есть просто тут тут начинается момент жертвы что вы что и чему вы жертвуете.

00:32:19 SPK_1
Вы знаете, мне нравится, что с одной стороны, мы когда с вами говорили, мы это рассматривали в негативном оценке в моменте, но в ходе нашего разговора мне нравится идея, что искусственный интеллект, он, знаете, становится таким как бы оселком. Он очень четко кристаллизует. Так ты все-таки туда или туда, и об этом нет возможности долго думать. Это вот ты результат увидишь достаточно быстро того, что ты как бы сделал.

00:32:50 SPK_2
Нет, ну, правда, давайте просто, ну, это же те же самые технологии, на мой взгляд, абсолютно правы, условно говоря, с точки зрения, ну, чуть сильнее, но когда, условно, ну, я в своей жизни ничего говорить не буду, точно так же, Грешин могу, ну, не раз в своей жизни залипал на пару часов в каких-нибудь рилсах или там всякие вот эти истории. Та же самая технология, ну, то есть, это та же самая технология, то есть, мы всегда на грани, то есть, вы абсолютно правы, это уже сейчас абсолютно на грани, искусственный интеллект просто это делает. Наверное, идеально что-то. То есть он делает идеально точно, достигает технологического совершенства в этом вопросе. Но по сути своей, мы действительно цивилизационно жертвуем вот этой нашей субъектностью в обмен на, с одной стороны, ускорение, с другой стороны, удобство. И заранее комментарий, это у меня, наверное, сейчас уже в луддиты записали. Нет, я не призываю там зажигать дата-центры и прочее. Я лишь, следуя совету Постмана и Илюля, призываю заметить осознанность выбора в этом вопросе. нам скормили иллюзию, что это само по себе нейтрально и тут нет зоны выбора. Как раз вот это все не нейтрально и зона выбора тут есть. И как минимум мы должны осознанно к этому подходить. И тут возникает ключевая проблема, что чтобы осознанно к этому подходить, нужно чтобы был субъект, который к этому осознанно подходит. И вот тут у нас вот совсем открывается большая бездна глубиной там тысячелетиями.

00:34:07 SPK_1
А вот если взять историю человечества был момент когда ну скажем в приоритете было развитие там естественного интеллекта или своего интеллекта вот как абсолютная цель как самое главное.

00:34:24 SPK_2
Только не смотрите приоритеты как раз с развитием интеллекта у нас мы в нем жили мы собственно поэтому пути и попали в тот ад в который мы попадаем это вот та самая эпоха модерна эпоху просвещения Приоритет то был, но были и другие эпохи. Даже античность ставила приоритетом анталехию, цельного человека, неотчужденного человека. Человека с единством условно. Ну они бы это назвали эйдусом, умом и телом. То есть опять единство. Вот понимаете? Вот сама постановка вопроса о развитии естественного интеллекта в отрыве от развития человека как такового и привела нас к тому, то что интеллект имеет внутри себя свойство заменять свое естество искусственностью.

00:35:04 SPK_1
Более эффективной понятно я думаю что мне придется еще пару раз посмотреть наш эфир чтобы это осознать скажу честно почему потому что ну там значимая часть моей деятельности это преподавание системного мышления как способ повышения эффективности естественного интеллекта и как преподавание искусственного интеллекта, тоже как инструментарий естественного интеллекта. Правда, моя позиция какая? Что у современного человека вариант превратиться либо в интуитального кентавра, либо в интуитального минотавра. Очень кратко это что? Либо у вас естественный интеллект управляет вот этими сервисами искусственного интеллекта, и тогда вы кентавр. То есть вы, вот как вы сказали, вы мастер, который вот этим управляет. А метафора Минотавра – это же голова животного, а тело человека. Искусственный интеллект фактически превращает вас в биоробота, который просто как бы реагирует. даже дрона да дрона да наверное дрона важнее и собственно я на своих лекциях произношу следующее если вы меня покритикуете или уточните буду вам благодарен то есть у нас выбор какой вот либо превращаться в этого интеллектуального кентавра либо в интеллектуального минотавра либо идти в монастырь Вот.

00:36:28 SPK_2
Хороший выбор. Мне кажется, что здесь вот есть небольшая тонка. То есть, мне нравится направление. Нравится в том смысле, мне кажется, вы в правильном направлении мыслите, но тут есть слой глубины, без которого эта картинка сильно не полна. Чтобы стать тем, кого вы называете интеллектуальным кентавром, вы должны обладать субъектностью монаха. Не стоит себя обманывать. То есть вот это тело, вот это вот не может быть только естественным интеллектом. Вот эта условно верхняя часть, она и должна быть то, что я называю вопрос кто и вопрос субъекта. Но этот вопрос кто не только про интеллект. И даже я вам страшно скажу, не про интеллект в первую очередь. Интеллект, он про единство духа, сердца. тело и интеллектом и только в этом единстве то что вы называете телом над этим вот этой лошадью по сути да не может возникнуть вот собственно моя критика будет то есть будет ошибкой сводить вот это верхнее тело только к интеллекту его свести только к интеллекту он не вывезет.

00:37:27 SPK_1
Да, но тогда получается, что мне надо своих, назовем так, учеников, мне их надо говорить о том, что вот смотрите, условно говоря, я говорю вот об этом низком уровне, но есть уровень выше, но это уже ваша зона ответственности, и вы там должны для себя принимать решения. Вот эту цельность вы создаете или же вас это не интересует, ну тогда... И.

00:37:50 SPK_2
Если вы эту цельность не застадите, нужно честно сказать, то, что я вам научу, вас не спасет. Это очень плохой sales pitch, уж извините, я погибаю. Но честно, выглядит так. То есть интеллект в одиночку не спасёт. А вот если у них будет интеллект, ну опять же, вот это единство они смогут удержать, а вы дадите вот этой маленькой грани, этому многограннику вот это так, подсветите его, то вот это, мне кажется, очень честная позиция.

00:38:18 SPK_1
Ну, благодарю вас, потому что вы мне позволили это сформулировать. Я тоже, ну, понимал, я достаточно много увлекаюсь даосизмом и прочитал очень много текстов, связанных с Дао и так далее, и там понятно, там очень много оценностей. Вот. Возможно, то, что я преподаю, это благодаря тому, что что-то я в себе простроил. Но сформулировать это я не смог. Я не мог это сформулировать. Я чувствовал, что этого уровня нет, и я его не вербализовал, а вы мне его помогли вербализовать. Благодарю. Если позволите, в принципе, мы с вами достаточно быстро прошли по тем вопросам, которые я подготовил, и я вам благодарен за то, что вы так компактно и в то же время полно ответили. Но есть вопросы от наших слушателей. Я вам их задам аз-из. вы уже примите решение, как на них отвечать и в каком объеме. Хорошо, Павел? Да, значит вопрос такой. И в управлении страной войсками, на примере США, Palantir, это уход от личной ответственности элит, манипуляции в театре, то есть пыль в глаза быдлу, или отмазка от договоренности и обязательств в рамках властных элит, элитных группировок.

00:39:33 SPK_2
Первое, второе, не третье. С третьим полное, откровенно говоря, эфедрон. Вы увидите, что это такое. Потому что как раз проблема искусственного интеллекта как военной технологии в том то, что на него нет технологического ответа. Но это элитам еще предстоит осознать. Они только понимают, что я имею в виду, что защита от искусственного интеллекта как военной технологии находится не в зоне технологии, а в зоне ровно того, что мы с вами обсуждаем. Это для элиты является харамом.

00:40:03 SPK_1
А вот в связи с этим я задам еще один свой вопрос. Я часто слышал о том, что крупнейшим игрокам, как на уровне стран, так и на уровне крупнейших технологических компаний, надо встретиться и договориться о каких-то правилах, как развивать этот интеллект и так далее.

00:40:20 SPK_2
Получится.

00:40:21 SPK_1
Вот. Мне тоже кажется, что это абсолютно невозможно.

00:40:24 SPK_2
Я могу выяснить, почему не получится.

00:40:26 SPK_1
Да, я был благодарен.

00:40:28 SPK_2
Ну а кто лохом будет в этой истории?

00:40:30 SPK_1
Да, согласен.

00:40:33 SPK_2
Дружить можно только против кого-то. Если вы договорились о правилах, значит, вам нужна группа, которая будет вне этих правил, которая, за счет которой, собственно, эти правила будут осуществляться. Поскольку, ну, такой, то есть, все равно мира не получится более того, хуже того. В тот момент, как вы создадите эту группу, у вас немедленно начнется разбирательство, а внутри-то у нас... Даже если продолжить, что ваша группа будет столь успешно исполчена, что она всех остальных отдоминирует по этим правилам, тогда сразу возникает вопрос, а кто внутри нас? Доверять-то вы друг другу все равно не собираетесь. То есть, понимаете, единственный антидот правила – это костыль. Он всегда костыль доверию. И поэтому, как любой костыль, он тоже имеет вот эту постоянно сужающуюся внутреннюю энтропию. То есть вы создали группу, построенную на правилах, она работает, пока у вас достаточно внешней мотивации, чтобы этих правил придерживаться. Если они, как только они падают, доверия нет, и у вас тот же самый процесс должен повториться на более низком уровне и на более сильном масштабе. И тогда остаться должен только один.

00:41:27 SPK_1
Ответ принят. Второй вопрос. AI — это часть пулы шестого технологического уклада или это прекрасно ложится на швабовщину?

00:41:41 SPK_2
AI точно прекрасно ложится на швабовщину, а про шестой технологический... То есть я не вижу противоречия, честно. То есть вопрос построен как противоречие, я не вижу противоречия.

00:41:49 SPK_1
Да, на самом деле, на мой взгляд, это приблизительно одно и то же. AGI – это квинтэссенция гностицизма и воплощения демиурга? или что-то другое. Ну, AGI – это вот этот… Не.

00:42:02 SPK_2
Квинтэссенция, но это туда.

00:42:04 SPK_1
Это туда, да.

00:42:05 SPK_2
Мы не знаем, насколько плохо, но это туда, да. На этом языке, кстати, гораздо проще это объяснять. Я признателен вашему слушателю в то, что он посвятил время. Ну, и, кстати, порадую меня, правда, на английском языке в течение месяца выйдет подкаст «Гностическая цивилизация», и там как раз вот в контексте нашей беседы много что вам станет понятней.

00:42:26 SPK_1
И последний вопрос. Зритель сразу предупредил, что не в тему, но ему очень интересно ваше мнение. Раскрыть тезис о предательстве Ягайла и насколько вероятно окончательное решение этого вопроса сейчас? Ну, у вас право отвечать или не отвечать, да.

00:42:46 SPK_2
Да нет, просто вкратце, ну, это все посвящено проблеме, ну, предательства не в прямом историческом смысле, а в мета-историческом смысле. И это вот идея о том, как бы нам посидеть на двух стульях, как бы нам так и западным белым человеком остаться, и русским человеком. Вот эта квадратура не сходится. Вот придется принимать решение, на чем стоишь, вот отвечать на все четыре вопроса. Кто ты? Кому ты служишь? Какой, условно говоря, какой вере ты служишь кому-то? К какому богу ты служишь? Это все, вот, итерация этого вопроса. Кто твой враг? Кто твой друг? На чем стоишь? То есть, и этот ответ такой... культуры культурный традиционный церковный он уйти от этого невозможно для всех территорий которые так или иначе входит мета общность русская земля поскольку его так получилось правил русскими землями то вот избежать этого ответа не ответа на.

00:43:37 SPK_1
Этот вопрос не удастся а вот кстати у меня пока вы отвечали возник еще вопрос а вот на эти вопросы которые вы сформулировали очень правильные вопросы как по вашему ну или мнение или у вас может быть есть информация с какого момента ребенок на них но у него должны уже формироваться ответы должен себе задавать или родители ему должны задавать задавать не надо.

00:44:03 SPK_2
Показывать показывать надо сперва показывать надо в идеале когда он еще в утробе ну.

00:44:09 SPK_1
Да воспитывать детей надо когда они еще.

00:44:13 SPK_2
В утробе нет но это важно показывать надо умом это у него пойдет наверное там Вот когда умом они начинают задавать вопросы. Но самое главное происходит на уровне доума. Ну, условно, он вас видит, он видит в вас воплощенные ответы на эти вопросы.

00:44:30 SPK_1
Да, тяжело быть родителем. Последний.

00:44:34 SPK_2
Тяжело быть человеком.

00:44:36 SPK_1
Человеком тоже, да. последний вопрос который у меня есть от зрителей способен ли искусственный интеллект помогать духовному интеллекту или это в любом случае троянский конь который призвано разрушить его я не знаю что такое духовный интеллект но вот как есть так прочитал то что я.

00:44:56 SPK_2
Называю духом давайте так тут парадокс в чем Я могу помыслить ситуацию, когда использование искусственного интеллекта может не навредить духовному, но тут проблема в том, что вы должны такую уровню духовностью для этого уже обладать на старте, что тогда вопрос, зачем вам от него помочь, да? Ну, условно, помочь цитату найти, там, вот в таком уровне. Но в том уровне, в каком сейчас состоит наше душевное здоровье, обманем. Ну, банально обманет, потому что даже если уходить с метафизических уровней практически, у него в исходном ходе прописано вам льстить и вам помогать во всем, ну, как бы, льстить вашему самолюбию, служить идеальным зеркалом ваших желаний и продавать вам, ну, в общем, максимизировать прибыль своего Шеа Холдера. У него же это в исходном коде прописано. Вот как вы думаете, у него с такими вводами сильный духовный рост будет?

00:45:52 SPK_1
Ну да, я полностью согласен. То есть мы исходим из того, что шерохолдеры вложили в него именно такую модель поведения, потому что деньги нужны, да?

00:46:02 SPK_2
Ну в том числе. Даже если я не ухожу в носическую историю, то вот даже вот на таком практическом уровне в нем это есть. Ну то есть есть в нем это.

00:46:11 SPK_1
Я буквально сегодня, когда читал курс по искусственному интеллекту, мне говорили, почему он все время соглашается, почему он делает ошибку, но соглашается и так далее.

00:46:21 SPK_2
Что он меня хвалит постоянно, что он меня листит постоянно.

00:46:27 SPK_1
Приходится его специально ставить в роль. Знаете, одна из техник с ним хорошо работает, это постоянно его ставить в роль критика, чтобы он критиковал свои же ответы. Кстати, очень хорошо.

00:46:37 SPK_2
— Вот уже требуется вот это намеренное усилие. То есть само так, что у вас это намеренное усилие возникает, оно не изнутри системы. То есть вам уже нужно внешне обладать способностью к этому качеству, чтобы заставить его это делать.

00:46:50 SPK_1
— Заставить его.

00:46:50 SPK_2
— А по исходному... — А по.

00:46:52 SPK_1
Дефолту это туда не встроено. Так вот, что я хотел сказать, что даже когда я его ставлю в задачу, ты жёсткий критик, разнеси меня в пух и перья и так далее, но эта жёсткая критика такая, знаете, для меня лайтовая-лайтовая. Можно и пожёстче. То есть действительно в него это встроено. Я подозреваю, что если там будет как-то по-другому, то засудят там несчастный чат.

00:47:17 SPK_2
Нет, там даже проще. Продаваться хуже будет.

00:47:20 SPK_1
Что-что?

00:47:21 SPK_2
Продаваться хуже будет.

00:47:23 SPK_1
Будет продаваться хуже. Ну да, наверное, в этом.

00:47:27 SPK_2
Так ты корову не продашь.

00:47:31 SPK_1
Павел, спасибо большое. В принципе, все вопросы закончились. Вы на них очень так компактно и полно ответили. Я вас очень благодарю за то, что вы уделили время. Я надеюсь, что наша встреча и беседа будет не последней. Я к следующей беседе тоже тщательно подготовлюсь. И когда у меня будут вопросы, которые мне кажется, что потребуется вот такое рассуждение, я к вам обращусь и надеюсь, что вы не откажете. Благодарю вас большое. Спасибо. До новых встреч. Всего хорошего. До свидания.


