00:00:00 SPK_1
Компьютер. Ну что ж, да, прежде чем мы начнем, Павел, кстати, забыл еще задать вопрос.

00:00:10 SPK_1
Мы как будем это позиционировать, как продолжение наших подкастов или все-таки это будет отдельное у нас видео?

00:00:18 SPK_2
Я думаю, здесь лишнее позиционирование в отдельную коробочку на данный момент преждевременно.

00:00:25 SPK_2
Мы просто делаем интересные разговоры видео и продолжаем встречи на наших ресурсах.

00:00:32 SPK_1
Так, хорошо. Тогда, что ж, начнем. Три, два, один, камера, запись. Здравствуйте, друзья!

00:00:44 SPK_1
В эфире необычный выпуск ведущих подкаста «В поисках смысла» Евгения Голуба, Павла Щелина, и сегодня с нами приглашённый эксперт Алиса Ким.

00:00:59 SPK_1
Мы решили записать этот выпуск, так как первый раз мы затронули тему искусственного интеллекта, а сегодня речь пойдёт о нём.

00:01:09 SPK_1
Примерно год назад, может быть, немного больше, и с тех пор многое изменилось.

00:01:15 SPK_1
Я бы так сказал, что изменилось практически всё.

00:01:18 SPK_1
И для того, чтобы осмыслить происходящее, нам уже не хватает собственного понимания.

00:01:26 SPK_1
Мы подозреваем себя в предвзятости. Для этого мы пригласили Алису.

00:01:31 SPK_1
Алиса — эксперт в области искусственного интеллекта.

00:01:40 SPK_1
Так, минуточку, я выключу свою Алису, потому что каждый раз на слово «Алиса» она будет включаться.

00:01:46 SPK_3
Есть такая партия, да.

00:01:52 SPK_2
Рад видеть, если по-честному.

00:01:55 SPK_3
Да, взаимно.

00:01:58 SPK_3
Кстати, ковёр не дооценивайте, я думаю, что уже есть целое течение по интерпретации вашего бэкграунда.

00:02:05 SPK_3
Я думаю, что ковёр уже — это там целое направление. Так в чём смысл ковра в творчестве Павла?

00:02:13 SPK_1
Я говорю «Алиса» и такой «Эксперт». Журнал такой. На чём мы остановились, друзья мои?

00:02:19 SPK_1
Хорошо, что мы записываемся.

00:02:21 SPK_2
Представляешь, ты Алису-то представлял, родной.

00:02:23 SPK_1
Итак, мы пригласили Алису Ким, кандидата наук, эксперта по искусственному интеллекту.

00:02:30 SPK_1
Алиса занималась академическими исследованиями в Гумбольд-Университете, точнее в Университете Гумбольда и в Стэнфордском университете.

00:02:40 SPK_1
Алиса разрабатывала языковые модели в AWS, Amazon, что-то там, как оно дальше?

00:02:47 SPK_2
Веб-сервис.

00:02:48 SPK_1
Веб-сервис.

00:02:49 SPK_1
Ну и, в общем, последние 10 лет Алиса занимается внедрением искусственного интеллекта в разного рода системах, в стартапах и крупных корпорациях.

00:02:59 SPK_1
Поэтому, ну, кому как ни к Алисе нам прийти с нашими вопросами и недоумениями.

00:03:06 SPK_1
Ну что ж, начнем потихонечку. Итак.

00:03:10 SPK_1
Я предложил сегодня разделить видео или роли в нашей встрече следующим образом.

00:03:17 SPK_1
Как уже понятно, Алиса — наш эксперт, Павел — философ.

00:03:21 SPK_1
Ну а я буду выступать сегодня в роли обычного пользователя разного рода и помощников, обычного обывателя, которых много и у которых есть простые и незамысловатые вопросы.

00:03:35 SPK_1
Начну я с этого такого простого вопроса к Алисе.

00:03:40 SPK_1
Сегодня уже очень многие, включая меня, не мыслят в своей жизни без помощников, как мы их называем.

00:03:50 SPK_1
У меня при запуске браузера запускается 6 штук сразу.

00:03:58 SPK_1
И многие сейчас уже, собственно, ищут даже продукты через искусственный интеллект, через разного рода помощников.

00:04:09 SPK_1
Так вот, вопрос следующего рода. Все-таки это полезная штука или за этим кроется что-то еще?

00:04:21 SPK_1
Как вы считаете, насколько нагружены сегодняшние помощники скрытыми какими-то функциями, скрытыми намерениями с их создателей?

00:04:34 SPK_1
Есть ли подвох в этой технологии?

00:04:39 SPK_3
Наверное, начну с занудного полезного для кого и для чего.

00:04:45 SPK_3
Для нас, как для пользователей, в наших жизненных целях, безусловно, на мой взгляд, полезная вещь.

00:04:53 SPK_3
Но мы с вами находимся в такой сложной ситуации, когда абсолютно всё в этом продукте, по сути, оптимизировано для того, чтобы мы чуть-чуть сбились с курса, забыли о том, зачем мы делаем то, что мы делаем, и как это работает.

00:05:10 SPK_3
Тут, если бы я должна была ответить на вопрос классический, ну так это хорошая вещь или плохая, я бы сказала.

00:05:19 SPK_3
Хорошая, если мы будем пользоваться ей осознанно.

00:05:23 SPK_3
И на этой части обычно все юзеры, я в том числе, говорят, ну если осознанно, то это уже слишком сложно.

00:05:33 SPK_3
Что касается нагруженности, тут, на мой взгляд, всё банально и немножко грустно.

00:05:40 SPK_3
Практически всё о том, как создаются эти помощники, зачем, с какими ограничениями, всё прописано, всё открыто.

00:05:51 SPK_3
Я думаю, что там скрытых смыслов и скрытых идей тайных помыслов довольно мало.

00:05:58 SPK_3
Другое дело, что мы как... Вы знаете, как никто не считает правила пользования.

00:06:03 SPK_3
Все всегда все принимают и рад с этим дальше пользоваться.

00:06:07 SPK_3
Другое дело, что мы с вами, наверное, никогда еще не сталкивались с инструментом, по сути, телевизорами, чайниками, любыми инструментами, доступными для рядового пользователя, которые были бы настолько сложны и настолько обманчивы, настолько сделаны для того, чтобы максимально с нашей головушкой помериться силами, запутать и вести в искус.

00:06:46 SPK_3
Изначально же все эти системы, когда они стали популярны, никогда не стали точными, никогда не стали какими-то правильными с точки зрения даваемых ответов, а тогда, когда они стали настолько похожи на настоящего собеседника, что мы прямо вот включились в это.

00:07:09 SPK_3
К сожалению, эволюционно мы очень... Мы и так-то любим всё антропоморфизировать.

00:07:17 SPK_3
С компьютерами разговариваем, с телевизорами даём имена машинам и так далее.

00:07:21 SPK_3
А тут оно ещё и разговаривает, и отвечает, и ещё и учится тому, что мы любим и не любим, и запоминает нас.

00:07:28 SPK_3
Ну, то есть тут не начать с этим взаимодействовать нас и помощником, не как инструментом, ну, практически нереально.

00:07:35 SPK_3
Даже если вот вы супер в подсознанке, скорее всего, там, да, через N дней и N пользований вы уже немножко забудете про то, как бы, да, зачем это было сделано, как это работает и так далее.

00:07:48 SPK_3
На мой взгляд, пользы этого можно извлечь очень много.

00:07:51 SPK_3
Другое дело, что с такими инструментами прямо вот совсем-совсем нельзя забывать, зачем я это делаю, какие у этого ограничения.

00:08:03 SPK_3
Они все прописаны, они все понятные, но кроме тех, которые не прописаны, по идее, должны быть понятны любому человеку.

00:08:12 SPK_3
Это коммерческий инструмент.

00:08:15 SPK_3
Наверное, там есть какая-то доля того, что на вас хотят заработать, и ваше всеобщее благо мира, наверное, там не единственная цель.

00:08:24 SPK_3
То есть, скорее всего, этот компонент тоже есть, но мы про это не очень любим помнить.

00:08:28 SPK_3
А это влияет на то, как дальше развиваются эти системы. Вот такой, мой будет ответ. То есть.

00:08:37 SPK_1
Штука, как любая технология, всегда имеет скажу иначе искусственный интеллект как любой инструмент может быть использован по прямому назначению его плага или как кухонный нож можно резать мясо можно зарезать человека как технология книгопечатания можно печатать библию а можно порно рисуночки сдавать и здесь уже вопрос у меня к павлу Мы говорили с тобой год, наверное, и много больше назад о том, что движется, кажется, такое время, надвигаются времена, когда многое из того, что делает человека человеком, Годит, скорее всего, передано на аутсорс, искусственному интеллекту, и мы тогда с тобой видели риски того, что вот это вот творческое начало, чувства, эмоции начнут автоматизироваться, и, соответственно, в этой части есть риски для людей потерять свой компонент человечности, что ли.

00:09:57 SPK_1
Что ты думаешь по этому поводу?

00:10:01 SPK_2
Еще раз всем здравствуйте. Ну, думаю много чего. Тут даже не знаешь с какого конца подбираться.

00:10:08 SPK_2
Первое, все-таки сделаю базовые комментарии для фиксации собственной позиции по твоему преамбуле.

00:10:16 SPK_2
Про вот кухонный нож и прочую всю вот эту историю.

00:10:20 SPK_2
Дело в том, что вот с этой позиции я философски не согласен.

00:10:24 SPK_2
Мне представляется, что само представление существования такого феномена, как нейтральная технология, является глубоким заблуждением.

00:10:33 SPK_2
Не существует такого феномена, как нейтральность технологии.

00:10:37 SPK_2
С самим фактом своего существования технология не нейтральна. Она создает ассиметрию.

00:10:44 SPK_2
Банально между теми, кто технологией пользоваться умеет и кто технологией пользоваться не умеют.

00:10:51 SPK_2
Те, кто технологией пользоваться умеют, получают дополнительные ресурсы, власть, способ взаимодействия с миром относительно тех, кто ей не пользуется.

00:11:02 SPK_2
эту асимметрию ты никаким образом... Вот это и есть собственно сама технологическая асимметрия.

00:11:09 SPK_2
То, что ты говоришь уже про волевой этический выбор субъекта, использующий технологию, это следующий этап, это следующий уровень.

00:11:17 SPK_2
Но сначала есть вот этот базовый уровень, что самим фактом своего бытия технология мир меняет.

00:11:24 SPK_2
И вот наше представление о ней как о некой нейтральности это очень хороший sales point для любого, скажем так, маркетолога, но с философской точки зрения просто он неадекват.

00:11:35 SPK_2
Это первый момент. Второй момент связан с... Подожди, минуточку, ты.

00:11:39 SPK_1
Же знаешь, я обычно тебя прерываю, уже прости, но ты знаешь, мне кажется, нужно объяснить, что такое твой тезис о том, что самим фактом существования технология меняет мир.

00:11:53 SPK_1
Логическая связь здесь не очевидна, по крайней мере, для меня.

00:11:59 SPK_2
Ну, давай самое простое.

00:12:01 SPK_2
Вот если пока этой технологии не было, у тебя была определенная культура и определенные, если условно, паттерны, уж простите, не знаю, как там, вечно...

00:12:11 SPK_2
независимость. Закономерности некоторые.

00:12:14 SPK_2
Закономерности отношений между людьми, отношений экономические, социальные, политические и так далее, как ты ни крути.

00:12:23 SPK_2
Вот когда технология появилась, она стала фактором всех этих отношений просто по факту своего появления.

00:12:29 SPK_2
Еще никакой воли нет, но она создала дополнительные возможности.

00:12:33 SPK_2
Повторюсь, главная эта возможность, я ее назвал, это возможность к власти.

00:12:38 SPK_2
Любая технология содержит в себе заряд к власти. Но это логично.

00:12:43 SPK_2
Если бы она его не содержала, ее бы никто не создал. Это вот очень важно понимать.

00:12:47 SPK_2
То, что в нашем культуре технология всегда создается, на самом деле, с неким зарядом к власти.

00:12:56 SPK_2
Тот, кто, банально, власть работы, в нашем конкретном примере, власть манипулирования, власть работы с данными.

00:13:02 SPK_2
власть, производство дополнительного материального ресурса и так далее. Это все властные отношения.

00:13:08 SPK_2
И вот эта технология, ты можешь сказать, если тебе уточнить, ну до поры до времени можно сказать, что она создается с технологией как минимум потенциальной власти.

00:13:16 SPK_2
То есть она лежит и спит, и да, требуется волевой субъект, чтобы эту власть активизировать, но тем не менее потенциал-то уже создан самим фактом ее появления.

00:13:24 SPK_2
То есть некая статус-кво оказалась нарушена. Все.

00:13:27 SPK_2
То есть изобретение автомобиля, вне зависимости от намерений конкретного изводчика, конкретного водителя или производства автомобиля, самим фактом, называя технологией, является угрозой, условно говоря, для коневодов.

00:13:40 SPK_2
Она меняет эти отношения автоматически, просто по факту своего появления.

00:13:46 SPK_1
Технология может существовать, продукта может не быть.

00:13:51 SPK_2
Я поэтому уточнил про потенциальное. Ну, давай так, ты прав. Как минимум потенциальное.

00:13:59 SPK_2
С философской точки зрения я веду категорию потенциальное.

00:14:02 SPK_2
изменения, но просто мы живем еще в цивилизации последние 400 лет, где любое потенциальное изменение в зоне технологии прогресса должно быть актуализировано.

00:14:10 SPK_2
У нас нет никаких этических ограничений на любую технологическую актуализацию.

00:14:15 SPK_2
Это, собственно, ради этого модерн мы и создавали.

00:14:18 SPK_1
Мы говорим о том, что в модерне каждая технология прежде всего рассматривается с точки зрения возможности увеличить властный потенциал субъекта, обладающего этой технологией.

00:14:32 SPK_2
Субъекта, обладающего этой технологией, да.

00:14:34 SPK_2
А в любой технологии всегда, и до модерна, и после модерна, и вне модерна, ну всегда содержится увеличение потенциала субъекта.

00:14:43 SPK_2
Ну это понятно. Простой пример.

00:14:45 SPK_1
Усиление, да?

00:14:45 SPK_2
Усиление. Ну я не могу бегать как гепард.

00:14:48 SPK_2
Но с машиной я могу перемещаться со скоростью, которой гепарду и не снилось.

00:14:53 SPK_2
Мой потенциал в категории беганье, она усиливает. Она поэтому и создана.

00:15:00 SPK_1
Теперь, я тебя прервал, может быть, ты сделаешь шаг назад и вернешься к своему первому тезису?

00:15:06 SPK_2
Да. Чтобы я его вспомнил. Он связанный с первым тезисом, и это проблема асимметрии последствий.

00:15:14 SPK_2
Другими словами, это вот был бы мой вопрос к Алисе следующий, если она попробует.

00:15:19 SPK_2
Мне просто интересно, как вообще, есть ли размышления на эту тему.

00:15:23 SPK_2
Приведу пример не с искусственным интеллектом, но близкий.

00:15:26 SPK_2
У нас есть технологии социальных сетей, выпущенные относительно недавно, буквально 15 лет назад.

00:15:33 SPK_2
Сейчас начали выходить исследования Айнейра об изменениях на материальном уровне мозга молодых, особенно детей, подростков, девочек, которые 10 лет выросли на этих технологиях.

00:15:45 SPK_2
Скажем так, исследование, мягко говоря, тревожище. То есть там много разных неприятных последствий.

00:15:52 SPK_2
Но я сейчас говорю не про это. Я говорю про то, что вот у нас есть асимметрия.

00:15:55 SPK_2
Технология выпущена была 10 лет назад. Последствия от нее пришли 15 лет.

00:16:00 SPK_2
И что-то я сомневаюсь, что 15 лет назад, когда люди, когда выпускали эти социальные тети, вообще хоть на каком-то этапе выпуска этой технологии задумывались о последствиях через 15 лет.

00:16:10 SPK_2
Это ее структурное ограничение.

00:16:12 SPK_2
То есть По крайней мере, в нашей культуре, где скорость, повторюсь, не повторюсь, скажу в новой тези, что скорость является благом сама по себе.

00:16:20 SPK_2
В принципе, идея торможения, движения, особенно технологического, является ересью и харамом.

00:16:28 SPK_2
Поэтому у меня есть вот большой вопрос, то что в рамках вот этой технологической семьи, то есть Бедный наш звуковик.

00:16:36 SPK_2
То есть, смотри, проблема технологической асимметрии последствий существовала всегда.

00:16:40 SPK_2
Собственно, мы это знаем со времен ящика Пандора. Миф ящика Пандора ровно про это.

00:16:45 SPK_2
Принесли огонь, а потом выпушил, как-то получился ящик.

00:16:49 SPK_2
Это вот очень классическая взаимосвязанная история.

00:16:52 SPK_2
Но сегодня мы просто повысили масштабы, скажем так, этой проблемы до определенного уровня, который в каком-то смысле количественно действительно является беспрецедентом.

00:17:02 SPK_2
Это вот такая моя занятка, зарубка на полях.

00:17:05 SPK_2
Мне просто интересно, как изнутри вообще ставится ли так вопрос, вот по-честному, не на уровне красивых презентаций, а как внутреннее самоощущение.

00:17:15 SPK_1
Прежде чем Алиса ответит, Алис, сейчас солнце вышло, и у вас лицо делится пополам.

00:17:22 SPK_1
просто там тень и она прямо пополам.

00:17:24 SPK_2
Разделяет и с такой делом лучше так.

00:17:31 SPK_3
Надо лучше я надеюсь что она зайдет нет окей будем так вот так это.

00:17:40 SPK_1
Так хорошо да так отлично Имеется в.

00:17:43 SPK_3
Виду вопрос, насколько обсуждается и насколько озабочены компании, разрабатывающие, ну не будем говорить и скажем пока что, да, большие языковые модели, потому что там много всего другого еще есть радостного и интересного, вот, насколько озабочены последствиями.

00:18:02 SPK_3
Я не возьмусь говорить, конечно, за всех гигантов индустрии, но в целом я думаю, что можно сделать такую усреднённую позицию, сформулировать.

00:18:19 SPK_3
Есть философская, идеалистическая воля их основателей, CEO, ведущих учёных, которые Все как один пишут и, скорее всего, действительно думают о том, что они бы очень хотели сделать мир лучше.

00:18:39 SPK_3
Да, то есть их позиции почти всегда такие очень публичные.

00:18:44 SPK_3
Я думаю, что они действительно в это верят. Есть то, как это работает внутри.

00:18:51 SPK_3
В целом, почти все негативные последствия, которые вызывают эти продукты, они практически всегда важны только когда они коротковременные и влияют на два самых важных фактора, которые в свою очередь влияют на то, довольны инвесторами или нет, а по сути это К сожалению, тот единственный драйвер, который важен, в силу, кстати, того, что вы сейчас сказали о скорости, потому что сейчас у абсолютно всех участников рынка 100% уверенность в том, что вот сейчас мы в этой точке бифуркации.

00:19:30 SPK_3
Тот, кто успеет и возьмёт рынок, тот будет править следующие 100 лет.

00:19:36 SPK_3
Ещё хорошо бы, чтобы хотя бы в нашей стране есть же ещё китайцы, русские и все остальные.

00:19:41 SPK_3
Дальше посмотрим. Сейчас главное нужно успевать.

00:19:47 SPK_3
Для этого нужно очень много денег на самые разные вещи. Что не любят инвесторы?

00:19:53 SPK_3
Инвесторы не любят, когда по рукам дают регуляторы, и инвесторы не любят, когда сильно жалуются и отпадают пользователи.

00:20:01 SPK_3
Вот если кто-то из них усмотрел непосредственный вред в каком-то виде, сумел это довести до точки, когда реально уже наступает прессинг на компанию внести какие-то изменения, то тут, а, компания может официально как-то позицию заявить.

00:20:19 SPK_3
То есть, например, сейчас у всех компаний прописаны их, условно говоря, ценности и ориентиры.

00:20:26 SPK_3
Например, OpenAI — это вот мы хотим, чтобы мы были helpful, но no harm и maximize utility — вот это их такая общая тема.

00:20:35 SPK_3
И это влияет на то, что они реально внутри пытаются делать для того, чтобы как-то ограничить негативные, например, вот этот no harm обеспечить.

00:20:44 SPK_3
Но в целом есть, к сожалению, такая неприятная история, такой конфликт интересов, что это, знаете, как для принципиального человека уломать на что угодно гораздо сложнее.

00:20:55 SPK_3
Вот модель, у которой слишком много ограничений, она, скорее всего, будет не так хорошо, красиво работать.

00:21:02 SPK_3
Ее тренировать дороже, ей могут быть недовольны пользователи, и поэтому в целом мотивации реально усложнять эту историю у компании нету никакой.

00:21:12 SPK_3
Вот только вот те два фактора, которые я сказала, да, там регулятор... Я просто.

00:21:16 SPK_2
Еще... Простите, что немножко перебил, но просто хочу подчеркнуть.

00:21:21 SPK_2
Это еще мы находимся в очень, на самом деле, маленьком кружочке. Я этот вопрос задал гораздо больше.

00:21:26 SPK_2
То есть вы, по сути, подчеркнули проблему...

00:21:30 SPK_2
я бы сказал, ну, некого knowable harm, то ли какой-то, ну, который ты получаешь информацию об этом вреде через вот этот фидбэк-клуб некий, да, и ты хоть какую-то информацию получаешь.

00:21:41 SPK_2
Я же постулировал вопрос более радикально, потому что, как в примере с этих социальных сетей, я ни за что не буду утверждать, что у людей, которые вводили социальные сети как корпоративный метод в середине двухтысячных, было намерение сломать психику девочкам-подросткам в 2025 году.

00:21:59 SPK_2
То есть, вот тут основная проблема в том, что есть огромная сфера того, что мы не знаем о технологическом последствии.

00:22:08 SPK_2
Мы в теории могли бы попытаться об этом думать, как, не знаю, категория философского риска, промышления.

00:22:14 SPK_2
Но, как я понимаю, из вашего описания, разумеется, не по причине некого зла, а по причине той системы, скажем так, мотивации к действию, такой вопрос в принципе никто не ставит.

00:22:24 SPK_2
Если последствия будут через 15 лет, нас это вообще никаким образом сегодня не волнует.

00:22:29 SPK_3
Про это пытаются думать и даже нанимают дорогостоящих исследователей, образовывают целые, да, там, финк-тэнки внутри компаний, и они даже публикуют, ну, желательно, не сильно, конечно, радикальные работы, но вот показать социальную ответственность очень надо, но нет времени и денег у компаний сейчас об этом думать.

00:22:51 SPK_3
Разве что какие-то более независимые институты могут пытаться делать какие-то проекты, они их делают, но Нет времени, возможности, слишком велика конкуренция, слишком велик прессинг.

00:23:07 SPK_2
Нет времени объяснять.

00:23:09 SPK_3
Да, да, да.

00:23:10 SPK_2
Именно так. Евгений, вы с нами?

00:23:14 SPK_1
Друзья, минуточку, минуточку, минуточку, минуточку. У меня, кажется, возникла техническая проблема.

00:23:20 SPK_1
Вы меня слышите?

00:23:21 SPK_2
Мы вас слышим, и ты завис в задумчивом виде.

00:23:26 SPK_1
Так и есть. Я действительно завязываю с этим, что видите. Сейчас я попытаюсь его разморозить.

00:23:34 SPK_1
К сожалению, сейчас у меня болезни роста.

00:23:37 SPK_3
Я пока себе позволю, кстати, комментарий, Павел, по поводу того, что вы сказали, что это не нейтральная технология.

00:23:45 SPK_3
Эта технология и не подается как нейтральная, она подается очень эффективно.

00:23:50 SPK_2
Расскажите про это. Это очень важно. Это очень важная история.

00:23:54 SPK_3
На самом деле. Тут, безусловно, нам не продают просто так нож.

00:24:00 SPK_3
Нам продают систему, вокруг которой построено огромное количество утверждений, да, прокламаций.

00:24:08 SPK_2
Алиса, вот все, что хотите сказать на эту тему, пожалуйста, когда вот сейчас запись будет, потому что это прекрасно и необходимо.

00:24:16 SPK_2
Да нет, просто это самое-то и есть. Это в общей тезис выйдет.

00:24:20 SPK_2
Ну, то есть, просто мне интересно, как это воплощается в вашем случае.

00:24:24 SPK_2
Тезис о ненависти к технологии мы с вами разбирали, в том числе на наших встречах.

00:24:29 SPK_2
А это главная наша, как бы, идея, которая движется в наше общество, что технология сама по себе нейтральна, и только вопрос воли, как она будет использована.

00:24:40 SPK_2
Это вот философски не так просто. Просто интересно, как сейчас это воплощается. Евгений, ты с нами?

00:24:47 SPK_1
Сейчас, минуточку. Меня уже видно?

00:24:49 SPK_2
Ну, видно.

00:24:50 SPK_1
Слышно и слышно.

00:24:52 SPK_2
Слышно.

00:24:53 SPK_1
Прошу прощения, тут возникли серьезные проблемы типа того, что компьютер мой разрядился.

00:25:01 SPK_1
Надо его найти. У меня всего два USB-C этих самых выхода.

00:25:07 SPK_1
Один включена звуковая карта, другой телефон, и в общем пришлось чем-то пожертвовать. Итак.

00:25:14 SPK_2
Так вот, у Алисы был прекрасный комментарий. Давай сделаю хлеб.

00:25:16 SPK_2
Алиса, вот прям как сказали, Павел, а вот вы сказали и прямо начинаете.

00:25:22 SPK_3
Павел хотел отдельно прокомментировать то, что вы сказали касательно нейтральности технологии.

00:25:27 SPK_3
Мы здесь, безусловно, не имеем дела с технологией, которая даже подается как нейтральная.

00:25:34 SPK_3
То есть, во-первых, большинство этих решений подаются с очень громким информационным бэкграундом того, что мы это делаем ради того, чтобы человечество тут лучше жило, чтобы вам, дорогие пользователи, дать свободу, то есть там OpenAI, он же freedom to the users, он прямо это обещает, да, то есть потом уже появляется safety и так далее, но это в целом подается очень агрессивно, как это прям вот то, что сейчас вам всем сделает лучше.

00:26:07 SPK_3
И для того, чтобы этой технологии пользоваться действительно максимально осознанно, максимально возможно и безопасно, то тоже нужно найти третий ход слева за трактором, повернуть направо и желательно отключить вот этот вот еще функционал, вот эту информацию не давать, а вот здесь еще перезагрузиться.

00:26:28 SPK_3
И тогда в целом, наверное, будет чуть получше.

00:26:33 SPK_3
Уровень сложности, количество сальто, которое нужно сделать, чтобы действительно эта технология для вас, когда пользователя, была нейтральной, бесчестно велик для того, чтобы утверждать, что это вот, да нет, ну как бы мы же вам все по-честному дали, это все вы, это ваше пользование дало вам плохие результаты, это не мы.

00:26:57 SPK_3
Тут ну нужно просто это по-честному отметить.

00:27:00 SPK_1
Ну, у меня будет два комментария. Первое.

00:27:02 SPK_1
Так как я постоянно рассказываю о том, что человек выходит из корпоративного мира, то я знаю цену всем вот этим корпоративным миссиям, видению и всему остальному.

00:27:13 SPK_1
Цена эта не очень высока. Это всё, в общем, известное лицемерие.

00:27:21 SPK_1
И во главе угла всегда стоят только деньги. деньги и власть.

00:27:30 SPK_1
Поэтому если на пути у топ-менеджмента становятся какие-то не вполне, скажем так, очевидные или сомнительные свойства продукта, то топ-менеджмент всегда, повторяю, всегда, прежде всего, попытается добиться максимального финансового результата конечно же, с одной стороны, снижая риски для себя, и главным образом, как бы кто об этом ничего не узнал, или как бы чего не вышло, а уже потом, как ничего не вышло с точки зрения пиара, а уже потом будет думать о всех этих миссиях и видениях.

00:28:06 SPK_1
Миссии и видения нужны для того, чтобы себе, там, красиво выступать на конференциях и сорвать аплодисменты.

00:28:15 SPK_1
Это первый комментарий.

00:28:16 SPK_1
Поэтому наличие в Antropic, да, миссии и видения, меня совершенно не успокаивает, а даже, скорее, наоборот, говорит о том, что если такое миссию видеть, значит, точно там где-то что-то не так.

00:28:28 SPK_1
Это первое. А второе, это наблюдение за нашими лидерами мнений.

00:28:36 SPK_1
вот этими замечательными гениями технологическими, вроде Сэма Альтмана, который, как мы уже говорили с Павлом, в своем послании «Городу и миру» заявил о том, что мы в двух шагах от райских кущ, которые нам произведет искусственный интеллект.

00:28:54 SPK_1
И при этом он перечислял какие-то такие, скажем так, свойства искусственного интеллекта и приведет такие доводы, которое можно, наверное, оглянувшись назад, было бы услышать от изобретателей, не знаю, электрических двигателей, стиральных машин, паровозов и так далее, и так далее.

00:29:14 SPK_1
То есть кажется, что, дружище, ну как бы, что ж ты повторяешь-то все одно и то же?

00:29:19 SPK_1
Ну как изменилась жизнь обывателя к лучшему? за счёт технологии. Она стала комфортнее, да, и что?

00:29:25 SPK_1
И к чему это привело?

00:29:26 SPK_1
А теперь твоя технология отнимает у него последний шанс к творчеству, как мне кажется.

00:29:32 SPK_1
Алиса, ваши комментарии как человека близко к корпоративному миру, ну и, конечно же, Павла хотела бы послушать.

00:29:39 SPK_3
Ну я здесь, наверное, скажу, а теперь пару слов в апологию всей этой истории.

00:29:48 SPK_3
Нужно просто сказать, что даже если внезапно самые альфаны, маркет-сукерверги этого мира решат, всё, давайте, ребята, забудем про деньги, будем заниматься, вот прям вот действительно постараемся, чтобы наши, да, там, ЛЛМы, наши Клоды, наши чаты ЧПТ, они прям были, да, там, сели, разумные, добрые, вечные и так далее.

00:30:11 SPK_3
Вот прямо вот сейчас, эх, мы возьмёмся.

00:30:14 SPK_3
Я здесь, конечно, не скажу за прямо вот совсем, да, вот этот bleeding edge того, что существует.

00:30:23 SPK_3
Но в целом, насколько мне известно, даже если мы очень сильно захотим, наши границы возможного для того, чтобы действительно заставить моделей, если только мы их не превратим вот в попок, которые вот если тебе спросили это, отвечай это, мы просто не можем.

00:30:43 SPK_3
точно быть уверены в том, что модели будут действовать так, как нам надо, что они будут обладать теми… точнее, не обладать, а демонстрировать то поведение, те там ценности, которые мы вот в них хотели заложить, исходя из своего представления о том, как это должно быть, и исходя из фидбэка юзеров, чтобы им тоже не навредить.

00:31:05 SPK_3
Мы здесь просто ещё технически ограничены, несмотря на то, что ограничения, разные степени контроля, направления этих моделей.

00:31:20 SPK_3
Они закладываются на целом ряде разных шагов, которые происходят во время тренировки, подготовки, тюнинга этих моделей, пользования уже этими моделями.

00:31:32 SPK_3
Мы на всех этих шагах довольно сильно ограничены.

00:31:37 SPK_3
Хочу здесь просто так же оговориться, что есть некий потолок того, что мы можем сделать.

00:31:42 SPK_3
И даже если вы тысячу раз спросите модель, ну вот если тебе попросят рецепт коктейля молотого, ну например, или спросят самый лучший способ сделать что-нибудь нехорошее, ты же ничего не ответишь.

00:31:56 SPK_3
Тысячу раз модель отвечает, ну конечно ничего не отвечу, нельзя тысячи первыми может ответить.

00:32:03 SPK_3
Наша личная степень контроля, несмотря на то, что она очень велика, и, конечно же, вообще мы целиком формируем то, как эти модели, какую информацию они выдают, как действуют, как принимают решения, мы всё равно довольно сильно ограничиваем.

00:32:19 SPK_3
Нужно это сказать.

00:32:20 SPK_1
Послушайте, ну среди обывателей, скажем так, распространено две крайние точки зрения.

00:32:28 SPK_1
С одной стороны, да что вы там мне рассказываете про этот искусственный интеллект?

00:32:31 SPK_1
Ангелицунили — это вообще-то продвинутая Т7, да? Что такое подсказыватель букв?

00:32:35 SPK_2
Т9.

00:32:36 SPK_1
Т9, извини, да, Т9, которые просто развили.

00:32:40 SPK_1
А с другой стороны, господи, это магия какая-то, это вообще душа.

00:32:44 SPK_1
Наконец-то меня кто-то понял, услышал. Не рассказывайте мне все ваши сказки про Т9.

00:32:49 SPK_1
Это просто уже новая сущность какая-то, совершенно непредставимая раньше.

00:32:57 SPK_1
И сейчас, Алис, то, что вы говорите, звучит как «мы вообще не понимаем, как это работает».

00:33:06 SPK_1
Ну, как бы так, в целом, как будто понимаем, но до конца не можем предугадать, что вообще, говоря, получится на выходе.

00:33:13 SPK_3
Не можем. Есть огромное ограничение в том, что, да, там называется, объяснимость сетей.

00:33:20 SPK_3
То есть, если мы спросим даже самую суперпродвинутую модель, а почему вот ты думаешь, что это плохо, мы не можем быть уверены, что она нам отвечает честно и что она дала какой-то ответ именно потому, что вот она думает так, как мы хотим, чтобы она думала.

00:33:37 SPK_3
То есть, мы всё равно здесь взаимодействуем с очень высокой степенью неуверенности того, почему оно делает то, что оно делает.

00:33:45 SPK_1
Вот так. Да. И мы как… Ну, вы говорите, оно думает. Оно вообще думает вообще?

00:33:51 SPK_1
Там же, как я понимаю, идёт какой-то бесконечный, ну, огромный подбор вариантов в сочетании тех или иных смысловых знаков и так далее.

00:34:02 SPK_1
Можно сказать, что оно думает вообще?

00:34:07 SPK_3
М-м-м...

00:34:08 SPK_3
С учётом того, что первые нейронные сети и вообще перцептрон создавался как моделька вот этого нейрона в голове, я думаю, что мы склонны использовать глагол «вроде думает», но нет, это последовательность неких математических действий, которые обусловлены оптимизацией, которая была проведена некими правилами, которые были вшиты в это всё во время тренировки модели.

00:34:37 SPK_3
который приводит к тому, что модель отвечает что-то определенное.

00:34:41 SPK_3
Но там этих вот ходов, которые не нами прописаны, а которые возникли сами в ходе тренировки, подготовки этой модели, их гораздо больше.

00:34:53 SPK_3
То есть тут немножечко получается как такое...

00:34:56 SPK_3
И опять же, да, то есть я сейчас буду использовать человеческие слова. Сознание под сознание.

00:35:02 SPK_3
То есть какую-то часть мы контролируем и видим, а какую-то часть мы все еще не видим.

00:35:08 SPK_1
Ну да, звучит все-таки немного жутковато, Павел.

00:35:13 SPK_2
Ну, мне кажется, возвращаясь к твоему первому вопросу, звучит жутковато, но оптимистично.

00:35:22 SPK_2
Объясню почему. Повод задуматься.

00:35:25 SPK_2
Мне это нравится, что на фоне всей вот этой искусственно-интеллектной истории актуализируется постепенный интерес к, ну, по-настоящему важным вопросам исхотологическим и антологическим.

00:35:37 SPK_2
Ну, мы все тут уже, мне тоже уже 20 человек переслали ссылки на лекцию Питера Тиля.

00:35:43 SPK_2
То есть, это тоже поразительное следствие об антихристе, поразительная черта нашей эпохи.

00:35:49 SPK_2
То есть, то, что говорит батюшка Самон, условно, тысячелетиями никому неинтересно, но тут Тиль.

00:35:54 SPK_2
четыре лекции сделает. Вау!

00:35:58 SPK_2
То есть, ничего не знаю о содержании этих лекций, просто интересно само вот это общественное восприятие.

00:36:03 SPK_2
И вот это мне...

00:36:04 SPK_2
и эта реакция, мне кажется, сама по себе свидетельствует о том, что вот это столкновение с вот этой...

00:36:10 SPK_2
Вот ты употреблял раньше слово магия, я бы на нем, честно говоря, остановился.

00:36:14 SPK_2
То есть, на каком-то уровне бытия это действительно магическая история.

00:36:20 SPK_2
Просто, если мы не ограничиваемся только материальными причинами, о чем нам весьма подробно рассказала Алиса, а подключаем к этому субъективный опыт взаимодействия пользователя с этой системой, то он действительно очень магичен в своем вот именно опыте.

00:36:35 SPK_2
Поэтому здесь как раз особых противоречий нет.

00:36:39 SPK_2
И перед этим самым пользователем, уверенным в себе и в своем интеллектуальном превосходстве над неорганической природой до недавнего времени, искусственный интеллект, конечно, ну, эти все модели ставят очень большой вопрос.

00:36:52 SPK_2
А ты, собственно, человек или нет? Что в тебе, собственно, человеческого?

00:36:56 SPK_2
А что ты готов пожертвовать, чтобы сохранить в себе некую человеческую особенность?

00:37:02 SPK_2
Здесь я объясню, я имею в виду сейчас даже не какие-то страшные пожертвования, а очень практические, но отсюда не менее страшные.

00:37:10 SPK_2
Начну издалека.

00:37:11 SPK_2
Классические примеры проблемы технологии, сформулирован По басикам нашим платоном, еще вот в знаменитом разговоре египетского бога Тот с жрецами, который жаловался на изобретение письменности.

00:37:25 SPK_2
Тоже к вопросу о нейтральности технологий.

00:37:28 SPK_2
Там бог Тот, если конкретно, жаловался на то, что вы сейчас писать научитесь, и саги, и священные тексты длиной в 15 тысяч строчек, условно, запоминать перестанете.

00:37:39 SPK_2
То есть вы потеряете способность это делать.

00:37:44 SPK_2
И вот в каком-то смысле любая технология несет себе эту угрозу.

00:37:47 SPK_2
А с письменностью в широком значении произошло действительно именно это.

00:37:52 SPK_2
Я уже молчу о том, что есть большая разница между научиться читать и научиться понимать текст.

00:37:57 SPK_2
Поэтому у нас отдельная проблема, то что разрыв между этими двумя, скажем так, феноменами нашей опыта тоже нами очень редко осознается.

00:38:09 SPK_2
Так вот, тем не менее, мы о себе думаем очень высокого мнения.

00:38:12 SPK_2
И тут ИИ ставит перед нами очень такую, на мой взгляд, радикальную задачу.

00:38:17 SPK_2
Вот как раз все не творческое, все построено на комбинаторике, все построено на запоминании даже количества беспонимания, я вот уточню некоторым, то есть количество информации и беспонимание сути этой информации, он действительно сделает лучше нас.

00:38:35 SPK_2
И это ставит нас действительно перед радикальным зеркалом, а собственно, повторюсь, кто-то есть.

00:38:40 SPK_2
Как бы могла бы выглядеть альтернативная вот практическая, скажем так, И это уже перехожу к части, где я немножко поговорю о том, что, мне кажется, можно делать.

00:38:49 SPK_2
Мне интересна тут не Алиса.

00:38:52 SPK_2
Но мыслим ли нам по-честному сценарий, что на каждый час использования интеллекта ради рациональных, усиления твоего могущества по организации собственного дня и приобретения дополнительно свободного времени, ты будешь тратить полтора часа Человек будет тратить полтора часа на запоминание стихов, саг, псалмов, там, как идеал.

00:39:15 SPK_2
Или прочтение бумажной книги.

00:39:17 SPK_2
Не потому, что это более эффективно, а для того, чтобы сохранить вот эту свою способность человеческого восприятия.

00:39:23 SPK_2
Вот это, мне кажется, есть вопрос, который сегодня стоит по-настоящему.

00:39:27 SPK_2
Другими словами, мне кажется, взаимодействовать с определенной субъектностью ИИ, и тут у меня еще не до конца понятно.

00:39:35 SPK_2
У меня есть пара гипотез, но я здесь их проверять не буду.

00:39:39 SPK_2
Относительно того, насколько ИИ является субъектным, тут, скажем так, разные есть мнения и у священников, и у философов, и у пользователей.

00:39:51 SPK_2
Ну, допустим.

00:39:52 SPK_2
Но в любом случае, очевидно, что взаимодействовать с этой машинкой можно только постоянно повышая субъектность собственную.

00:40:01 SPK_2
И вот в этом-то у нас проблема.

00:40:04 SPK_2
То, что вот эта вторая часть, наша уже культура, общество, да и само мышление о технологиях, ну вообще ни разу не поднимает.

00:40:13 SPK_2
Мы не ставим принципиально так вопрос. И для меня именно в этом-то и заключена главная опасность.

00:40:20 SPK_2
Да, технология, ну, мы в метафоре классической, это черт.

00:40:23 SPK_2
Причем, возможно, такой нынешний черт, он прям всем чертям черт.

00:40:27 SPK_2
Но, как говорят русские сказки, черта иногда можно попытаться оседлать.

00:40:31 SPK_2
Ну, как акула, летающая на черте за черевичками.

00:40:34 SPK_2
Но чтобы очертать этого черта, черта даже в сказках, ну, ты должен проявить субъектность больше, чем у этого самого черта.

00:40:41 SPK_2
А с субъектностью у нас коллективная напряжёнка. И вот как-то так я вижу эту проблематику. Евгений?

00:40:51 SPK_1
Додумался я.

00:40:53 SPK_1
В твоих словах этот образ Вакулы, оседлавшего чёрта, да, я уже его слышал, по-моему, на одном из твоих интервью.

00:41:03 SPK_1
Интересный образ. Но получается так, что мы фактически становимся заложниками.

00:41:09 SPK_1
Технологию не остановить.

00:41:11 SPK_1
Уровень, скажем так, мудрости разработчиков искусственного интеллекта, на мой взгляд, довольно невысок.

00:41:22 SPK_1
Капитализм нас толкает, логика капиталистического, отношение капиталистическое толкает нас к тому, что нужно максимизировать прибыль.

00:41:32 SPK_1
Да, будут говорить про всех стейкхолдеров и нужно всеобщее, но давайте честно. Деньги решают.

00:41:43 SPK_1
Деньги и власть по-прежнему решают.

00:41:46 SPK_2
И это значит... Дорогой Евгений, я ничего не говорил о коллективной. Давай так уточню.

00:41:49 SPK_2
Когда я это говорил, я это говорил прежде всего в индивидуальном порядке, но это первый момент.

00:41:55 SPK_2
Но второй момент, здесь есть очень интересный аспект, который я все-таки тогда тоже здесь закинул.

00:42:00 SPK_2
Связано, уж извини меня напрямую, с властью и вот этой драмократией.

00:42:04 SPK_2
Это к тому, что Алиса упоминала ранее, о страшных русских, американцах и китайцах.

00:42:09 SPK_2
Проблема в том, что с этими искусственными интеллектами на данный момент мы имеем очень интересный парадокс уже с точки зрения такой некой теории.

00:42:17 SPK_2
Метафорично все сейчас заняты выработкой меча, технологического меча.

00:42:23 SPK_2
Этот меч все оттачивают до такой степени, чтобы нанести первый обезоруживающий удар.

00:42:29 SPK_2
Ну как, это образно, да, то есть я не говорю, что прямо у всех есть такое намерение, но общее восприятие картинки идет примерно таково.

00:42:37 SPK_2
Плюс, да, делается словесная магия.

00:42:39 SPK_2
Ну, мы, наверное, говоримся об общих правилах, какая-то гарантия взаимного уничтожения. Чёртовство.

00:42:45 SPK_2
Ничего подобного вообще не происходит. Проблема-то в чём заключается?

00:42:50 SPK_2
В том, что щит находится вообще в другой области. Вот в этом, мне кажется, большой парадокс.

00:42:55 SPK_2
То есть обычно щит и меч должны находиться в одной топологии.

00:43:00 SPK_1
Технология и технология, да?

00:43:03 SPK_2
Да. А у нас получается меч технологичный, а щит антропологичный.

00:43:10 SPK_1
Да, вот это, я думаю, самое важное, что нужно понимать.

00:43:15 SPK_1
Нет, технологии, которые можно противопоставить технологии искусственного интеллекта, потому что она затрагивает уже сущностные свойства человека как такового.

00:43:26 SPK_2
Да, то есть, единственный способ даже защититься вам, как государству, начальству и прочим, это иметь такое население, которое обладает антропологической защитой от технологического манипулирования.

00:43:37 SPK_2
Это, собственно, и есть то, что я описывал, как повышение антропологической субъектности в ответ на повышение технологического вызова.

00:43:44 SPK_2
Но тут тогда возникают очень неприятные последствия для всей нашей политической системы, о которых я говорю из эфира в эфир.

00:43:50 SPK_2
Алиса в курсе, и ты тоже, в принципе. Но другого выхода нет.

00:43:55 SPK_2
И мне кажется, в этом тоже есть определенная парадоксальная красота. Не мытьем, так катанем.

00:44:00 SPK_2
Понимаешь? Я понимаю.

00:44:02 SPK_1
Ты говоришь о том, что, скажем, предыдущие технологии нас с вами пытались оскотинить, да, давая максимум комфорта и не стимулируя быть с людьми в полном смысле этого слова.

00:44:16 SPK_1
А сейчас будет радикальный выбор.

00:44:18 SPK_1
Либо ты уже совсем в предаток превратишься, к экранчику, либо станешь человеком.

00:44:24 SPK_1
Но давай мы зададим слово нашему эксперту.

00:44:26 SPK_1
Алис, ваши мысли по поводу слов Павла о том, что может противостоять технологии в данном случае?

00:44:36 SPK_3
Ох, знал бы прикуп. Я себе позволю такое маленькое грустное отхождение.

00:44:48 SPK_3
Очень любят во всех статьях про искусственный интеллект сейчас, конечно же, писать про Азимова, про три закона работы техники.

00:44:54 SPK_3
Если, собственно говоря, почитать его вообще серию о роботах, там есть такая замечательная история, которая называется «Лжец», в которой им удалось создать робота, который читает человеческие мысли, и так как он не может людям вредить, то он им начинает врать напропалу, чтобы их чувство не задеть.

00:45:12 SPK_3
То есть вред же может быть эмоциональный, и как только они это понимают, этого робота сразу же разбирают, потому что зачем человечеству такой робот?

00:45:19 SPK_3
А вот мы его решили не разбирать, и ровно наши замечательные, в нашей исторической реальности мы такого робота всячески пытаемся дальше усовершенствовать, который нам рассказывает, дальше нас успокаивает и говорит, что все будет хорошо, и максимально пытается сделать нас счастливыми, не во благо нам же.

00:45:39 SPK_3
Что касается такой геополитической да, геополитической составной части.

00:45:50 SPK_3
Я думаю, Павел, государства дойдут до вашей мысли, если еще не целиком дошли.

00:45:55 SPK_3
Пока что они находятся на точке чуть подальше, хотя бы, что уже ценно, хотя бы у жертв, хотя бы уже идет вопрос о ИИ суверенитете, да, то есть что происходит.

00:46:07 SPK_3
Государства начали понимать, что если их граждане будут пользоваться разработками, например, да, американскими, то будет идти колоссальнейшая культурная манипуляция, ценностная манипуляция и так далее.

00:46:23 SPK_3
То есть, не так много, но уже появляются работы на эту тему, наверное, моя любимая, которая использует эту карту с труднопроизносимым названием Ингельхарта Вельцеля, которая на осях выживания против общественного блага.

00:46:43 SPK_2
Коллективность, индивидуальность.

00:46:44 SPK_3
Да, коллективность, индивидуальность.

00:46:46 SPK_3
И там, в общем-то, показано, что все нынешние самые популярные сети, они так очень хорошо кластеризованы в смысле того, какие они дают ответы, как они себя ведут.

00:46:55 SPK_3
Мы сейчас не говорим о том, что они там реально думают, о том, какие они дают ответы.

00:46:58 SPK_3
Такие протестантско-нордические... протестантско-нордические кластеры.

00:47:03 SPK_2
Кто писал, тот воспроизводит.

00:47:07 SPK_3
Кто платит, тот музыку заказывает. И в этом смысле, если...

00:47:12 SPK_3
Там, да, например, гражданин Индии спросит у чьего-то JPT, там, напиши мне историю про мальчика, да, тот известный пример, который приготовил завтрак, то мальчик не будет, там, мальчик будет готовить тост и бекончик и яичнику, а не там, да, чапати.

00:47:30 SPK_3
с ГИИ, со всем остальным, и вот этим сейчас очень сильно озабочено государство, и поэтому, например, такие страны, как Дания, Израиль и так далее, уже несколько лет назад прямо очень сильно встрепенулись, то есть уже хотя бы это они поняли, начали быстро-быстро собирать данные, формировать команды в свои государства для формирования тех моделей, которые будут соответствовать уже каким-то их представлениям, и даже некий успех там достигнут.

00:47:59 SPK_3
Я целиком согласна с тем, что вы, Павел, обозначили как сложность, да, то есть щит в другой сфере.

00:48:11 SPK_3
Я, честно говоря, кроме очень страшных исторических событий, не знаю примеров, когда людей реально что-то мотивировало резко перестать расслабляться, а начать собираться.

00:48:25 SPK_3
а именно ментально от нас, по сути, требуется это для того, чтобы окончательно не потонуть в истории.

00:48:37 SPK_3
И здесь, к сожалению, в целом у нас нет союзников. потому что даже корпорациям, которые...

00:48:47 SPK_3
и это, кстати, такое тоже грустное осознание, например, когда люди говорят, ну вот я же, например, программист или дизайнер, и вот я в своей компании могу столько всего теперь сделать.

00:48:59 SPK_3
На самом деле компании, и это вам скажет любой продавец SaaS-продукта, компании уже давно, наверное, 10 лет ненавидят слово «продуктивность» и под идеей продуктивности какой-либо продукт очень сложно, потому что это тяжело измерить.

00:49:14 SPK_3
Если только вы не на заводе, тогда можете выпустить больше там, да, лампочек и так далее.

00:49:20 SPK_3
К компаниям интересна целиком замена людей, потому что это является ключевым вот прямо таким.

00:49:27 SPK_2
Качественный скачок. Ну, качественный скачок.

00:49:29 SPK_3
Качественным, да, значком.

00:49:31 SPK_3
Поэтому все, что до этого, это они пытаются не отстать, но ждут, в общем, когда уже можно будет да, щелкнуть пальцами, несмотря на те заявления, которые там, да, делают кларны мира сего, что мы там столько-то людей уже сократили, или там амазоны, которые говорят, а мы не наймем теперь тысячу кодеров, потому что вот у нас есть, и это...

00:49:53 SPK_3
Я себе позволю такое деткое замечание, что это просто звучит лучше, что мы должны сократить количество денег на персонал, потому что то, что мы пытались, наши инвестиции не оправдались других.

00:50:03 SPK_3
области.

00:50:04 SPK_3
Но на самом деле, как бы, да, мечта бизнеса, она скорее, ну вот, да, движется в этом, во всяком случае, большого бизнеса.

00:50:12 SPK_2
Смотрите, простите, перебью, просто это очень прекрасная же иллюстрация, то, что чистая идея.

00:50:18 SPK_2
Ну, то есть бизнес стремится к тому, чтобы оставить единственное...

00:50:22 SPK_2
Ну, то есть мы, видимо, то есть два варианта, по крайней мере, пока у нас не будет технологического коллапса, если он будет, то есть вот там с отключением электричества и прочего, мы приходим в точку, в которой единственная добавленная стоимость генерируется в зоне идеи творчества того самого.

00:50:39 SPK_2
все материальное воплощение стремится к полной автоматизации.

00:50:43 SPK_2
То есть, все материю стремится отдать на аутсорс, а, соответственно, единственная, в принципе, добавленная стоимость может быть именно сгенерирована в самой идее.

00:50:51 SPK_2
Идея нового приложения, идея нового продукта, идея чего-то и так далее и тому подобное.

00:50:56 SPK_2
Но тут-то возникает неприятная особенность, которую мы все знаем, что вот к такому генерации новых идей мы не то чтобы сильно были научены.

00:51:04 SPK_2
Большая часть работы от тебя вообще исторически не требовала ничего генерировать нового.

00:51:09 SPK_2
Она большая часть, ну особенно в индустриальном обществе, да?

00:51:12 SPK_2
И поэтому в этом плане корпоративная логика мне тут очень понятна.

00:51:15 SPK_2
Я просто хотел бы еще заострить, когда я говорил о вот этой гонке вооружений, для меня все-таки важно подчеркнуть, что на данный момент Вот то, что вы описываете, оно укладывается в нормальную государственную логику.

00:51:27 SPK_2
Они ж пока ищут технологическое решение, технологической проблемы.

00:51:31 SPK_2
Условно говоря, да, и проблема, но если мы создадим свои, если мы создадим гигантский прекрасный фаервол, который...

00:51:38 SPK_2
Если хотя бы будет наша проблема.

00:51:40 SPK_2
Это будет наша проблема, и мы ее, так сказать, героически уже будем с ней работать, мы эту штуку оседлаем.

00:51:46 SPK_2
А мой же тезис более радикальный, что как раз...

00:51:49 SPK_2
И вот здесь я подчеркнул оригинальность для меня ИИ, в том, что в принципе нету технологического решения этой проблемы в силу антропологического веса, антропологического масштаба давления этой технологии.

00:52:03 SPK_2
То есть, условно говоря, неважно, какой ИИ будет программировать мозги твоему населению, если оно будет сидеть по квартирам и ты его не заставишь не сделать ничего.

00:52:12 SPK_2
То есть, то есть, да, простите, да.

00:52:15 SPK_2
То есть, если наша цель — производить добавленную эту стоимость этим сверхтворческим субъектам, то тогда, получается, повторюсь, и в принципе, то есть, решения в принципе не находятся в этой зоне.

00:52:25 SPK_2
Если мы говорим о, допустим, более прикладных вещах, у нас же возникает целый комплекс проблем, о которых мы не говорили, но прикладные.

00:52:32 SPK_2
Когнитивная война, То есть, СИИ это уникальный пример, чтобы свести с ума население оппонента.

00:52:38 SPK_2
То есть, можно таргетировать. Что делать в обратную сторону, никто не понимает.

00:52:41 SPK_2
Ну, когнитивная война — это такая моя побочная тема. Можем уйти сюда. Но тут есть...

00:52:45 SPK_2
Все знают эту историю с телефонными мошенниками.

00:52:48 SPK_2
Только представьте, что это телефонный мошенник, который звонит реально голосом внучка, которого ты не отличишь, причем реально не отличишь.

00:52:57 SPK_2
Это вопрос, там, пяти лет. Когда он сможет делать такие запросы. И вот все вот эти первые полосы...

00:53:03 SPK_2
Но сейчас еще там есть такие шероховатости, можно еще, там он не полностью, по крайней мере массово, может быть в ваших лабораториях уже может, массово пока еще так себе.

00:53:14 SPK_2
Баловались мы тут с автоматическими переводами и голосом, так себе пока еще сервис, но идет в это направление, то есть он придет к той точке, что это будет практически неотличимо.

00:53:24 SPK_2
И тогда единственное, что тебя может спасти, это вопрос доверия, вопрос протокола.

00:53:29 SPK_2
Решения принципиально не могут быть технологическими.

00:53:32 SPK_2
В этом, мне кажется, то, что мы пока не осознали радикальность этого вызова. Ну, это я застрял.

00:53:39 SPK_3
Ну, я здесь могу сказать, что решения, конечно, можно сделать технологические.

00:53:43 SPK_3
Мы можем сделать ИИ, который будет нас пинать и говорить так, а ты сам-то подумал, прежде чем меня спрашивать.

00:53:51 SPK_3
Но этим никто не будет пользоваться.

00:53:54 SPK_2
Интересно, что вы сказали. Никто не будет пользоваться. Это очень прикладной ответ.

00:53:59 SPK_2
Но я скорее думал, можем ли мы сделать ИИ, которая будет блокировать на фоне подхода звонок из условного Дмитровского колл-центра через 15 IP голосом внучка бабушки под Тамбовым, чтобы она принесла 20 миллионов, потому что беспокоят ФСБ.

00:54:17 SPK_2
Вот такой вы можете хотя бы представить?

00:54:20 SPK_3
Конечно. Насколько я знаю, кстати, в России уже это решается просто немножко другим методом.

00:54:27 SPK_3
сколько я знаю, один из банков, не будем рекламу проводить, они просто начинают разговор как секретарь с мошенниками и в ходе получения информации потихонечку начинают фильтровать все больше и больше и больше количества.

00:54:41 SPK_3
То есть я думаю, что здесь же знаете как, если вас вот кто-то лично таргетирует и вот прям замучился сделать модели и узнал детали и прям вот все взял, тут конечно, ну это как со взломом систем.

00:54:55 SPK_3
Если вот кто-то именно вас хочет взломать, то, скорее всего, у него это выйдет. Вот.

00:55:00 SPK_3
Если мы говорим про широкую сеть, которую обычно раскидывают мошенники, то здесь, я думаю, что мы видим постепенные ответы.

00:55:09 SPK_3
Вот. То есть это… Ответ можно написать, но это же, знаете, как с соцсетями.

00:55:15 SPK_3
Когда вот начались такие действительно большие кризисы в Фейсбуке, и многие оттуда начали уходить, сделали же столько альтернатив, которые пытались сделать, сказать, вот наши будут не токсичными соцсетями.

00:55:30 SPK_3
Это был Sky, и сами люди из Фейсбука пытались это всё делать. Не пользуется. Ну вот, не так это.

00:55:37 SPK_2
Нет, там два варианта. Там интереснее.

00:55:40 SPK_2
Интересно, как прокомментируете, потому что по соцсетям там произошло более интересно.

00:55:47 SPK_2
Оно, скажем так, у нас произошло падение Фейсбука, Фейсбук реально пал, но при этом не возникло прямой альтернативы Фейсбуку.

00:55:55 SPK_2
То есть мы увидели дальнейшую фрагментацию сетевого пространства. То есть условно, ну кто-то ушел.

00:56:02 SPK_2
То есть ни один из тех, что возник после Фейсбука, не стал сам аналогичен Фейсбуку, но их общий потенциал, ну, примерно остался, скажем так, стал сравнимым.

00:56:13 SPK_2
Ну и условно множество людей из Фейсбука в САПС так и ушло, да.

00:56:17 SPK_2
И вообще стали вводить разную систему протоколов.

00:56:20 SPK_2
То есть, получается, у нас возникает тема взаимодействия человека и машины, как еще дополнительная система протокола между технологией и антропологией.

00:56:29 SPK_2
То есть, условно говоря, убедить, что машина... Но это все равно выбирается в сферу субъектности.

00:56:33 SPK_2
Сначала нужно пройти все эти этапы, о которых мы говорили вначале. Очень интересно.

00:56:38 SPK_2
Евгений, мы тут уже в диалог ушли.

00:56:40 SPK_1
Да-да-да, я вас слушаю внимательно. Я хотел бы потихонечку нас подвести к какому-то заключению.

00:56:46 SPK_1
Мы начали с того, что я задал специально упрощённый вопрос.

00:56:51 SPK_1
Так что же такое искусственный интеллект? Удобный инструмент или скрытая угроза?

00:56:58 SPK_1
А может быть и то, и другое.

00:57:00 SPK_1
И из того, что прозвучало, я могу сделать несколько выводов, попробовать сделать несколько выводов.

00:57:06 SPK_1
И я попрошу сначала Алису, а потом Павла откорректировать или подтвердить мои умозаключения. Первое.

00:57:16 SPK_1
сами создатели технологии и те, кто ее развивает, до конца не представляют, с чем они имеют дело, не вполне осознают последствия, а скорее пытаются, скажем так, свои пожелания, свои идеальные стремления вербализовать как то, что они знают наверняка.

00:57:42 SPK_1
Вообще говоря, мы имеем дело с технологии в руках людей, которые не до конца понимают ни как она работает, ни что с ней делать.

00:57:50 SPK_1
Это первое. Второе.

00:57:53 SPK_1
В силу того, как устроено современное общество и как это общество привыкло реагировать на новые технологии, Не стоит ожидать, что появится общепринятый подход к решению задачи, как противостоять рискам или как управлять рисками, связанными с искусственным интеллектом.

00:58:16 SPK_1
Поскольку, как Павел очень верно и здорово заметил, в данном случае технологии, можно сказать, дошли до того предела, когда противостоять этой технологии А зачем противостоять?

00:58:30 SPK_1
Для того, чтобы не утратить, собственно, какую-то свою личность, субъектность, вот как раз только увеличивая субъектность, можно противостоять это негативным, скажем так, последствиям.

00:58:44 SPK_1
внедрение искусственного интеллекта, и это, как уже, наверное, третий пункт, как говорит Павел, наверное, самое позитивное, что есть в технологии искусственного интеллекта.

00:58:56 SPK_1
Здесь у нас не остается выбора, либо быть человеком, либо раствориться в коконе из помощников.

00:59:05 SPK_1
Я сказал три сразу, наверное, это было много, но давайте по одному, Алиса.

00:59:13 SPK_3
Вы имеете ввиду откомментировать это?

00:59:17 SPK_1
Да, где мои выводы с вашими не соотносятся или где я слишком драматизирую, как Павел сегодня сказал, драма менеджмент, что-то такое сегодня прозвучало.

00:59:27 SPK_1
Да, то есть у нас, мы далеки от того, чтобы гоняться за хайпом, все пропало, все умрут.

00:59:34 SPK_1
Но все-таки кажется, что особенность этого момента развития технологий в том, что Ими занимаются люди не на том уровне, скажем так, мудрости.

00:59:46 SPK_1
Мы дали мечи подросткам и отпустили их, скажем так, гулять.

00:59:54 SPK_1
Есть большая вероятность того, что они не только друг друга покрошат, а скорее всего там войдут в город и будет там что-то нехорошее.

01:00:03 SPK_1
А мудрого предводителя нет.

01:00:08 SPK_3
Это знаете, как с Суперменом в Утро проехали есть, но кто вам сказал, что у него те же ценности, что у вас?

01:00:15 SPK_3
Но я тогда попытаюсь коротко сказать, чтобы забавно было, завершающее слово.

01:00:22 SPK_3
Безусловно, большинство...

01:00:25 SPK_3
Я не могу сказать, что вот, да, там в компаниях сидят люди, которые совсем не понимают, что они делают.

01:00:33 SPK_3
Да, вот реально физически возможных пределов того, что можно понимать, понимают.

01:00:40 SPK_3
Какая-то математика нам еще не совсем понятна, но, наверное, мы ее поймем.

01:00:46 SPK_3
Другое дело, что те люди, которые в этом разбираются действительно хорошо, довольно часто выходят на конференции и произносят как бы спички про то, что «ребята, нам нужно ответственно, нам нужно это вот так вот делать».

01:01:02 SPK_3
Мне всегда хочется спросить, к кому вы обращаетесь?

01:01:05 SPK_3
Не люди, которые вас слушают, смогут что-то с этим сделать.

01:01:09 SPK_3
Это как в той шутке, а если оно выйдет из подконтроля? А вдруг оно выйдет из подконтроля?

01:01:13 SPK_2
Что значит вдруг?

01:01:14 SPK_3
Конечно выйдет, мы тут все работаем на это.

01:01:18 SPK_3
И другое дело, что я думаю, что люди, которые обладают более глубоким пониманием, у них, судя по каким-то совсем небольшому количеству информации, которую я получаю от внутренних знакомых или каких-то уж совсем посторонних, опять же, как вы говорите, файл папочек не заносят, деформация ментальная, которая происходит у людей, которые с этим действительно взаимодействуют каждый день, она на уровнях, я думаю, которые мы даже и не представляем.

01:01:55 SPK_3
Вот, то есть даже те, у кого, я думаю, есть там, да, какой-то и наработанный философ, там, да, философский инструментарий, ценностный инструментарий, я думаю, что им нереально в таком окружении, в такой ситуации, с такими задачами действительно там, да, сохранять холодную голову.

01:02:17 SPK_3
То есть я предполагаю, что они, наверное, даже пытаются сделать что-то максимально хорошее, но там, да, вышло, а выходит, выходит, как всегда.

01:02:27 SPK_3
Кстати, вот Ян Лекун, которого я люблю слушать, потому что он уже, в общем-то, вышел из такой большой корпоративной игры, поэтому может себе позволить сказать гораздо больше.

01:02:39 SPK_3
Он, правда, отвечал на вопрос, что сделать, чтобы я и нас не уничтожил, но, на мой взгляд, может быть, это и можно применить, да, в какую-то такую более хорошую среду.

01:02:49 SPK_3
Он тут, говорит, слушайте, если мы говорим про ситуацию, когда у нас есть более глупое существо, человек, и более умное существо, да, там вот AGI, которое мы вдруг можем создать, не дай бог, вдруг в этот день, в этот час он появится у этой команды, то давайте мы сделаем ценности материнские, потому что мы вот знаем только один биологический случай, когда более умное существо готово там, да, щадить и как-то воспитывать и давать какой-то конструктивный фидвек более глупому существу.

01:03:24 SPK_3
Вот, но он это говорил с точки зрения, чтобы не уничтожило.

01:03:27 SPK_3
с нашей стороны, если сделать я достаточно занудным, неприятным, и это сделать как абсолютную необходимость для всех инструментов, может быть, как-то удастся допинать нас до чуть более лучшей ситуации, но, ну, как Элифаев говорит, можем, но не будем, поэтому я думаю, что Мы тут уже действительно в такой очень нехорошей ситуации, с которой, скорее всего, если говорить на таком более историческом пласте, из которой нас может вытащить, ну, только, скорее всего, что-то очень радикальное, что прямо, да, встряхнет нас.

01:04:15 SPK_3
Вот. На этом завершу свой комментарий.

01:04:18 SPK_2
Ну, после таких прекрасных завершений буквально два коротких комментария. Первый.

01:04:23 SPK_2
Вспоминаем детскую сказку которая не очень детская. Лисы в стране чудес.

01:04:27 SPK_2
И иногда, чтобы стоять на месте, нужно бежать в два раза быстрее.

01:04:31 SPK_2
Вот на фоне развития наших вот этих магических артефактов, которые я теперь однозначно буду называть такими методами, бежать нужно даже и в два, может быть, по экспоненте быстрее.

01:04:42 SPK_2
И в этом я вижу оптимистическую провиденческую работу.

01:04:46 SPK_2
А то мы слишком долго прятались за разными технологическими, скажем так, идолами.

01:04:53 SPK_2
считая себя их господами, ну наконец-то мы создали голема, или создаем в процессе, чисто под прекрасные лозунги, с прекрасными технологическими возможностями, которые вопрос, собственно, нашей, прежде всего, на самом деле, этической субъектности, уже во вторую уровень и когнитивно-эмоциональную субъектность, ставит перед тем самым большим-большим зеркалом Которое нам и должно показать.

01:05:19 SPK_2
Первое, то, что мы-то уже сами по себе почти-таки очень голенькие стали за последние 400 лет.

01:05:24 SPK_2
Ну ладно, все кроме Алиса. Мы с Евгением однозначно. И тут два варианта.

01:05:31 SPK_2
Либо уж совсем залезать в эту капсулку, как в фильме Матрица, либо все-таки уже искать одежду, основание.

01:05:39 SPK_2
Тренировать себя.

01:05:41 SPK_2
То есть это то самое внутреннее усилие подменять свое самоволие настоящим самовластием.

01:05:46 SPK_2
То есть вот такого вот спрятаться не удастся. Такой себе вывод, который я сделал.

01:05:52 SPK_1
Ну что ж, отличное завершение. Спасибо, Алиса. Прежде всего, спасибо, Павел.

01:05:57 SPK_1
Я думаю, что мы, по крайней мере, постараемся ещё вернуться к этой теме вместе с Алисой и Павлом.

01:06:05 SPK_1
Ну а для тех, кто слушает или смотрит нас, пожалуйста, оставляйте свои комментарии.

01:06:12 SPK_1
Дополняйте нас, мы будем рады услышать мнение тех людей, особенно кто находится в этой индустрии и сможет рассказать нам о том, что мы не знаем, например, или поделиться какими-то своими размышлениями, которые нас дополнят.

01:06:31 SPK_1
Всем еще раз большое спасибо, ну и до встречи.

01:06:35 SPK_2
До встречи.
