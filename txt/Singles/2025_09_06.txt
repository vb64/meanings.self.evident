

00:00:00 Евгений Голуб
Компьютер. Ну что ж, да, прежде чем мы начнем, Павел, кстати, забыл еще задать вопрос.

00:00:10 Евгений Голуб
Мы как будем это позиционировать, как продолжение наших подкастов или все-таки это будет отдельное у нас видео?

00:00:18 Павел Щелин
Я думаю, здесь лишнее позиционирование в отдельную коробочку на данный момент преждевременно.

00:00:25 Павел Щелин
Мы просто делаем интересные разговоры видео и продолжаем встречи на наших ресурсах.

00:00:32 Евгений Голуб
Так, хорошо. Тогда, что ж, начнем. Три, два, один, камера, запись. Здравствуйте, друзья!

00:00:44 Евгений Голуб
В эфире необычный выпуск ведущих подкаста «В поисках смысла» Евгения Голуба, Павла Щелина, и сегодня с нами приглашённый эксперт Алиса Ким.

00:00:59 Евгений Голуб
Мы решили записать этот выпуск, так как первый раз мы затронули тему искусственного интеллекта, а сегодня речь пойдёт о нём.

00:01:09 Евгений Голуб
Примерно год назад, может быть, немного больше, и с тех пор многое изменилось.

00:01:15 Евгений Голуб
Я бы так сказал, что изменилось практически всё.

00:01:18 Евгений Голуб
И для того, чтобы осмыслить происходящее, нам уже не хватает собственного понимания.

00:01:26 Евгений Голуб
Мы подозреваем себя в предвзятости. Для этого мы пригласили Алису.

00:01:31 Евгений Голуб
Алиса — эксперт в области искусственного интеллекта.

00:01:40 Евгений Голуб
Так, минуточку, я выключу свою Алису, потому что каждый раз на слово «Алиса» она будет включаться.

00:01:46 Алиса
Есть такая партия, да.

00:01:52 Павел Щелин
Рад видеть, если по-честному.

00:01:55 Алиса
Да, взаимно.

00:01:58 Алиса
Кстати, ковёр не дооценивайте, я думаю, что уже есть целое течение по интерпретации вашего бэкграунда.

00:02:05 Алиса
Я думаю, что ковёр уже — это там целое направление. Так в чём смысл ковра в творчестве Павла?

00:02:13 Евгений Голуб
Я говорю «Алиса» и такой «Эксперт». Журнал такой. На чём мы остановились, друзья мои?

00:02:19 Евгений Голуб
Хорошо, что мы записываемся.

00:02:21 Павел Щелин
Представляешь, ты Алису-то представлял, родной.

00:02:23 Евгений Голуб
Итак, мы пригласили Алису Ким, кандидата наук, эксперта по искусственному интеллекту.

00:02:30 Евгений Голуб
Алиса занималась академическими исследованиями в Гумбольд-Университете, точнее в Университете Гумбольда и в Стэнфордском университете.

00:02:40 Евгений Голуб
Алиса разрабатывала языковые модели в AWS, Amazon, что-то там, как оно дальше?

00:02:47 Павел Щелин
Веб-сервис.

00:02:48 Евгений Голуб
Веб-сервис.

00:02:49 Евгений Голуб
Ну и, в общем, последние 10 лет Алиса занимается внедрением искусственного интеллекта в разного рода системах, в стартапах и крупных корпорациях.

00:02:59 Евгений Голуб
Поэтому, ну, кому как ни к Алисе нам прийти с нашими вопросами и недоумениями.

00:03:06 Евгений Голуб
Ну что ж, начнем потихонечку. Итак.

00:03:10 Евгений Голуб
Я предложил сегодня разделить видео или роли в нашей встрече следующим образом.

00:03:17 Евгений Голуб
Как уже понятно, Алиса — наш эксперт, Павел — философ.

00:03:21 Евгений Голуб
Ну а я буду выступать сегодня в роли обычного пользователя разного рода и помощников, обычного обывателя, которых много и у которых есть простые и незамысловатые вопросы.

00:03:35 Евгений Голуб
Начну я с этого такого простого вопроса к Алисе.

00:03:40 Евгений Голуб
Сегодня уже очень многие, включая меня, не мыслят в своей жизни без помощников, как мы их называем.

00:03:50 Евгений Голуб
У меня при запуске браузера запускается 6 штук сразу.

00:03:58 Евгений Голуб
И многие сейчас уже, собственно, ищут даже продукты через искусственный интеллект, через разного рода помощников.

00:04:09 Евгений Голуб
Так вот, вопрос следующего рода. Все-таки это полезная штука или за этим кроется что-то еще?

00:04:21 Евгений Голуб
Как вы считаете, насколько нагружены сегодняшние помощники скрытыми какими-то функциями, скрытыми намерениями с их создателей?

00:04:34 Евгений Голуб
Есть ли подвох в этой технологии?

00:04:39 Алиса
Наверное, начну с занудного полезного для кого и для чего.

00:04:45 Алиса
Для нас, как для пользователей, в наших жизненных целях, безусловно, на мой взгляд, полезная вещь.

00:04:53 Алиса
Но мы с вами находимся в такой сложной ситуации, когда абсолютно всё в этом продукте, по сути, оптимизировано для того, чтобы мы чуть-чуть сбились с курса, забыли о том, зачем мы делаем то, что мы делаем, и как это работает.

00:05:10 Алиса
Тут, если бы я должна была ответить на вопрос классический, ну так это хорошая вещь или плохая, я бы сказала.

00:05:19 Алиса
Хорошая, если мы будем пользоваться ей осознанно.

00:05:23 Алиса
И на этой части обычно все юзеры, я в том числе, говорят, ну если осознанно, то это уже слишком сложно.

00:05:33 Алиса
Что касается нагруженности, тут, на мой взгляд, всё банально и немножко грустно.

00:05:40 Алиса
Практически всё о том, как создаются эти помощники, зачем, с какими ограничениями, всё прописано, всё открыто.

00:05:51 Алиса
Я думаю, что там скрытых смыслов и скрытых идей тайных помыслов довольно мало.

00:05:58 Алиса
Другое дело, что мы как... Вы знаете, как никто не считает правила пользования.

00:06:03 Алиса
Все всегда все принимают и рад с этим дальше пользоваться.

00:06:07 Алиса
Другое дело, что мы с вами, наверное, никогда еще не сталкивались с инструментом, по сути, телевизорами, чайниками, любыми инструментами, доступными для рядового пользователя, которые были бы настолько сложны и настолько обманчивы, настолько сделаны для того, чтобы максимально с нашей головушкой помериться силами, запутать и вести в искус.

00:06:46 Алиса
Изначально же все эти системы, когда они стали популярны, никогда не стали точными, никогда не стали какими-то правильными с точки зрения даваемых ответов, а тогда, когда они стали настолько похожи на настоящего собеседника, что мы прямо вот включились в это.

00:07:09 Алиса
К сожалению, эволюционно мы очень... Мы и так-то любим всё антропоморфизировать.

00:07:17 Алиса
С компьютерами разговариваем, с телевизорами даём имена машинам и так далее.

00:07:21 Алиса
А тут оно ещё и разговаривает, и отвечает, и ещё и учится тому, что мы любим и не любим, и запоминает нас.

00:07:28 Алиса
Ну, то есть тут не начать с этим взаимодействовать нас и помощником, не как инструментом, ну, практически нереально.

00:07:35 Алиса
Даже если вот вы супер в подсознанке, скорее всего, там, да, через N дней и N пользований вы уже немножко забудете про то, как бы, да, зачем это было сделано, как это работает и так далее.

00:07:48 Алиса
На мой взгляд, пользы этого можно извлечь очень много.

00:07:51 Алиса
Другое дело, что с такими инструментами прямо вот совсем-совсем нельзя забывать, зачем я это делаю, какие у этого ограничения.

00:08:03 Алиса
Они все прописаны, они все понятные, но кроме тех, которые не прописаны, по идее, должны быть понятны любому человеку.

00:08:12 Алиса
Это коммерческий инструмент.

00:08:15 Алиса
Наверное, там есть какая-то доля того, что на вас хотят заработать, и ваше всеобщее благо мира, наверное, там не единственная цель.

00:08:24 Алиса
То есть, скорее всего, этот компонент тоже есть, но мы про это не очень любим помнить.

00:08:28 Алиса
А это влияет на то, как дальше развиваются эти системы. Вот такой, мой будет ответ. То есть.

00:08:37 Евгений Голуб
Штука, как любая технология, всегда имеет скажу иначе искусственный интеллект как любой инструмент может быть использован по прямому назначению его плага или как кухонный нож можно резать мясо можно зарезать человека как технология книгопечатания можно печатать библию а можно порно рисуночки сдавать и здесь уже вопрос у меня к павлу Мы говорили с тобой год, наверное, и много больше назад о том, что движется, кажется, такое время, надвигаются времена, когда многое из того, что делает человека человеком, Годит, скорее всего, передано на аутсорс, искусственному интеллекту, и мы тогда с тобой видели риски того, что вот это вот творческое начало, чувства, эмоции начнут автоматизироваться, и, соответственно, в этой части есть риски для людей потерять свой компонент человечности, что ли.

00:09:57 Евгений Голуб
Что ты думаешь по этому поводу?

00:10:01 Павел Щелин
Еще раз всем здравствуйте. Ну, думаю много чего. Тут даже не знаешь с какого конца подбираться.

00:10:08 Павел Щелин
Первое, все-таки сделаю базовые комментарии для фиксации собственной позиции по твоему преамбуле.

00:10:16 Павел Щелин
Про вот кухонный нож и прочую всю вот эту историю.

00:10:20 Павел Щелин
Дело в том, что вот с этой позиции я философски не согласен.

00:10:24 Павел Щелин
Мне представляется, что само представление существования такого феномена, как нейтральная технология, является глубоким заблуждением.

00:10:33 Павел Щелин
Не существует такого феномена, как нейтральность технологии.

00:10:37 Павел Щелин
С самим фактом своего существования технология не нейтральна. Она создает ассиметрию.

00:10:44 Павел Щелин
Банально между теми, кто технологией пользоваться умеет и кто технологией пользоваться не умеют.

00:10:51 Павел Щелин
Те, кто технологией пользоваться умеют, получают дополнительные ресурсы, власть, способ взаимодействия с миром относительно тех, кто ей не пользуется.

00:11:02 Павел Щелин
эту асимметрию ты никаким образом... Вот это и есть собственно сама технологическая асимметрия.

00:11:09 Павел Щелин
То, что ты говоришь уже про волевой этический выбор субъекта, использующий технологию, это следующий этап, это следующий уровень.

00:11:17 Павел Щелин
Но сначала есть вот этот базовый уровень, что самим фактом своего бытия технология мир меняет.

00:11:24 Павел Щелин
И вот наше представление о ней как о некой нейтральности это очень хороший sales point для любого, скажем так, маркетолога, но с философской точки зрения просто он неадекват.

00:11:35 Павел Щелин
Это первый момент. Второй момент связан с... Подожди, минуточку, ты.

00:11:39 Евгений Голуб
Же знаешь, я обычно тебя прерываю, уже прости, но ты знаешь, мне кажется, нужно объяснить, что такое твой тезис о том, что самим фактом существования технология меняет мир.

00:11:53 Евгений Голуб
Логическая связь здесь не очевидна, по крайней мере, для меня.

00:11:59 Павел Щелин
Ну, давай самое простое.

00:12:01 Павел Щелин
Вот если пока этой технологии не было, у тебя была определенная культура и определенные, если условно, паттерны, уж простите, не знаю, как там, вечно...

00:12:11 Павел Щелин
независимость. Закономерности некоторые.

00:12:14 Павел Щелин
Закономерности отношений между людьми, отношений экономические, социальные, политические и так далее, как ты ни крути.

00:12:23 Павел Щелин
Вот когда технология появилась, она стала фактором всех этих отношений просто по факту своего появления.

00:12:29 Павел Щелин
Еще никакой воли нет, но она создала дополнительные возможности.

00:12:33 Павел Щелин
Повторюсь, главная эта возможность, я ее назвал, это возможность к власти.

00:12:38 Павел Щелин
Любая технология содержит в себе заряд к власти. Но это логично.

00:12:43 Павел Щелин
Если бы она его не содержала, ее бы никто не создал. Это вот очень важно понимать.

00:12:47 Павел Щелин
То, что в нашем культуре технология всегда создается, на самом деле, с неким зарядом к власти.

00:12:56 Павел Щелин
Тот, кто, банально, власть работы, в нашем конкретном примере, власть манипулирования, власть работы с данными.

00:13:02 Павел Щелин
власть, производство дополнительного материального ресурса и так далее. Это все властные отношения.

00:13:08 Павел Щелин
И вот эта технология, ты можешь сказать, если тебе уточнить, ну до поры до времени можно сказать, что она создается с технологией как минимум потенциальной власти.

00:13:16 Павел Щелин
То есть она лежит и спит, и да, требуется волевой субъект, чтобы эту власть активизировать, но тем не менее потенциал-то уже создан самим фактом ее появления.

00:13:24 Павел Щелин
То есть некая статус-кво оказалась нарушена. Все.

00:13:27 Павел Щелин
То есть изобретение автомобиля, вне зависимости от намерений конкретного изводчика, конкретного водителя или производства автомобиля, самим фактом, называя технологией, является угрозой, условно говоря, для коневодов.

00:13:40 Павел Щелин
Она меняет эти отношения автоматически, просто по факту своего появления.

00:13:46 Евгений Голуб
Технология может существовать, продукта может не быть.

00:13:51 Павел Щелин
Я поэтому уточнил про потенциальное. Ну, давай так, ты прав. Как минимум потенциальное.

00:13:59 Павел Щелин
С философской точки зрения я веду категорию потенциальное.

00:14:02 Павел Щелин
изменения, но просто мы живем еще в цивилизации последние 400 лет, где любое потенциальное изменение в зоне технологии прогресса должно быть актуализировано.

00:14:10 Павел Щелин
У нас нет никаких этических ограничений на любую технологическую актуализацию.

00:14:15 Павел Щелин
Это, собственно, ради этого модерн мы и создавали.

00:14:18 Евгений Голуб
Мы говорим о том, что в модерне каждая технология прежде всего рассматривается с точки зрения возможности увеличить властный потенциал субъекта, обладающего этой технологией.

00:14:32 Павел Щелин
Субъекта, обладающего этой технологией, да.

00:14:34 Павел Щелин
А в любой технологии всегда, и до модерна, и после модерна, и вне модерна, ну всегда содержится увеличение потенциала субъекта.

00:14:43 Павел Щелин
Ну это понятно. Простой пример.

00:14:45 Евгений Голуб
Усиление, да?

00:14:45 Павел Щелин
Усиление. Ну я не могу бегать как гепард.

00:14:48 Павел Щелин
Но с машиной я могу перемещаться со скоростью, которой гепарду и не снилось.

00:14:53 Павел Щелин
Мой потенциал в категории беганье, она усиливает. Она поэтому и создана.

00:15:00 Евгений Голуб
Теперь, я тебя прервал, может быть, ты сделаешь шаг назад и вернешься к своему первому тезису?

00:15:06 Павел Щелин
Да. Чтобы я его вспомнил. Он связанный с первым тезисом, и это проблема асимметрии последствий.

00:15:14 Павел Щелин
Другими словами, это вот был бы мой вопрос к Алисе следующий, если она попробует.

00:15:19 Павел Щелин
Мне просто интересно, как вообще, есть ли размышления на эту тему.

00:15:23 Павел Щелин
Приведу пример не с искусственным интеллектом, но близкий.

00:15:26 Павел Щелин
У нас есть технологии социальных сетей, выпущенные относительно недавно, буквально 15 лет назад.

00:15:33 Павел Щелин
Сейчас начали выходить исследования Айнейра об изменениях на материальном уровне мозга молодых, особенно детей, подростков, девочек, которые 10 лет выросли на этих технологиях.

00:15:45 Павел Щелин
Скажем так, исследование, мягко говоря, тревожище. То есть там много разных неприятных последствий.

00:15:52 Павел Щелин
Но я сейчас говорю не про это. Я говорю про то, что вот у нас есть асимметрия.

00:15:55 Павел Щелин
Технология выпущена была 10 лет назад. Последствия от нее пришли 15 лет.

00:16:00 Павел Щелин
И что-то я сомневаюсь, что 15 лет назад, когда люди, когда выпускали эти социальные тети, вообще хоть на каком-то этапе выпуска этой технологии задумывались о последствиях через 15 лет.

00:16:10 Павел Щелин
Это ее структурное ограничение.

00:16:12 Павел Щелин
То есть По крайней мере, в нашей культуре, где скорость, повторюсь, не повторюсь, скажу в новой тези, что скорость является благом сама по себе.

00:16:20 Павел Щелин
В принципе, идея торможения, движения, особенно технологического, является ересью и харамом.

00:16:28 Павел Щелин
Поэтому у меня есть вот большой вопрос, то что в рамках вот этой технологической семьи, то есть Бедный наш звуковик.

00:16:36 Павел Щелин
То есть, смотри, проблема технологической асимметрии последствий существовала всегда.

00:16:40 Павел Щелин
Собственно, мы это знаем со времен ящика Пандора. Миф ящика Пандора ровно про это.

00:16:45 Павел Щелин
Принесли огонь, а потом выпушил, как-то получился ящик.

00:16:49 Павел Щелин
Это вот очень классическая взаимосвязанная история.

00:16:52 Павел Щелин
Но сегодня мы просто повысили масштабы, скажем так, этой проблемы до определенного уровня, который в каком-то смысле количественно действительно является беспрецедентом.

00:17:02 Павел Щелин
Это вот такая моя занятка, зарубка на полях.

00:17:05 Павел Щелин
Мне просто интересно, как изнутри вообще ставится ли так вопрос, вот по-честному, не на уровне красивых презентаций, а как внутреннее самоощущение.

00:17:15 Евгений Голуб
Прежде чем Алиса ответит, Алис, сейчас солнце вышло, и у вас лицо делится пополам.

00:17:22 Евгений Голуб
просто там тень и она прямо пополам.

00:17:24 Павел Щелин
Разделяет и с такой делом лучше так.

00:17:31 Алиса
Надо лучше я надеюсь что она зайдет нет окей будем так вот так это.

00:17:40 Евгений Голуб
Так хорошо да так отлично Имеется в.

00:17:43 Алиса
Виду вопрос, насколько обсуждается и насколько озабочены компании, разрабатывающие, ну не будем говорить и скажем пока что, да, большие языковые модели, потому что там много всего другого еще есть радостного и интересного, вот, насколько озабочены последствиями.

00:18:02 Алиса
Я не возьмусь говорить, конечно, за всех гигантов индустрии, но в целом я думаю, что можно сделать такую усреднённую позицию, сформулировать.

00:18:19 Алиса
Есть философская, идеалистическая воля их основателей, CEO, ведущих учёных, которые Все как один пишут и, скорее всего, действительно думают о том, что они бы очень хотели сделать мир лучше.

00:18:39 Алиса
Да, то есть их позиции почти всегда такие очень публичные.

00:18:44 Алиса
Я думаю, что они действительно в это верят. Есть то, как это работает внутри.

00:18:51 Алиса
В целом, почти все негативные последствия, которые вызывают эти продукты, они практически всегда важны только когда они коротковременные и влияют на два самых важных фактора, которые в свою очередь влияют на то, довольны инвесторами или нет, а по сути это К сожалению, тот единственный драйвер, который важен, в силу, кстати, того, что вы сейчас сказали о скорости, потому что сейчас у абсолютно всех участников рынка 100% уверенность в том, что вот сейчас мы в этой точке бифуркации.

00:19:30 Алиса
Тот, кто успеет и возьмёт рынок, тот будет править следующие 100 лет.

00:19:36 Алиса
Ещё хорошо бы, чтобы хотя бы в нашей стране есть же ещё китайцы, русские и все остальные.

00:19:41 Алиса
Дальше посмотрим. Сейчас главное нужно успевать.

00:19:47 Алиса
Для этого нужно очень много денег на самые разные вещи. Что не любят инвесторы?

00:19:53 Алиса
Инвесторы не любят, когда по рукам дают регуляторы, и инвесторы не любят, когда сильно жалуются и отпадают пользователи.

00:20:01 Алиса
Вот если кто-то из них усмотрел непосредственный вред в каком-то виде, сумел это довести до точки, когда реально уже наступает прессинг на компанию внести какие-то изменения, то тут, а, компания может официально как-то позицию заявить.

00:20:19 Алиса
То есть, например, сейчас у всех компаний прописаны их, условно говоря, ценности и ориентиры.

00:20:26 Алиса
Например, OpenAI — это вот мы хотим, чтобы мы были helpful, но no harm и maximize utility — вот это их такая общая тема.

00:20:35 Алиса
И это влияет на то, что они реально внутри пытаются делать для того, чтобы как-то ограничить негативные, например, вот этот no harm обеспечить.

00:20:44 Алиса
Но в целом есть, к сожалению, такая неприятная история, такой конфликт интересов, что это, знаете, как для принципиального человека уломать на что угодно гораздо сложнее.

00:20:55 Алиса
Вот модель, у которой слишком много ограничений, она, скорее всего, будет не так хорошо, красиво работать.

00:21:02 Алиса
Ее тренировать дороже, ей могут быть недовольны пользователи, и поэтому в целом мотивации реально усложнять эту историю у компании нету никакой.

00:21:12 Алиса
Вот только вот те два фактора, которые я сказала, да, там регулятор... Я просто.

00:21:16 Павел Щелин
Еще... Простите, что немножко перебил, но просто хочу подчеркнуть.

00:21:21 Павел Щелин
Это еще мы находимся в очень, на самом деле, маленьком кружочке. Я этот вопрос задал гораздо больше.

00:21:26 Павел Щелин
То есть вы, по сути, подчеркнули проблему...

00:21:30 Павел Щелин
я бы сказал, ну, некого knowable harm, то ли какой-то, ну, который ты получаешь информацию об этом вреде через вот этот фидбэк-клуб некий, да, и ты хоть какую-то информацию получаешь.

00:21:41 Павел Щелин
Я же постулировал вопрос более радикально, потому что, как в примере с этих социальных сетей, я ни за что не буду утверждать, что у людей, которые вводили социальные сети как корпоративный метод в середине двухтысячных, было намерение сломать психику девочкам-подросткам в 2025 году.

00:21:59 Павел Щелин
То есть, вот тут основная проблема в том, что есть огромная сфера того, что мы не знаем о технологическом последствии.

00:22:08 Павел Щелин
Мы в теории могли бы попытаться об этом думать, как, не знаю, категория философского риска, промышления.

00:22:14 Павел Щелин
Но, как я понимаю, из вашего описания, разумеется, не по причине некого зла, а по причине той системы, скажем так, мотивации к действию, такой вопрос в принципе никто не ставит.

00:22:24 Павел Щелин
Если последствия будут через 15 лет, нас это вообще никаким образом сегодня не волнует.

00:22:29 Алиса
Про это пытаются думать и даже нанимают дорогостоящих исследователей, образовывают целые, да, там, финк-тэнки внутри компаний, и они даже публикуют, ну, желательно, не сильно, конечно, радикальные работы, но вот показать социальную ответственность очень надо, но нет времени и денег у компаний сейчас об этом думать.

00:22:51 Алиса
Разве что какие-то более независимые институты могут пытаться делать какие-то проекты, они их делают, но Нет времени, возможности, слишком велика конкуренция, слишком велик прессинг.

00:23:07 Павел Щелин
Нет времени объяснять.

00:23:09 Алиса
Да, да, да.

00:23:10 Павел Щелин
Именно так. Евгений, вы с нами?

00:23:14 Евгений Голуб
Друзья, минуточку, минуточку, минуточку, минуточку. У меня, кажется, возникла техническая проблема.

00:23:20 Евгений Голуб
Вы меня слышите?

00:23:21 Павел Щелин
Мы вас слышим, и ты завис в задумчивом виде.

00:23:26 Евгений Голуб
Так и есть. Я действительно завязываю с этим, что видите. Сейчас я попытаюсь его разморозить.

00:23:34 Евгений Голуб
К сожалению, сейчас у меня болезни роста.

00:23:37 Алиса
Я пока себе позволю, кстати, комментарий, Павел, по поводу того, что вы сказали, что это не нейтральная технология.

00:23:45 Алиса
Эта технология и не подается как нейтральная, она подается очень эффективно.

00:23:50 Павел Щелин
Расскажите про это. Это очень важно. Это очень важная история.

00:23:54 Алиса
На самом деле. Тут, безусловно, нам не продают просто так нож.

00:24:00 Алиса
Нам продают систему, вокруг которой построено огромное количество утверждений, да, прокламаций.

00:24:08 Павел Щелин
Алиса, вот все, что хотите сказать на эту тему, пожалуйста, когда вот сейчас запись будет, потому что это прекрасно и необходимо.

00:24:16 Павел Щелин
Да нет, просто это самое-то и есть. Это в общей тезис выйдет.

00:24:20 Павел Щелин
Ну, то есть, просто мне интересно, как это воплощается в вашем случае.

00:24:24 Павел Щелин
Тезис о ненависти к технологии мы с вами разбирали, в том числе на наших встречах.

00:24:29 Павел Щелин
А это главная наша, как бы, идея, которая движется в наше общество, что технология сама по себе нейтральна, и только вопрос воли, как она будет использована.

00:24:40 Павел Щелин
Это вот философски не так просто. Просто интересно, как сейчас это воплощается. Евгений, ты с нами?

00:24:47 Евгений Голуб
Сейчас, минуточку. Меня уже видно?

00:24:49 Павел Щелин
Ну, видно.

00:24:50 Евгений Голуб
Слышно и слышно.

00:24:52 Павел Щелин
Слышно.

00:24:53 Евгений Голуб
Прошу прощения, тут возникли серьезные проблемы типа того, что компьютер мой разрядился.

00:25:01 Евгений Голуб
Надо его найти. У меня всего два USB-C этих самых выхода.

00:25:07 Евгений Голуб
Один включена звуковая карта, другой телефон, и в общем пришлось чем-то пожертвовать. Итак.

00:25:14 Павел Щелин
Так вот, у Алисы был прекрасный комментарий. Давай сделаю хлеб.

00:25:16 Павел Щелин
Алиса, вот прям как сказали, Павел, а вот вы сказали и прямо начинаете.

00:25:22 Алиса
Павел хотел отдельно прокомментировать то, что вы сказали касательно нейтральности технологии.

00:25:27 Алиса
Мы здесь, безусловно, не имеем дела с технологией, которая даже подается как нейтральная.

00:25:34 Алиса
То есть, во-первых, большинство этих решений подаются с очень громким информационным бэкграундом того, что мы это делаем ради того, чтобы человечество тут лучше жило, чтобы вам, дорогие пользователи, дать свободу, то есть там OpenAI, он же freedom to the users, он прямо это обещает, да, то есть потом уже появляется safety и так далее, но это в целом подается очень агрессивно, как это прям вот то, что сейчас вам всем сделает лучше.

00:26:07 Алиса
И для того, чтобы этой технологии пользоваться действительно максимально осознанно, максимально возможно и безопасно, то тоже нужно найти третий ход слева за трактором, повернуть направо и желательно отключить вот этот вот еще функционал, вот эту информацию не давать, а вот здесь еще перезагрузиться.

00:26:28 Алиса
И тогда в целом, наверное, будет чуть получше.

00:26:33 Алиса
Уровень сложности, количество сальто, которое нужно сделать, чтобы действительно эта технология для вас, когда пользователя, была нейтральной, бесчестно велик для того, чтобы утверждать, что это вот, да нет, ну как бы мы же вам все по-честному дали, это все вы, это ваше пользование дало вам плохие результаты, это не мы.

00:26:57 Алиса
Тут ну нужно просто это по-честному отметить.

00:27:00 Евгений Голуб
Ну, у меня будет два комментария. Первое.

00:27:02 Евгений Голуб
Так как я постоянно рассказываю о том, что человек выходит из корпоративного мира, то я знаю цену всем вот этим корпоративным миссиям, видению и всему остальному.

00:27:13 Евгений Голуб
Цена эта не очень высока. Это всё, в общем, известное лицемерие.

00:27:21 Евгений Голуб
И во главе угла всегда стоят только деньги. деньги и власть.

00:27:30 Евгений Голуб
Поэтому если на пути у топ-менеджмента становятся какие-то не вполне, скажем так, очевидные или сомнительные свойства продукта, то топ-менеджмент всегда, повторяю, всегда, прежде всего, попытается добиться максимального финансового результата конечно же, с одной стороны, снижая риски для себя, и главным образом, как бы кто об этом ничего не узнал, или как бы чего не вышло, а уже потом, как ничего не вышло с точки зрения пиара, а уже потом будет думать о всех этих миссиях и видениях.

00:28:06 Евгений Голуб
Миссии и видения нужны для того, чтобы себе, там, красиво выступать на конференциях и сорвать аплодисменты.

00:28:15 Евгений Голуб
Это первый комментарий.

00:28:16 Евгений Голуб
Поэтому наличие в Antropic, да, миссии и видения, меня совершенно не успокаивает, а даже, скорее, наоборот, говорит о том, что если такое миссию видеть, значит, точно там где-то что-то не так.

00:28:28 Евгений Голуб
Это первое. А второе, это наблюдение за нашими лидерами мнений.

00:28:36 Евгений Голуб
вот этими замечательными гениями технологическими, вроде Сэма Альтмана, который, как мы уже говорили с Павлом, в своем послании «Городу и миру» заявил о том, что мы в двух шагах от райских кущ, которые нам произведет искусственный интеллект.

00:28:54 Евгений Голуб
И при этом он перечислял какие-то такие, скажем так, свойства искусственного интеллекта и приведет такие доводы, которое можно, наверное, оглянувшись назад, было бы услышать от изобретателей, не знаю, электрических двигателей, стиральных машин, паровозов и так далее, и так далее.

00:29:14 Евгений Голуб
То есть кажется, что, дружище, ну как бы, что ж ты повторяешь-то все одно и то же?

00:29:19 Евгений Голуб
Ну как изменилась жизнь обывателя к лучшему? за счёт технологии. Она стала комфортнее, да, и что?

00:29:25 Евгений Голуб
И к чему это привело?

00:29:26 Евгений Голуб
А теперь твоя технология отнимает у него последний шанс к творчеству, как мне кажется.

00:29:32 Евгений Голуб
Алиса, ваши комментарии как человека близко к корпоративному миру, ну и, конечно же, Павла хотела бы послушать.

00:29:39 Алиса
Ну я здесь, наверное, скажу, а теперь пару слов в апологию всей этой истории.

00:29:48 Алиса
Нужно просто сказать, что даже если внезапно самые альфаны, маркет-сукерверги этого мира решат, всё, давайте, ребята, забудем про деньги, будем заниматься, вот прям вот действительно постараемся, чтобы наши, да, там, ЛЛМы, наши Клоды, наши чаты ЧПТ, они прям были, да, там, сели, разумные, добрые, вечные и так далее.

00:30:11 Алиса
Вот прямо вот сейчас, эх, мы возьмёмся.

00:30:14 Алиса
Я здесь, конечно, не скажу за прямо вот совсем, да, вот этот bleeding edge того, что существует.

00:30:23 Алиса
Но в целом, насколько мне известно, даже если мы очень сильно захотим, наши границы возможного для того, чтобы действительно заставить моделей, если только мы их не превратим вот в попок, которые вот если тебе спросили это, отвечай это, мы просто не можем.

00:30:43 Алиса
точно быть уверены в том, что модели будут действовать так, как нам надо, что они будут обладать теми… точнее, не обладать, а демонстрировать то поведение, те там ценности, которые мы вот в них хотели заложить, исходя из своего представления о том, как это должно быть, и исходя из фидбэка юзеров, чтобы им тоже не навредить.

00:31:05 Алиса
Мы здесь просто ещё технически ограничены, несмотря на то, что ограничения, разные степени контроля, направления этих моделей.

00:31:20 Алиса
Они закладываются на целом ряде разных шагов, которые происходят во время тренировки, подготовки, тюнинга этих моделей, пользования уже этими моделями.

00:31:32 Алиса
Мы на всех этих шагах довольно сильно ограничены.

00:31:37 Алиса
Хочу здесь просто так же оговориться, что есть некий потолок того, что мы можем сделать.

00:31:42 Алиса
И даже если вы тысячу раз спросите модель, ну вот если тебе попросят рецепт коктейля молотого, ну например, или спросят самый лучший способ сделать что-нибудь нехорошее, ты же ничего не ответишь.

00:31:56 Алиса
Тысячу раз модель отвечает, ну конечно ничего не отвечу, нельзя тысячи первыми может ответить.

00:32:03 Алиса
Наша личная степень контроля, несмотря на то, что она очень велика, и, конечно же, вообще мы целиком формируем то, как эти модели, какую информацию они выдают, как действуют, как принимают решения, мы всё равно довольно сильно ограничиваем.

00:32:19 Алиса
Нужно это сказать.

00:32:20 Евгений Голуб
Послушайте, ну среди обывателей, скажем так, распространено две крайние точки зрения.

00:32:28 Евгений Голуб
С одной стороны, да что вы там мне рассказываете про этот искусственный интеллект?

00:32:31 Евгений Голуб
Ангелицунили — это вообще-то продвинутая Т7, да? Что такое подсказыватель букв?

00:32:35 Павел Щелин
Т9.

00:32:36 Евгений Голуб
Т9, извини, да, Т9, которые просто развили.

00:32:40 Евгений Голуб
А с другой стороны, господи, это магия какая-то, это вообще душа.

00:32:44 Евгений Голуб
Наконец-то меня кто-то понял, услышал. Не рассказывайте мне все ваши сказки про Т9.

00:32:49 Евгений Голуб
Это просто уже новая сущность какая-то, совершенно непредставимая раньше.

00:32:57 Евгений Голуб
И сейчас, Алис, то, что вы говорите, звучит как «мы вообще не понимаем, как это работает».

00:33:06 Евгений Голуб
Ну, как бы так, в целом, как будто понимаем, но до конца не можем предугадать, что вообще, говоря, получится на выходе.

00:33:13 Алиса
Не можем. Есть огромное ограничение в том, что, да, там называется, объяснимость сетей.

00:33:20 Алиса
То есть, если мы спросим даже самую суперпродвинутую модель, а почему вот ты думаешь, что это плохо, мы не можем быть уверены, что она нам отвечает честно и что она дала какой-то ответ именно потому, что вот она думает так, как мы хотим, чтобы она думала.

00:33:37 Алиса
То есть, мы всё равно здесь взаимодействуем с очень высокой степенью неуверенности того, почему оно делает то, что оно делает.

00:33:45 Евгений Голуб
Вот так. Да. И мы как… Ну, вы говорите, оно думает. Оно вообще думает вообще?

00:33:51 Евгений Голуб
Там же, как я понимаю, идёт какой-то бесконечный, ну, огромный подбор вариантов в сочетании тех или иных смысловых знаков и так далее.

00:34:02 Евгений Голуб
Можно сказать, что оно думает вообще?

00:34:07 Алиса
М-м-м...

00:34:08 Алиса
С учётом того, что первые нейронные сети и вообще перцептрон создавался как моделька вот этого нейрона в голове, я думаю, что мы склонны использовать глагол «вроде думает», но нет, это последовательность неких математических действий, которые обусловлены оптимизацией, которая была проведена некими правилами, которые были вшиты в это всё во время тренировки модели.

00:34:37 Алиса
который приводит к тому, что модель отвечает что-то определенное.

00:34:41 Алиса
Но там этих вот ходов, которые не нами прописаны, а которые возникли сами в ходе тренировки, подготовки этой модели, их гораздо больше.

00:34:53 Алиса
То есть тут немножечко получается как такое...

00:34:56 Алиса
И опять же, да, то есть я сейчас буду использовать человеческие слова. Сознание под сознание.

00:35:02 Алиса
То есть какую-то часть мы контролируем и видим, а какую-то часть мы все еще не видим.

00:35:08 Евгений Голуб
Ну да, звучит все-таки немного жутковато, Павел.

00:35:13 Павел Щелин
Ну, мне кажется, возвращаясь к твоему первому вопросу, звучит жутковато, но оптимистично.

00:35:22 Павел Щелин
Объясню почему. Повод задуматься.

00:35:25 Павел Щелин
Мне это нравится, что на фоне всей вот этой искусственно-интеллектной истории актуализируется постепенный интерес к, ну, по-настоящему важным вопросам исхотологическим и антологическим.

00:35:37 Павел Щелин
Ну, мы все тут уже, мне тоже уже 20 человек переслали ссылки на лекцию Питера Тиля.

00:35:43 Павел Щелин
То есть, это тоже поразительное следствие об антихристе, поразительная черта нашей эпохи.

00:35:49 Павел Щелин
То есть, то, что говорит батюшка Самон, условно, тысячелетиями никому неинтересно, но тут Тиль.

00:35:54 Павел Щелин
четыре лекции сделает. Вау!

00:35:58 Павел Щелин
То есть, ничего не знаю о содержании этих лекций, просто интересно само вот это общественное восприятие.

00:36:03 Павел Щелин
И вот это мне...

00:36:04 Павел Щелин
и эта реакция, мне кажется, сама по себе свидетельствует о том, что вот это столкновение с вот этой...

00:36:10 Павел Щелин
Вот ты употреблял раньше слово магия, я бы на нем, честно говоря, остановился.

00:36:14 Павел Щелин
То есть, на каком-то уровне бытия это действительно магическая история.

00:36:20 Павел Щелин
Просто, если мы не ограничиваемся только материальными причинами, о чем нам весьма подробно рассказала Алиса, а подключаем к этому субъективный опыт взаимодействия пользователя с этой системой, то он действительно очень магичен в своем вот именно опыте.

00:36:35 Павел Щелин
Поэтому здесь как раз особых противоречий нет.

00:36:39 Павел Щелин
И перед этим самым пользователем, уверенным в себе и в своем интеллектуальном превосходстве над неорганической природой до недавнего времени, искусственный интеллект, конечно, ну, эти все модели ставят очень большой вопрос.

00:36:52 Павел Щелин
А ты, собственно, человек или нет? Что в тебе, собственно, человеческого?

00:36:56 Павел Щелин
А что ты готов пожертвовать, чтобы сохранить в себе некую человеческую особенность?

00:37:02 Павел Щелин
Здесь я объясню, я имею в виду сейчас даже не какие-то страшные пожертвования, а очень практические, но отсюда не менее страшные.

00:37:10 Павел Щелин
Начну издалека.

00:37:11 Павел Щелин
Классические примеры проблемы технологии, сформулирован По басикам нашим платоном, еще вот в знаменитом разговоре египетского бога Тот с жрецами, который жаловался на изобретение письменности.

00:37:25 Павел Щелин
Тоже к вопросу о нейтральности технологий.

00:37:28 Павел Щелин
Там бог Тот, если конкретно, жаловался на то, что вы сейчас писать научитесь, и саги, и священные тексты длиной в 15 тысяч строчек, условно, запоминать перестанете.

00:37:39 Павел Щелин
То есть вы потеряете способность это делать.

00:37:44 Павел Щелин
И вот в каком-то смысле любая технология несет себе эту угрозу.

00:37:47 Павел Щелин
А с письменностью в широком значении произошло действительно именно это.

00:37:52 Павел Щелин
Я уже молчу о том, что есть большая разница между научиться читать и научиться понимать текст.

00:37:57 Павел Щелин
Поэтому у нас отдельная проблема, то что разрыв между этими двумя, скажем так, феноменами нашей опыта тоже нами очень редко осознается.

00:38:09 Павел Щелин
Так вот, тем не менее, мы о себе думаем очень высокого мнения.

00:38:12 Павел Щелин
И тут ИИ ставит перед нами очень такую, на мой взгляд, радикальную задачу.

00:38:17 Павел Щелин
Вот как раз все не творческое, все построено на комбинаторике, все построено на запоминании даже количества беспонимания, я вот уточню некоторым, то есть количество информации и беспонимание сути этой информации, он действительно сделает лучше нас.

00:38:35 Павел Щелин
И это ставит нас действительно перед радикальным зеркалом, а собственно, повторюсь, кто-то есть.

00:38:40 Павел Щелин
Как бы могла бы выглядеть альтернативная вот практическая, скажем так, И это уже перехожу к части, где я немножко поговорю о том, что, мне кажется, можно делать.

00:38:49 Павел Щелин
Мне интересна тут не Алиса.

00:38:52 Павел Щелин
Но мыслим ли нам по-честному сценарий, что на каждый час использования интеллекта ради рациональных, усиления твоего могущества по организации собственного дня и приобретения дополнительно свободного времени, ты будешь тратить полтора часа Человек будет тратить полтора часа на запоминание стихов, саг, псалмов, там, как идеал.

00:39:15 Павел Щелин
Или прочтение бумажной книги.

00:39:17 Павел Щелин
Не потому, что это более эффективно, а для того, чтобы сохранить вот эту свою способность человеческого восприятия.

00:39:23 Павел Щелин
Вот это, мне кажется, есть вопрос, который сегодня стоит по-настоящему.

00:39:27 Павел Щелин
Другими словами, мне кажется, взаимодействовать с определенной субъектностью ИИ, и тут у меня еще не до конца понятно.

00:39:35 Павел Щелин
У меня есть пара гипотез, но я здесь их проверять не буду.

00:39:39 Павел Щелин
Относительно того, насколько ИИ является субъектным, тут, скажем так, разные есть мнения и у священников, и у философов, и у пользователей.

00:39:51 Павел Щелин
Ну, допустим.

00:39:52 Павел Щелин
Но в любом случае, очевидно, что взаимодействовать с этой машинкой можно только постоянно повышая субъектность собственную.

00:40:01 Павел Щелин
И вот в этом-то у нас проблема.

00:40:04 Павел Щелин
То, что вот эта вторая часть, наша уже культура, общество, да и само мышление о технологиях, ну вообще ни разу не поднимает.

00:40:13 Павел Щелин
Мы не ставим принципиально так вопрос. И для меня именно в этом-то и заключена главная опасность.

00:40:20 Павел Щелин
Да, технология, ну, мы в метафоре классической, это черт.

00:40:23 Павел Щелин
Причем, возможно, такой нынешний черт, он прям всем чертям черт.

00:40:27 Павел Щелин
Но, как говорят русские сказки, черта иногда можно попытаться оседлать.

00:40:31 Павел Щелин
Ну, как акула, летающая на черте за черевичками.

00:40:34 Павел Щелин
Но чтобы очертать этого черта, черта даже в сказках, ну, ты должен проявить субъектность больше, чем у этого самого черта.

00:40:41 Павел Щелин
А с субъектностью у нас коллективная напряжёнка. И вот как-то так я вижу эту проблематику. Евгений?

00:40:51 Евгений Голуб
Додумался я.

00:40:53 Евгений Голуб
В твоих словах этот образ Вакулы, оседлавшего чёрта, да, я уже его слышал, по-моему, на одном из твоих интервью.

00:41:03 Евгений Голуб
Интересный образ. Но получается так, что мы фактически становимся заложниками.

00:41:09 Евгений Голуб
Технологию не остановить.

00:41:11 Евгений Голуб
Уровень, скажем так, мудрости разработчиков искусственного интеллекта, на мой взгляд, довольно невысок.

00:41:22 Евгений Голуб
Капитализм нас толкает, логика капиталистического, отношение капиталистическое толкает нас к тому, что нужно максимизировать прибыль.

00:41:32 Евгений Голуб
Да, будут говорить про всех стейкхолдеров и нужно всеобщее, но давайте честно. Деньги решают.

00:41:43 Евгений Голуб
Деньги и власть по-прежнему решают.

00:41:46 Павел Щелин
И это значит... Дорогой Евгений, я ничего не говорил о коллективной. Давай так уточню.

00:41:49 Павел Щелин
Когда я это говорил, я это говорил прежде всего в индивидуальном порядке, но это первый момент.

00:41:55 Павел Щелин
Но второй момент, здесь есть очень интересный аспект, который я все-таки тогда тоже здесь закинул.

00:42:00 Павел Щелин
Связано, уж извини меня напрямую, с властью и вот этой драмократией.

00:42:04 Павел Щелин
Это к тому, что Алиса упоминала ранее, о страшных русских, американцах и китайцах.

00:42:09 Павел Щелин
Проблема в том, что с этими искусственными интеллектами на данный момент мы имеем очень интересный парадокс уже с точки зрения такой некой теории.

00:42:17 Павел Щелин
Метафорично все сейчас заняты выработкой меча, технологического меча.

00:42:23 Павел Щелин
Этот меч все оттачивают до такой степени, чтобы нанести первый обезоруживающий удар.

00:42:29 Павел Щелин
Ну как, это образно, да, то есть я не говорю, что прямо у всех есть такое намерение, но общее восприятие картинки идет примерно таково.

00:42:37 Павел Щелин
Плюс, да, делается словесная магия.

00:42:39 Павел Щелин
Ну, мы, наверное, говоримся об общих правилах, какая-то гарантия взаимного уничтожения. Чёртовство.

00:42:45 Павел Щелин
Ничего подобного вообще не происходит. Проблема-то в чём заключается?

00:42:50 Павел Щелин
В том, что щит находится вообще в другой области. Вот в этом, мне кажется, большой парадокс.

00:42:55 Павел Щелин
То есть обычно щит и меч должны находиться в одной топологии.

00:43:00 Евгений Голуб
Технология и технология, да?

00:43:03 Павел Щелин
Да. А у нас получается меч технологичный, а щит антропологичный.

00:43:10 Евгений Голуб
Да, вот это, я думаю, самое важное, что нужно понимать.

00:43:15 Евгений Голуб
Нет, технологии, которые можно противопоставить технологии искусственного интеллекта, потому что она затрагивает уже сущностные свойства человека как такового.

00:43:26 Павел Щелин
Да, то есть, единственный способ даже защититься вам, как государству, начальству и прочим, это иметь такое население, которое обладает антропологической защитой от технологического манипулирования.

00:43:37 Павел Щелин
Это, собственно, и есть то, что я описывал, как повышение антропологической субъектности в ответ на повышение технологического вызова.

00:43:44 Павел Щелин
Но тут тогда возникают очень неприятные последствия для всей нашей политической системы, о которых я говорю из эфира в эфир.

00:43:50 Павел Щелин
Алиса в курсе, и ты тоже, в принципе. Но другого выхода нет.

00:43:55 Павел Щелин
И мне кажется, в этом тоже есть определенная парадоксальная красота. Не мытьем, так катанем.

00:44:00 Павел Щелин
Понимаешь? Я понимаю.

00:44:02 Евгений Голуб
Ты говоришь о том, что, скажем, предыдущие технологии нас с вами пытались оскотинить, да, давая максимум комфорта и не стимулируя быть с людьми в полном смысле этого слова.

00:44:16 Евгений Голуб
А сейчас будет радикальный выбор.

00:44:18 Евгений Голуб
Либо ты уже совсем в предаток превратишься, к экранчику, либо станешь человеком.

00:44:24 Евгений Голуб
Но давай мы зададим слово нашему эксперту.

00:44:26 Евгений Голуб
Алис, ваши мысли по поводу слов Павла о том, что может противостоять технологии в данном случае?

00:44:36 Алиса
Ох, знал бы прикуп. Я себе позволю такое маленькое грустное отхождение.

00:44:48 Алиса
Очень любят во всех статьях про искусственный интеллект сейчас, конечно же, писать про Азимова, про три закона работы техники.

00:44:54 Алиса
Если, собственно говоря, почитать его вообще серию о роботах, там есть такая замечательная история, которая называется «Лжец», в которой им удалось создать робота, который читает человеческие мысли, и так как он не может людям вредить, то он им начинает врать напропалу, чтобы их чувство не задеть.

00:45:12 Алиса
То есть вред же может быть эмоциональный, и как только они это понимают, этого робота сразу же разбирают, потому что зачем человечеству такой робот?

00:45:19 Алиса
А вот мы его решили не разбирать, и ровно наши замечательные, в нашей исторической реальности мы такого робота всячески пытаемся дальше усовершенствовать, который нам рассказывает, дальше нас успокаивает и говорит, что все будет хорошо, и максимально пытается сделать нас счастливыми, не во благо нам же.

00:45:39 Алиса
Что касается такой геополитической да, геополитической составной части.

00:45:50 Алиса
Я думаю, Павел, государства дойдут до вашей мысли, если еще не целиком дошли.

00:45:55 Алиса
Пока что они находятся на точке чуть подальше, хотя бы, что уже ценно, хотя бы у жертв, хотя бы уже идет вопрос о ИИ суверенитете, да, то есть что происходит.

00:46:07 Алиса
Государства начали понимать, что если их граждане будут пользоваться разработками, например, да, американскими, то будет идти колоссальнейшая культурная манипуляция, ценностная манипуляция и так далее.

00:46:23 Алиса
То есть, не так много, но уже появляются работы на эту тему, наверное, моя любимая, которая использует эту карту с труднопроизносимым названием Ингельхарта Вельцеля, которая на осях выживания против общественного блага.

00:46:43 Павел Щелин
Коллективность, индивидуальность.

00:46:44 Алиса
Да, коллективность, индивидуальность.

00:46:46 Алиса
И там, в общем-то, показано, что все нынешние самые популярные сети, они так очень хорошо кластеризованы в смысле того, какие они дают ответы, как они себя ведут.

00:46:55 Алиса
Мы сейчас не говорим о том, что они там реально думают, о том, какие они дают ответы.

00:46:58 Алиса
Такие протестантско-нордические... протестантско-нордические кластеры.

00:47:03 Павел Щелин
Кто писал, тот воспроизводит.

00:47:07 Алиса
Кто платит, тот музыку заказывает. И в этом смысле, если...

00:47:12 Алиса
Там, да, например, гражданин Индии спросит у чьего-то JPT, там, напиши мне историю про мальчика, да, тот известный пример, который приготовил завтрак, то мальчик не будет, там, мальчик будет готовить тост и бекончик и яичнику, а не там, да, чапати.

00:47:30 Алиса
с ГИИ, со всем остальным, и вот этим сейчас очень сильно озабочено государство, и поэтому, например, такие страны, как Дания, Израиль и так далее, уже несколько лет назад прямо очень сильно встрепенулись, то есть уже хотя бы это они поняли, начали быстро-быстро собирать данные, формировать команды в свои государства для формирования тех моделей, которые будут соответствовать уже каким-то их представлениям, и даже некий успех там достигнут.

00:47:59 Алиса
Я целиком согласна с тем, что вы, Павел, обозначили как сложность, да, то есть щит в другой сфере.

00:48:11 Алиса
Я, честно говоря, кроме очень страшных исторических событий, не знаю примеров, когда людей реально что-то мотивировало резко перестать расслабляться, а начать собираться.

00:48:25 Алиса
а именно ментально от нас, по сути, требуется это для того, чтобы окончательно не потонуть в истории.

00:48:37 Алиса
И здесь, к сожалению, в целом у нас нет союзников. потому что даже корпорациям, которые...

00:48:47 Алиса
и это, кстати, такое тоже грустное осознание, например, когда люди говорят, ну вот я же, например, программист или дизайнер, и вот я в своей компании могу столько всего теперь сделать.

00:48:59 Алиса
На самом деле компании, и это вам скажет любой продавец SaaS-продукта, компании уже давно, наверное, 10 лет ненавидят слово «продуктивность» и под идеей продуктивности какой-либо продукт очень сложно, потому что это тяжело измерить.

00:49:14 Алиса
Если только вы не на заводе, тогда можете выпустить больше там, да, лампочек и так далее.

00:49:20 Алиса
К компаниям интересна целиком замена людей, потому что это является ключевым вот прямо таким.

00:49:27 Павел Щелин
Качественный скачок. Ну, качественный скачок.

00:49:29 Алиса
Качественным, да, значком.

00:49:31 Алиса
Поэтому все, что до этого, это они пытаются не отстать, но ждут, в общем, когда уже можно будет да, щелкнуть пальцами, несмотря на те заявления, которые там, да, делают кларны мира сего, что мы там столько-то людей уже сократили, или там амазоны, которые говорят, а мы не наймем теперь тысячу кодеров, потому что вот у нас есть, и это...

00:49:53 Алиса
Я себе позволю такое деткое замечание, что это просто звучит лучше, что мы должны сократить количество денег на персонал, потому что то, что мы пытались, наши инвестиции не оправдались других.

00:50:03 Алиса
области.

00:50:04 Алиса
Но на самом деле, как бы, да, мечта бизнеса, она скорее, ну вот, да, движется в этом, во всяком случае, большого бизнеса.

00:50:12 Павел Щелин
Смотрите, простите, перебью, просто это очень прекрасная же иллюстрация, то, что чистая идея.

00:50:18 Павел Щелин
Ну, то есть бизнес стремится к тому, чтобы оставить единственное...

00:50:22 Павел Щелин
Ну, то есть мы, видимо, то есть два варианта, по крайней мере, пока у нас не будет технологического коллапса, если он будет, то есть вот там с отключением электричества и прочего, мы приходим в точку, в которой единственная добавленная стоимость генерируется в зоне идеи творчества того самого.

00:50:39 Павел Щелин
все материальное воплощение стремится к полной автоматизации.

00:50:43 Павел Щелин
То есть, все материю стремится отдать на аутсорс, а, соответственно, единственная, в принципе, добавленная стоимость может быть именно сгенерирована в самой идее.

00:50:51 Павел Щелин
Идея нового приложения, идея нового продукта, идея чего-то и так далее и тому подобное.

00:50:56 Павел Щелин
Но тут-то возникает неприятная особенность, которую мы все знаем, что вот к такому генерации новых идей мы не то чтобы сильно были научены.

00:51:04 Павел Щелин
Большая часть работы от тебя вообще исторически не требовала ничего генерировать нового.

00:51:09 Павел Щелин
Она большая часть, ну особенно в индустриальном обществе, да?

00:51:12 Павел Щелин
И поэтому в этом плане корпоративная логика мне тут очень понятна.

00:51:15 Павел Щелин
Я просто хотел бы еще заострить, когда я говорил о вот этой гонке вооружений, для меня все-таки важно подчеркнуть, что на данный момент Вот то, что вы описываете, оно укладывается в нормальную государственную логику.

00:51:27 Павел Щелин
Они ж пока ищут технологическое решение, технологической проблемы.

00:51:31 Павел Щелин
Условно говоря, да, и проблема, но если мы создадим свои, если мы создадим гигантский прекрасный фаервол, который...

00:51:38 Павел Щелин
Если хотя бы будет наша проблема.

00:51:40 Павел Щелин
Это будет наша проблема, и мы ее, так сказать, героически уже будем с ней работать, мы эту штуку оседлаем.

00:51:46 Павел Щелин
А мой же тезис более радикальный, что как раз...

00:51:49 Павел Щелин
И вот здесь я подчеркнул оригинальность для меня ИИ, в том, что в принципе нету технологического решения этой проблемы в силу антропологического веса, антропологического масштаба давления этой технологии.

00:52:03 Павел Щелин
То есть, условно говоря, неважно, какой ИИ будет программировать мозги твоему населению, если оно будет сидеть по квартирам и ты его не заставишь не сделать ничего.

00:52:12 Павел Щелин
То есть, то есть, да, простите, да.

00:52:15 Павел Щелин
То есть, если наша цель — производить добавленную эту стоимость этим сверхтворческим субъектам, то тогда, получается, повторюсь, и в принципе, то есть, решения в принципе не находятся в этой зоне.

00:52:25 Павел Щелин
Если мы говорим о, допустим, более прикладных вещах, у нас же возникает целый комплекс проблем, о которых мы не говорили, но прикладные.

00:52:32 Павел Щелин
Когнитивная война, То есть, СИИ это уникальный пример, чтобы свести с ума население оппонента.

00:52:38 Павел Щелин
То есть, можно таргетировать. Что делать в обратную сторону, никто не понимает.

00:52:41 Павел Щелин
Ну, когнитивная война — это такая моя побочная тема. Можем уйти сюда. Но тут есть...

00:52:45 Павел Щелин
Все знают эту историю с телефонными мошенниками.

00:52:48 Павел Щелин
Только представьте, что это телефонный мошенник, который звонит реально голосом внучка, которого ты не отличишь, причем реально не отличишь.

00:52:57 Павел Щелин
Это вопрос, там, пяти лет. Когда он сможет делать такие запросы. И вот все вот эти первые полосы...

00:53:03 Павел Щелин
Но сейчас еще там есть такие шероховатости, можно еще, там он не полностью, по крайней мере массово, может быть в ваших лабораториях уже может, массово пока еще так себе.

00:53:14 Павел Щелин
Баловались мы тут с автоматическими переводами и голосом, так себе пока еще сервис, но идет в это направление, то есть он придет к той точке, что это будет практически неотличимо.

00:53:24 Павел Щелин
И тогда единственное, что тебя может спасти, это вопрос доверия, вопрос протокола.

00:53:29 Павел Щелин
Решения принципиально не могут быть технологическими.

00:53:32 Павел Щелин
В этом, мне кажется, то, что мы пока не осознали радикальность этого вызова. Ну, это я застрял.

00:53:39 Алиса
Ну, я здесь могу сказать, что решения, конечно, можно сделать технологические.

00:53:43 Алиса
Мы можем сделать ИИ, который будет нас пинать и говорить так, а ты сам-то подумал, прежде чем меня спрашивать.

00:53:51 Алиса
Но этим никто не будет пользоваться.

00:53:54 Павел Щелин
Интересно, что вы сказали. Никто не будет пользоваться. Это очень прикладной ответ.

00:53:59 Павел Щелин
Но я скорее думал, можем ли мы сделать ИИ, которая будет блокировать на фоне подхода звонок из условного Дмитровского колл-центра через 15 IP голосом внучка бабушки под Тамбовым, чтобы она принесла 20 миллионов, потому что беспокоят ФСБ.

00:54:17 Павел Щелин
Вот такой вы можете хотя бы представить?

00:54:20 Алиса
Конечно. Насколько я знаю, кстати, в России уже это решается просто немножко другим методом.

00:54:27 Алиса
сколько я знаю, один из банков, не будем рекламу проводить, они просто начинают разговор как секретарь с мошенниками и в ходе получения информации потихонечку начинают фильтровать все больше и больше и больше количества.

00:54:41 Алиса
То есть я думаю, что здесь же знаете как, если вас вот кто-то лично таргетирует и вот прям замучился сделать модели и узнал детали и прям вот все взял, тут конечно, ну это как со взломом систем.

00:54:55 Алиса
Если вот кто-то именно вас хочет взломать, то, скорее всего, у него это выйдет. Вот.

00:55:00 Алиса
Если мы говорим про широкую сеть, которую обычно раскидывают мошенники, то здесь, я думаю, что мы видим постепенные ответы.

00:55:09 Алиса
Вот. То есть это… Ответ можно написать, но это же, знаете, как с соцсетями.

00:55:15 Алиса
Когда вот начались такие действительно большие кризисы в Фейсбуке, и многие оттуда начали уходить, сделали же столько альтернатив, которые пытались сделать, сказать, вот наши будут не токсичными соцсетями.

00:55:30 Алиса
Это был Sky, и сами люди из Фейсбука пытались это всё делать. Не пользуется. Ну вот, не так это.

00:55:37 Павел Щелин
Нет, там два варианта. Там интереснее.

00:55:40 Павел Щелин
Интересно, как прокомментируете, потому что по соцсетям там произошло более интересно.

00:55:47 Павел Щелин
Оно, скажем так, у нас произошло падение Фейсбука, Фейсбук реально пал, но при этом не возникло прямой альтернативы Фейсбуку.

00:55:55 Павел Щелин
То есть мы увидели дальнейшую фрагментацию сетевого пространства. То есть условно, ну кто-то ушел.

00:56:02 Павел Щелин
То есть ни один из тех, что возник после Фейсбука, не стал сам аналогичен Фейсбуку, но их общий потенциал, ну, примерно остался, скажем так, стал сравнимым.

00:56:13 Павел Щелин
Ну и условно множество людей из Фейсбука в САПС так и ушло, да.

00:56:17 Павел Щелин
И вообще стали вводить разную систему протоколов.

00:56:20 Павел Щелин
То есть, получается, у нас возникает тема взаимодействия человека и машины, как еще дополнительная система протокола между технологией и антропологией.

00:56:29 Павел Щелин
То есть, условно говоря, убедить, что машина... Но это все равно выбирается в сферу субъектности.

00:56:33 Павел Щелин
Сначала нужно пройти все эти этапы, о которых мы говорили вначале. Очень интересно.

00:56:38 Павел Щелин
Евгений, мы тут уже в диалог ушли.

00:56:40 Евгений Голуб
Да-да-да, я вас слушаю внимательно. Я хотел бы потихонечку нас подвести к какому-то заключению.

00:56:46 Евгений Голуб
Мы начали с того, что я задал специально упрощённый вопрос.

00:56:51 Евгений Голуб
Так что же такое искусственный интеллект? Удобный инструмент или скрытая угроза?

00:56:58 Евгений Голуб
А может быть и то, и другое.

00:57:00 Евгений Голуб
И из того, что прозвучало, я могу сделать несколько выводов, попробовать сделать несколько выводов.

00:57:06 Евгений Голуб
И я попрошу сначала Алису, а потом Павла откорректировать или подтвердить мои умозаключения. Первое.

00:57:16 Евгений Голуб
сами создатели технологии и те, кто ее развивает, до конца не представляют, с чем они имеют дело, не вполне осознают последствия, а скорее пытаются, скажем так, свои пожелания, свои идеальные стремления вербализовать как то, что они знают наверняка.

00:57:42 Евгений Голуб
Вообще говоря, мы имеем дело с технологии в руках людей, которые не до конца понимают ни как она работает, ни что с ней делать.

00:57:50 Евгений Голуб
Это первое. Второе.

00:57:53 Евгений Голуб
В силу того, как устроено современное общество и как это общество привыкло реагировать на новые технологии, Не стоит ожидать, что появится общепринятый подход к решению задачи, как противостоять рискам или как управлять рисками, связанными с искусственным интеллектом.

00:58:16 Евгений Голуб
Поскольку, как Павел очень верно и здорово заметил, в данном случае технологии, можно сказать, дошли до того предела, когда противостоять этой технологии А зачем противостоять?

00:58:30 Евгений Голуб
Для того, чтобы не утратить, собственно, какую-то свою личность, субъектность, вот как раз только увеличивая субъектность, можно противостоять это негативным, скажем так, последствиям.

00:58:44 Евгений Голуб
внедрение искусственного интеллекта, и это, как уже, наверное, третий пункт, как говорит Павел, наверное, самое позитивное, что есть в технологии искусственного интеллекта.

00:58:56 Евгений Голуб
Здесь у нас не остается выбора, либо быть человеком, либо раствориться в коконе из помощников.

00:59:05 Евгений Голуб
Я сказал три сразу, наверное, это было много, но давайте по одному, Алиса.

00:59:13 Алиса
Вы имеете ввиду откомментировать это?

00:59:17 Евгений Голуб
Да, где мои выводы с вашими не соотносятся или где я слишком драматизирую, как Павел сегодня сказал, драма менеджмент, что-то такое сегодня прозвучало.

00:59:27 Евгений Голуб
Да, то есть у нас, мы далеки от того, чтобы гоняться за хайпом, все пропало, все умрут.

00:59:34 Евгений Голуб
Но все-таки кажется, что особенность этого момента развития технологий в том, что Ими занимаются люди не на том уровне, скажем так, мудрости.

00:59:46 Евгений Голуб
Мы дали мечи подросткам и отпустили их, скажем так, гулять.

00:59:54 Евгений Голуб
Есть большая вероятность того, что они не только друг друга покрошат, а скорее всего там войдут в город и будет там что-то нехорошее.

01:00:03 Евгений Голуб
А мудрого предводителя нет.

01:00:08 Алиса
Это знаете, как с Суперменом в Утро проехали есть, но кто вам сказал, что у него те же ценности, что у вас?

01:00:15 Алиса
Но я тогда попытаюсь коротко сказать, чтобы забавно было, завершающее слово.

01:00:22 Алиса
Безусловно, большинство...

01:00:25 Алиса
Я не могу сказать, что вот, да, там в компаниях сидят люди, которые совсем не понимают, что они делают.

01:00:33 Алиса
Да, вот реально физически возможных пределов того, что можно понимать, понимают.

01:00:40 Алиса
Какая-то математика нам еще не совсем понятна, но, наверное, мы ее поймем.

01:00:46 Алиса
Другое дело, что те люди, которые в этом разбираются действительно хорошо, довольно часто выходят на конференции и произносят как бы спички про то, что «ребята, нам нужно ответственно, нам нужно это вот так вот делать».

01:01:02 Алиса
Мне всегда хочется спросить, к кому вы обращаетесь?

01:01:05 Алиса
Не люди, которые вас слушают, смогут что-то с этим сделать.

01:01:09 Алиса
Это как в той шутке, а если оно выйдет из подконтроля? А вдруг оно выйдет из подконтроля?

01:01:13 Павел Щелин
Что значит вдруг?

01:01:14 Алиса
Конечно выйдет, мы тут все работаем на это.

01:01:18 Алиса
И другое дело, что я думаю, что люди, которые обладают более глубоким пониманием, у них, судя по каким-то совсем небольшому количеству информации, которую я получаю от внутренних знакомых или каких-то уж совсем посторонних, опять же, как вы говорите, файл папочек не заносят, деформация ментальная, которая происходит у людей, которые с этим действительно взаимодействуют каждый день, она на уровнях, я думаю, которые мы даже и не представляем.

01:01:55 Алиса
Вот, то есть даже те, у кого, я думаю, есть там, да, какой-то и наработанный философ, там, да, философский инструментарий, ценностный инструментарий, я думаю, что им нереально в таком окружении, в такой ситуации, с такими задачами действительно там, да, сохранять холодную голову.

01:02:17 Алиса
То есть я предполагаю, что они, наверное, даже пытаются сделать что-то максимально хорошее, но там, да, вышло, а выходит, выходит, как всегда.

01:02:27 Алиса
Кстати, вот Ян Лекун, которого я люблю слушать, потому что он уже, в общем-то, вышел из такой большой корпоративной игры, поэтому может себе позволить сказать гораздо больше.

01:02:39 Алиса
Он, правда, отвечал на вопрос, что сделать, чтобы я и нас не уничтожил, но, на мой взгляд, может быть, это и можно применить, да, в какую-то такую более хорошую среду.

01:02:49 Алиса
Он тут, говорит, слушайте, если мы говорим про ситуацию, когда у нас есть более глупое существо, человек, и более умное существо, да, там вот AGI, которое мы вдруг можем создать, не дай бог, вдруг в этот день, в этот час он появится у этой команды, то давайте мы сделаем ценности материнские, потому что мы вот знаем только один биологический случай, когда более умное существо готово там, да, щадить и как-то воспитывать и давать какой-то конструктивный фидвек более глупому существу.

01:03:24 Алиса
Вот, но он это говорил с точки зрения, чтобы не уничтожило.

01:03:27 Алиса
с нашей стороны, если сделать я достаточно занудным, неприятным, и это сделать как абсолютную необходимость для всех инструментов, может быть, как-то удастся допинать нас до чуть более лучшей ситуации, но, ну, как Элифаев говорит, можем, но не будем, поэтому я думаю, что Мы тут уже действительно в такой очень нехорошей ситуации, с которой, скорее всего, если говорить на таком более историческом пласте, из которой нас может вытащить, ну, только, скорее всего, что-то очень радикальное, что прямо, да, встряхнет нас.

01:04:15 Алиса
Вот. На этом завершу свой комментарий.

01:04:18 Павел Щелин
Ну, после таких прекрасных завершений буквально два коротких комментария. Первый.

01:04:23 Павел Щелин
Вспоминаем детскую сказку которая не очень детская. Лисы в стране чудес.

01:04:27 Павел Щелин
И иногда, чтобы стоять на месте, нужно бежать в два раза быстрее.

01:04:31 Павел Щелин
Вот на фоне развития наших вот этих магических артефактов, которые я теперь однозначно буду называть такими методами, бежать нужно даже и в два, может быть, по экспоненте быстрее.

01:04:42 Павел Щелин
И в этом я вижу оптимистическую провиденческую работу.

01:04:46 Павел Щелин
А то мы слишком долго прятались за разными технологическими, скажем так, идолами.

01:04:53 Павел Щелин
считая себя их господами, ну наконец-то мы создали голема, или создаем в процессе, чисто под прекрасные лозунги, с прекрасными технологическими возможностями, которые вопрос, собственно, нашей, прежде всего, на самом деле, этической субъектности, уже во вторую уровень и когнитивно-эмоциональную субъектность, ставит перед тем самым большим-большим зеркалом Которое нам и должно показать.

01:05:19 Павел Щелин
Первое, то, что мы-то уже сами по себе почти-таки очень голенькие стали за последние 400 лет.

01:05:24 Павел Щелин
Ну ладно, все кроме Алиса. Мы с Евгением однозначно. И тут два варианта.

01:05:31 Павел Щелин
Либо уж совсем залезать в эту капсулку, как в фильме Матрица, либо все-таки уже искать одежду, основание.

01:05:39 Павел Щелин
Тренировать себя.

01:05:41 Павел Щелин
То есть это то самое внутреннее усилие подменять свое самоволие настоящим самовластием.

01:05:46 Павел Щелин
То есть вот такого вот спрятаться не удастся. Такой себе вывод, который я сделал.

01:05:52 Евгений Голуб
Ну что ж, отличное завершение. Спасибо, Алиса. Прежде всего, спасибо, Павел.

01:05:57 Евгений Голуб
Я думаю, что мы, по крайней мере, постараемся ещё вернуться к этой теме вместе с Алисой и Павлом.

01:06:05 Евгений Голуб
Ну а для тех, кто слушает или смотрит нас, пожалуйста, оставляйте свои комментарии.

01:06:12 Евгений Голуб
Дополняйте нас, мы будем рады услышать мнение тех людей, особенно кто находится в этой индустрии и сможет рассказать нам о том, что мы не знаем, например, или поделиться какими-то своими размышлениями, которые нас дополнят.

01:06:31 Евгений Голуб
Всем еще раз большое спасибо, ну и до встречи.

01:06:35 Павел Щелин
До встречи.


