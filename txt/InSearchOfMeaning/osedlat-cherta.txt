00:00:08 Евгений Голуб
Здравствуйте, друзья!

00:00:09 Евгений Голуб
В эфире необычный выпуск ведущих подкаста «В поисках смысла».

00:00:14 Евгений Голуб
Евгения Голуба, Павла Щелина и сегодня с нами приглашённый эксперт Алиса Ким.

00:00:20 Евгений Голуб
Мы решили записать этот выпуск, так как первый раз мы затронули тему искусственного интеллекта, а сегодня речь пойдёт о нём.

00:00:29 Евгений Голуб
Примерно год назад, может быть, немного больше, и с тех пор многое изменилось.

00:00:33 Евгений Голуб
Я бы так сказал, что изменилось практически всё.

00:00:36 Евгений Голуб
И для того чтобы осмыслить происходящее, нам уже не хватает собственного понимания.

00:00:41 Евгений Голуб
Мы подозреваем себя в предвзятости.

00:00:43 Евгений Голуб
И для этого мы пригласили Алису, кандидата наук, эксперта по искусственному интеллекту.

00:00:49 Евгений Голуб
Алиса занималась академическими исследованиями в университете Гумбольда и в Стэнфордском университете.

00:00:55 Евгений Голуб
Алиса разрабатывала языковые модели в AWS, Amazon, что-то там, как она дальше.

00:01:02 Павел Щелин
Веб-сервис.

00:01:02 Евгений Голуб
Веб-сервис.

00:01:03 Евгений Голуб
Ну и, в общем, последние 10 лет Алиса занимается внедрением искусственного интеллекта в разного рода системах, в стартапах и крупных корпорациях.

00:01:12 Евгений Голуб
Поэтому кому как ни к Алисе нам прийти с нашими вопросами и недоумениями?

00:01:18 Евгений Голуб
Итак, я предложил сегодня разделить роли в нашем встрече следующим образом.

00:01:24 Евгений Голуб
Как уже понятно, Алиса — наш эксперт, Павел — философ.

00:01:27 Евгений Голуб
Ну а я буду выступать сегодня в роли обычного пользователя разного рода и помощников.

00:01:33 Евгений Голуб
обычного обывателя, которых много и у которых есть простые незамысловатые вопросы.

00:01:39 Евгений Голуб
И начну я с такого простого вопроса к Алисе.

00:01:43 Евгений Голуб
Сегодня уже очень многие, включая меня, не мыслят в своей жизни без помощников, как мы их называем.

00:01:50 Евгений Голуб
У меня при запуске браузера запускается 6 штук сразу, и многие сейчас уже, собственно, ищут даже продукты через разного рода помощников.

00:02:01 Евгений Голуб
Так вот вопрос следующего рода.

00:02:03 Евгений Голуб
Всё-таки это полезная штука или за этим кроется что-то ещё?

00:02:08 Евгений Голуб
Как Вы считаете, насколько нагружены сегодняшние помощники скрытыми какими-то функциями, скрытыми намерениями их создателей?

00:02:17 Евгений Голуб
Есть ли подвох в этой технологии?

00:02:20 Алиса
Наверное, начну с занудного «полезно для кого и для чего».

00:02:24 Алиса
Для нас, как для пользователей в наших жизненных целях, безусловно, на мой взгляд, полезная вещь.

00:02:31 Алиса
Но мы с вами находимся в такой сложной ситуации, когда абсолютно всё в этом продукте, по сути, оптимизировано для того, чтобы мы чуть-чуть сбились с курса, забыли о том, зачем мы делаем то, что мы делаем, и как это работает.

00:02:45 Алиса
Если бы я должна была ответить на вопрос классический, ну так это хорошая вещь или плохая, я бы сказала.

00:02:51 Алиса
Хорошая, если мы будем пользоваться ей осознанно.

00:02:55 Алиса
И на этой части обычно все юзеры, я в том числе, говорят, ну если осознанно, то это уже как-то слишком сложно.

00:03:01 Алиса
Что касается нагруженности, тут, на мой взгляд, всё банально и немножко грустно.

00:03:06 Алиса
Практически всё о том, как создаются эти помощники, в общем-то зачем, с какими ограничениями, всё прописано, всё открыто.

00:03:15 Алиса
Я думаю, что там скрытых смыслов и скрытых идей и тайных помыслов довольно мало.

00:03:21 Алиса
Другое дело, что, знаете, как никто не считает правила пользования, все всегда всё принимают и радостно этим дальше пользуются.

00:03:27 Алиса
Другое дело, что мы с вами, наверное, никогда ещё не сталкивались с инструментом, по сути, телевизорами, чайниками, то есть любыми инструментами, доступными для рядового пользователя, которые были бы настолько сложны и настолько обманчивы, настолько сделаны для того, чтобы максимально с нашей головушкой помериться с силами, запутать и вести в искусство.

00:03:52 Алиса
Изначально же все эти системы, когда они стали популярны, не когда они стали точными, не когда они стали правильными с точки зрения даваемых ответов, а тогда, когда они стали настолько похожи на настоящего собеседника, что мы прямо включились в это.

00:04:10 Алиса
К сожалению, эволюционно мы очень быстро… Мы и так любим всё антропоморфизировать, с компьютерами разговариваем, с телевизорами даём имена машинам и так далее.

00:04:19 Алиса
А тут оно ещё и разговаривает, и отвечает, ещё и учится тому, что мы любим и не любим, и запоминает нас.

00:04:25 Алиса
Ну то есть тут не начать с этим взаимодействовать нас и помощникам, не как инструментом, ну практически нереально.

00:04:31 Алиса
Даже если вы супер в сознанке, скорее всего, через эти дни и от пользования вы уже немножко забудете про то, зачем это было сделано, как это работает и так далее.

00:04:41 Алиса
На мой взгляд, пользы этого можно извлечь очень много.

00:04:44 Алиса
Другое дело, что с такими инструментами, Прямо вот совсем-совсем нельзя забывать, зачем я это делаю и какие у этого ограничения.

00:04:52 Алиса
Они все прописаны, они все понятны.

00:04:55 Алиса
Но кроме тех, которые не прописаны, по идее, должны быть понятны любому человеку, что это коммерческий инструмент.

00:05:01 Алиса
Наверное, там есть какая-то доля того, что на вас хотят заработать, и всё общее благо мира, наверное, там не единственная цель.

00:05:08 Алиса
То есть, скорее всего, этот компонент тоже есть, но мы про это не очень любим помнить.

00:05:12 Алиса
А это влияет на то, как дальше развиваются эти системы.

00:05:15 Евгений Голуб
То есть искусственный интеллект, как любой инструмент, может быть использован по прямому назначению, его благо.

00:05:22 Евгений Голуб
Или как кухонный нож можно резать мясо, можно зарезать человека.

00:05:26 Евгений Голуб
Как технология книгопечатания можно печатать Библию, а можно порно-рисунки издавать.

00:05:33 Евгений Голуб
И здесь уже вопрос у меня к Павлу.

00:05:36 Евгений Голуб
Мы говорили с тобой год, наверное, немного больше назад о том, что надвигаются времена, когда многое из того, что делает человека человеком, будет, скорее всего, передано на аутсорс, искусственному интеллекту.

00:05:52 Евгений Голуб
Мы тогда с тобой видели риски того, что вот это творческое начало, чувства, эмоции начнут автоматизироваться, и, соответственно, в этой части есть риски для людей потерять свой компонент человечности.

00:06:08 Евгений Голуб
Что ты думаешь по этому поводу?

00:06:10 Павел Щелин
Первое, всё-таки сделаю базовые комментарии для фиксации собственной позиции по преамбуле, про вот кухонный нож и прочую всю эту историю.

00:06:19 Павел Щелин
Дело в том, что вот с этой позиции я философски не согласен.

00:06:23 Павел Щелин
Мне представляется, что само представление существования такого феномена как нейтральная технология является глубоким заблуждением.

00:06:31 Павел Щелин
Не существует такого феномена, как нейтральность технологий.

00:06:35 Павел Щелин
С самим фактом своего существования технология не нейтральна.

00:06:40 Павел Щелин
Она создаёт ассиметрию банально между теми, кто технологией пользоваться умеет, и кто технологией пользоваться не умеет.

00:06:47 Павел Щелин
Те, кто технологией пользоваться умеют, получают дополнительные ресурсы, власть, способ взаимодействия с миром относительно тех, кто ей не пользуется.

00:06:58 Павел Щелин
Вот это и есть, собственно, сама технологическая асимметрия.

00:07:01 Павел Щелин
То, что ты говоришь уже про волевой, этический выбор субъекта, использующий технологию, — это следующий этап, это следующий уровень.

00:07:08 Павел Щелин
Но сначала есть вот этот базовый уровень, что самим фактом своего бытия технология мир меняет.

00:07:15 Павел Щелин
И вот наше представление о ней как о некой нейтральности — это очень хороший sales point для любого, скажем так, маркетолога, но с философской точки зрения просто он неадекватный.

00:07:25 Евгений Голуб
Ты знаешь, мне кажется, нужно объяснить твой тезис о том, что самим фактом существования технология меняет мир.

00:07:33 Евгений Голуб
Логическая связь здесь не очевидна, по крайней мере, для меня.

00:07:37 Павел Щелин
Давай самое простое.

00:07:38 Павел Щелин
Вот если пока этой технологии не было, у тебя была определённая культура и определённые закономерности отношений между людьми, отношений экономические, социальные, политические и так далее, как ты ни крути.

00:07:52 Павел Щелин
Вот когда технология появилась, она стала фактором всех этих отношений просто по факту своего появления.

00:07:58 Павел Щелин
Еще никакой воли нет, но она создала дополнительные возможности.

00:08:02 Павел Щелин
Повторюсь, главная эта возможность, я ее назвал, это возможность к власти.

00:08:06 Павел Щелин
Любая технология содержит в себе заряд к власти.

00:08:10 Павел Щелин
Но это логично.

00:08:11 Павел Щелин
Если бы она его не содержала, ее бы никто не создал.

00:08:13 Павел Щелин
Это вот очень важно понимать.

00:08:14 Павел Щелин
То, что в нашем культуре технология всегда создается, на самом деле, с неким зарядом к власти.

00:08:22 Павел Щелин
В нашем конкретном примере.

00:08:23 Павел Щелин
Власть манипулирования, власть работы с данными, власть производства дополнительного материального ресурса и так далее.

00:08:30 Павел Щелин
Это все властные отношения.

00:08:31 Павел Щелин
И вот эта технология, ты можешь сказать, если тебе уточнить, Эта барыда времени может сказать, что она создается с технологией как минимум потенциальной власти.

00:08:38 Павел Щелин
То есть она лежит и спит, да, требуется волевой субъект, чтобы эту власть активизировать, но тем не менее потенциал-то уже создан самим фактом ее появления.

00:08:46 Павел Щелин
То есть некая статус-кво оказалась нарушенным.

00:08:49 Павел Щелин
Все.

00:08:49 Павел Щелин
Изобретение автомобиля, вне зависимости от намерений конкретного водителя или производства автомобиля, вот самим фактом своей технологии является угрозой, условно говоря, для коневодов.

00:08:58 Павел Щелин
Она меняет эти отношения автоматически, просто по факту своего появления.

00:09:03 Евгений Голуб
Технология может существовать, продукта может не быть.

00:09:05 Павел Щелин
Ты прав.

00:09:06 Павел Щелин
Как минимум потенциально.

00:09:07 Павел Щелин
С философской точки зрения я веду категорию потенциальное изменение, но просто мы живем еще в цивилизации последние 400 лет, где любое потенциальное изменение в зоне технологии и прогресса должно быть актуализировано.

00:09:18 Павел Щелин
У нас нет никаких этических ограничений на любую технологическую актуализацию.

00:09:22 Павел Щелин
Это, собственно, ради этого модерн мы и создавали.

00:09:25 Евгений Голуб
Мы говорим о том, что в модерне каждая технология прежде всего рассматривается с точки зрения возможности увеличить властный потенциал субъекта, обладающего этой технологией.

00:09:37 Павел Щелин
И да.

00:09:38 Павел Щелин
А в любой технологии, и до модерна, и после модерна, и вне модерна, всегда содержится увеличение потенциала субъекта.

00:09:45 Павел Щелин
Простой пример.

00:09:46 Павел Щелин
Я не могу бегать как гепард?

00:09:47 Павел Щелин
Но с машиной я могу перемещаться со скоростью, которой гепарду и не снилось.

00:09:52 Павел Щелин
Мой потенциал в категории бегания, она усиливает.

00:09:55 Павел Щелин
Она поэтому и создана.

00:09:57 Евгений Голуб
Теперь, я тебя прервал, может быть, ты сделаешь шаг назад и вернешься к своему второму тезису?

00:10:02 Павел Щелин
Он связанный с первым тезисом, и это проблема асимметрии последствий.

00:10:06 Павел Щелин
Другими словами, это вот был бы мой вопрос к Алисе следующий, если она в робот.

00:10:11 Павел Щелин
Мне просто интересно, есть ли размышления на эту тему.

00:10:14 Павел Щелин
Приведу пример не с искусственным интеллектом, но близким.

00:10:17 Павел Щелин
У нас есть технологии социальных сетей, выпущенные относительно недавно, буквально 15 лет назад Сейчас начали выходить исследования Айн-Нейра в изменениях на материальном уровне мозга молодых, особенно детей, подростков, девочек, которые 10 лет выросли на этих технологиях Скажем так, исследования, мягко говоря, тревожащие, там много разных неприятных последствий Но я сейчас говорю не про это.

00:10:40 Павел Щелин
Я говорю про то, что вот у нас есть асимметрия.

00:10:42 Павел Щелин
Технология выпущена была 10 лет назад, впоследствии от нее пришли 15 лет.

00:10:46 Павел Щелин
И что-то я сомневаюсь, что 15 лет назад, когда люди выпускали социальные дети, вообще хоть на каком-то этапе выпуска этой технологии задумывались о последствиях через 15 лет.

00:10:56 Павел Щелин
Это ее структурное ограничение.

00:10:58 Павел Щелин
По крайней мере, в нашей культуре, где скорость является благом сама по себе.

00:11:02 Павел Щелин
В принципе, идея торможения, движения, особенно технологического, является ересью и харамом.

00:11:09 Павел Щелин
У меня есть вот большой вопрос.

00:11:10 Павел Щелин
Проблема технологической асимметрии последствий существовала всегда.

00:11:14 Павел Щелин
Собственно, мы это знаем со времен ящика Пандоры.

00:11:16 Павел Щелин
Миф ящика Пандоры ровно про это.

00:11:18 Павел Щелин
Принесли огонь, а потом выпушил, как-то получился ящик.

00:11:22 Павел Щелин
Это вот очень классическая взаимосвязанная история.

00:11:25 Павел Щелин
Но сегодня мы просто повысили масштабы, скажем так, этой проблемы до определенного уровня, который в каком-то смысле количественно действительно является беспрецедентом.

00:11:34 Павел Щелин
Это вот такая моя занятка о зарубках на полях.

00:11:36 Павел Щелин
Мне просто интересно, как изнутри вообще ставится ли так вопрос, вот по-честному, не на уровне красивых презентаций, а как внутреннее самоощущение.

00:11:45 Алиса
Имеется в виду вопрос, насколько обсуждается и насколько озабочены компании, разрабатывающие большие языковые модели, озабочены последствиями.

00:11:54 Алиса
Не возьмусь говорить, конечно, за всех гигантов индустрии, но такую среднёную позицию сформулировать.

00:12:02 Алиса
философская, идеалистическая воля их основателей, CEO, предыдущих учёных, которые все как один пишут и, скорее всего, действительно думают о том, что они очень хотели сделать мир лучше.

00:12:16 Алиса
Их позиции почти всегда такие очень публичные.

00:12:19 Алиса
Я думаю, что они действительно в это верят.

00:12:22 Алиса
Есть то, как это работает внутри.

00:12:25 Алиса
В целом, почти все негативные последствия, которые вызывают эти продукты, они практически всегда важны, только когда они коротковременные и влияют на два самых важных фактора, которые, в свою очередь, влияют на то, довольны инвесторами или нет.

00:12:41 Алиса
К сожалению, тот единственный драйвер, который важен.

00:12:44 Алиса
В силу, кстати, того, что вы сейчас сказали о скорости, потому что сейчас у абсолютно всех участников рынка 100% уверенность в том, что вот сейчас мы в этой точке бифоркации.

00:12:54 Алиса
Тот, кто успеет и возьмёт рынок, тот будет править следующие 100 лет.

00:12:58 Алиса
А ещё хорошо бы, чтобы хотя бы в нашей стране, а есть же ещё китайцы, русские и все остальные.

00:13:03 Алиса
Дальше посмотрим.

00:13:04 Алиса
Сейчас главное — нужно успевать.

00:13:05 Алиса
Для этого нужно очень много денег на самые разные вещи.

00:13:10 Алиса
Что не любят инвесторы?

00:13:11 Алиса
Инвесторы не любят, когда по рукам дают регулятор, и инвесторы не любят, когда сильно жалуются и отпадает пользователь.

00:13:17 Алиса
Вот если кто-то из них посмотрел непосредственный вред в каком-то виде, сумел это довести до точки, когда реально уже наступает прессинг на компанию внести какие-то изменения, то тут компания может официально как-то позицию заявить.

00:13:32 Алиса
То есть, например, сейчас у всех компаний прописаны их, условно говоря, ценности и ориентиры.

00:13:38 Алиса
Например, OpenAI — это вот мы хотим, чтобы мы были helpful, но no harm и maximize utility — вот это их такая общая тема.

00:13:45 Алиса
И это влияет на то, что они реально внутри пытаются делать для того, чтобы как-то ограничить негативные, например, вот этот вот no harm обеспечить.

00:13:54 Алиса
Но в целом есть, к сожалению, такая неприятная история, такой конфликт интересов, что, знаете, принципиального человека уломать на что угодно гораздо сложнее.

00:14:03 Алиса
Вот модель, у которой слишком много ограничений, она, скорее всего, будет не так хорошо, красиво работать, её тренировать дороже, ей могут быть недовольны пользователи.

00:14:12 Алиса
И поэтому в целом мотивации реально усложнять эту историю у компаний нет никакой.

00:14:18 Алиса
Только вот те два фактора, которые я сказала, регуляторы и пользователи.

00:14:22 Павел Щелин
И это еще мы находимся в очень, на самом деле, маленьком кружочке.

00:14:26 Павел Щелин
Я этот вопрос задал гораздо больше.

00:14:28 Павел Щелин
Вы, по сути, подчеркнули проблему некого knowable harm, в которой ты получаешь информацию об этом вреде через вот этот фидбэк-клуб некий, да, и ты хоть о каком-то информации получаешь.

00:14:39 Павел Щелин
Я же постулировал вопрос более радикально, потому что, как в примере с этих социальных сетей, ни за что не буду утверждать, что у людей, которые вводили социальные сети как корпоративный метод в середине 2000-х, было намерение сломать психику девочкам-подросткам в 2025 году.

00:14:54 Павел Щелин
Основная проблема в том, что есть огромная сфера того, что мы не знаем о технологическом последствии, Мы в теории могли бы попытаться об этом думать, как, не знаю, категория философского риска, промышления, но, как я понимаю, из вашего описания, разумеется, не по причине некого зла, а по причине той системы, скажем так, мотивации к действию, такой вопрос в принципе никто не ставит.

00:15:15 Павел Щелин
Если последствия будут через 15 лет, нас это вообще никаким образом сегодня не волнует.

00:15:20 Алиса
Про это пытаются думать и даже нанимают дорогостоящих исследователей, образовывают целые «финк-тэнки» внутри компаний, и они даже публикуют желательно не сильно, конечно, радикальные работы, но показать социальную ответственность очень надо.

00:15:35 Алиса
Но нет времени и денег у компаний сейчас об этом думать.

00:15:38 Алиса
Разве что какие-то более независимые институты могут пытаться делать какие-то проекты, они их делают, но нет времени и возможностей, слишком велика конкуренция, слишком велик прессинг.

00:15:49 Алиса
Просто на это никак.

00:15:50 Алиса
Хотела отдельно прокомментировать то, что Вы сказали касательно нейтральности технологии.

00:15:55 Алиса
Мы здесь, безусловно, не имеем дела с технологией, которая даже подаётся как нейтральная.

00:16:00 Алиса
То есть, во-первых, большинство этих решений подаются с очень громким информационным бэкграундом того, Мы это делаем ради того, чтобы человечество тут лучше жило, чтобы вам, дорогие пользователи, дать свободу, то есть «freedom to the users» — он прямо это обещает.

00:16:20 Алиса
Потом уже появляются «safety» и так далее, но это в целом подаётся очень агрессивно, как это прямо то, что сейчас вам всем сделает лучше.

00:16:30 Алиса
И для того, чтобы этой технологией пользоваться действительно максимально осознанно, как-то максимально возможно и безопасно, тоже нужно найти третий ход слева за трактором, повернуть направо и желательно отключить вот этот вот ещё функционал, вот эту информацию не давать, а вот здесь ещё перезагрузиться.

00:16:48 Алиса
И тогда в целом, наверное, будет чуть получше.

00:16:51 Алиса
Ну то есть уровень сложности.

00:16:53 Алиса
количество сальто, которое нужно сделать, чтобы действительно эта технология для вас, когда пользователя, была нейтральной, бесчестно велика для того, чтобы утверждать.

00:17:04 Алиса
Да нет, мы же вам всё по-честному дали.

00:17:07 Алиса
Это всё вы, это ваше пользование дало вам плохие результаты.

00:17:10 Алиса
Это не мы.

00:17:11 Алиса
Тут нужно просто это по-честному отметить.

00:17:14 Евгений Голуб
У меня будет два комментария.

00:17:15 Евгений Голуб
Первое.

00:17:16 Евгений Голуб
Так как я постоянно рассказываю о том, что человек выходит из корпоративного мира, то я знаю цену всем вот этим корпоративным миссиям, виденью и всему остальному.

00:17:26 Евгений Голуб
Цена эта не очень высока.

00:17:28 Евгений Голуб
Это всё, в общем, известное лицемерие.

00:17:31 Евгений Голуб
И во главе угла всегда стоят только деньги.

00:17:34 Евгений Голуб
Деньги и власть.

00:17:37 Евгений Голуб
Поэтому если на пути у топ-менеджмента становятся какие-то не вполне очевидные или сомнительные свойства продукта, то топ-менеджмент всегда Повторяю, всегда, прежде всего, попытается добиться максимального финансового результата, конечно же, с одной стороны, снижая риски для себя, и главным образом, как бы кто об этом ничего не узнал, или как бы ничего не вышло с точки зрения пиара, а уже потом будет думать о всех этих миссиях и видениях.

00:18:05 Евгений Голуб
Миссии и видения нужны для того, чтобы красиво выступать на конференциях и сорвать аплодисменты.

00:18:10 Евгений Голуб
Поэтому наличие миссии и видения для меня совершенно не успокаивает, а даже скорее наоборот говорит о том, что если такое миссия и видение, значит точно там где-то что-то не так.

00:18:19 Евгений Голуб
Это первое.

00:18:20 Евгений Голуб
А второе — наблюдение за нашими лидерами мнений, вот этими замечательными гениями технологическими, вроде Сэма Альтмана, который, как мы уже говорили с Павлом, в своём послании «Городу и миру» заявил о том, что мы в двух шагах от райских кущ, которые нам произведёт искусственный интеллект.

00:18:39 Евгений Голуб
И при этом он перечислял какие-то такие, скажем так, свойства искусственного интеллекта и привёл такие доводы, которые можно, наверное, оглянувшись назад, было бы услышать от изобретателей, не знаю, электрических двигателей, стиральных машин, паровозов и так далее, и так далее.

00:18:56 Евгений Голуб
То есть кажется, что, дружище, ну что ж ты повторяешь-то всё одно и то же?

00:18:59 Евгений Голуб
Ну как изменилась жизнь обывателя к лучшему?

00:19:02 Евгений Голуб
За счёт технологии она стала комфортнее, да.

00:19:04 Евгений Голуб
И что?

00:19:05 Евгений Голуб
И к чему это привело?

00:19:07 Евгений Голуб
твоя технология отнимает у него последний шанс к творчеству, как мне кажется.

00:19:11 Евгений Голуб
Алиса, ваши комментарии как человека близко к корпоративному миру, ну и, конечно же, Павла хотелось бы послушать.

00:19:17 Алиса
Нужно просто сказать, что даже если внезапно самые айфоны Марки Цукерберге этого мира решат, всё, давайте, ребята, забудем про деньги, будем заниматься, вот прямо действительно постараемся, чтобы наши атом-ЛЛМы, наши клоды, наши чаты-ГПТ, они прямо сели разумное, доброе, вечное и так далее.

00:19:36 Алиса
Вот прямо вот сейчас, эх, мы возьмёмся.

00:19:38 Алиса
Я здесь, конечно, не скажу совсем за bleeding edge, того, что существует.

00:19:45 Алиса
Но в целом, насколько мне известно, даже если мы очень сильно захотим, наши границы возможного для того, чтобы действительно заставить моделей, если только мы их не превратим вот в попок, которые вот если тебя спросили, я отвечаю «это», мы просто не можем точно быть уверены в том, что модели будут действовать так, как нам надо, что они будут демонстрировать то поведение, те ценности, которые мы в них хотели заложить, исходя из своего представления о том, как это должно быть, и исходя из фидбэка вьюзеров, чтобы им тоже не навредить, мы здесь просто ещё технически ограничены.

00:20:20 Алиса
Несмотря на то, что ограничения в разной степени контроля направления этих моделей закладываются на целом ряде разных шагов, которые происходят во время тренировки, подготовки, тюнинга этих моделей, пользования уже этими моделями, Мы на всех этих шагах довольно сильно ограничены.

00:20:39 Алиса
Хочу здесь просто также оговориться, что есть некий потолок того, что мы можем сделать.

00:20:43 Алиса
И даже если вы тысячу раз спросите моделей, ну вот если тебе попросят рецепт коктейля молота, ну например, спросит, самый лучший способ сделать что-нибудь нехорошее, ты же ничего не ответишь?

00:20:56 Алиса
Тысячу раз модель отвечает, конечно, ничего не отвечу, нельзя.

00:20:59 Алиса
Тысяча первыми может ответить.

00:21:00 Алиса
То есть наша личная степень контроля, несмотря на то, что она очень велика, и, конечно же, вообще мы целиком формируем то, какую информацию они выдают, как действуют, как принимают решения, мы всё равно довольно сильно ограничены.

00:21:12 Евгений Голуб
Среди обывателей, скажем так, распространено две крайние точки зрения.

00:21:17 Евгений Голуб
С одной стороны, «да что вы там мне рассказываете про этот искусственный интеллект, он галлюцинир, это вообще продвинутая Т9, которую просто развили».

00:21:25 Евгений Голуб
А с другой стороны, «господи, это магия какая-то, это вообще душа, наконец-то меня кто-то понял, услышал, не рассказывайте мне все ваши сказки про Т9, это просто уже новая сущность какая-то, совершенно непредставимая раньше».

00:21:39 Евгений Голуб
И сейчас, Алиса, то, что вы говорите, звучит как «мы вообще не понимаем, как это работает».

00:21:45 Алиса
Есть огромное ограничение в том, что там называется «объяснимость сетей».

00:21:50 Алиса
То есть если мы спросим даже самую суперпродвинутую модель, «А почему ты думаешь, что это плохо?», мы не можем быть уверены, что она нам отвечает честно и что она дала какой-то ответ именно потому, что она думает так, как мы хотим, чтобы она думала.

00:22:04 Алиса
То есть мы всё равно здесь взаимодействуем с очень высокой степенью неуверенности того, почему она делает то, что она делает.

00:22:12 Евгений Голуб
Но вы говорите, она думает.

00:22:13 Евгений Голуб
Она вообще думает вообще?

00:22:14 Евгений Голуб
Там же, как я понимаю, идёт огромный подбор вариантов в сочетании тех или иных смысловых знаков и так далее.

00:22:22 Евгений Голуб
Можно сказать, что она думает вообще?

00:22:24 Алиса
С учётом того, что первые нейронные сети и вообще перисоптрон создавался как моделька вот этого нейрона в голове, я думаю, что мы склонны использовать глагол «вроде думает».

00:22:35 Алиса
Но нет, это последовательность неких математических действий, которые обусловлены оптимизацией, которая была проведена некими правилами, которые были вшиты в это всё во время тренировки модели, которые приводят к тому, что модель отвечает что-то определённое, но там этих вот ходов, которые не нами прописаны, а которые возникли сами в ходе тренировки, подготовки этой модели, их гораздо больше.

00:23:02 Алиса
То есть какую-то часть мы контролируем и видим, а какую-то часть мы всё ещё не видим.

00:23:06 Евгений Голуб
Ну да, звучит всё-таки немного жутковато.

00:23:09 Павел Щелин
Жутковато, но оптимистично.

00:23:11 Павел Щелин
Объясню почему.

00:23:12 Павел Щелин
Повод задуматься.

00:23:14 Павел Щелин
Мне нравится, что на фоне всей этой искусственно-интеллектной истории актуализируется постепенный интерес к по-настоящему важным вопросам эсхатологически.

00:23:23 Павел Щелин
и антологическим.

00:23:24 Павел Щелин
Мне тоже уже 20 человек переслали ссылки на лекцию Питера Тиля.

00:23:28 Павел Щелин
Тоже поразительная черта нашей эпохи, то есть то, что говорит батюшка Самон, условно тысячелетиями никому неинтересно, но тут Тиль четыре лекции сделает!

00:23:38 Павел Щелин
Вау!

00:23:39 Павел Щелин
Ничего не знаю о содержании этих лекций, просто интересно само вот это общественное восприятие.

00:23:43 Павел Щелин
И эта реакция, мне кажется, сама по себе свидетельствует о том, что вот это столкновение с вот этой Вот ты употреблял раньше слово магия, я бы на нем, честно говоря, остановился.

00:23:52 Павел Щелин
То есть на каком-то уровне бытия это действительно магическая история.

00:23:56 Павел Щелин
Просто если мы не ограничиваемся только материальными причинами, о чем весьма подробно рассказала Алиса, а подключаем к этому субъективный опыт взаимодействия пользователя с этой системой, то он действительно очень магичен.

00:24:08 Павел Щелин
в своем вот именно опыте, поэтому здесь как раз особых противоречий нет.

00:24:12 Павел Щелин
Перед этим самым пользователем, уверенным в себе и в своем интеллектуальном превосходстве над неорганической природой до недавнего времени, искусственный интеллект, конечно, ставит очень большой вопрос.

00:24:22 Павел Щелин
А ты, собственно, человек или нет?

00:24:24 Павел Щелин
А что в тебе, собственно, человеческого?

00:24:25 Павел Щелин
А что ты готов пожертвовать, чтобы сохранить в себе некую человеческую особенность?

00:24:31 Павел Щелин
Здесь я объясню, я имею в виду сейчас даже не какие-то страшные пожертвования, А очень практические, но отсюда не менее страшные.

00:24:38 Павел Щелин
Начну издалека.

00:24:39 Павел Щелин
Классические примеры проблемы технологии сформулирован Васькой нашим Платоном, а еще вот в знаменитом разговоре египетского бога Тото с жрецами, который жаловался на изобретение письменности.

00:24:51 Павел Щелин
Тоже к вопросу о нейтральности технологий.

00:24:53 Павел Щелин
Бог тот, если конкретно жаловался на то, что вы сейчас писать научитесь, и саги, и священные тексты длиной в 15 тысяч строчек запоминать перестанете.

00:25:03 Павел Щелин
То есть вы потеряете способность это делать.

00:25:06 Павел Щелин
И вот в каком-то смысле любая технология несет в себе эту угрозу.

00:25:09 Павел Щелин
На самом деле с письменностью в широком значении произошло действительно именно это.

00:25:13 Павел Щелин
Я уже молчу о том, что есть большая разница между научиться читать и научиться понимать текст.

00:25:18 Павел Щелин
Это у нас отдельная проблема, то что разрыв между этими двумя, скажем так, феноменами нашего опыта тоже нами очень редко осознаётся.

00:25:26 Павел Щелин
Так вот, тем не менее, мы о себе думаем очень высокого мнения.

00:25:29 Павел Щелин
И тут ИИ ставит перед нами очень такую, на мой взгляд, радикальную задачу.

00:25:33 Павел Щелин
Вот как раз всё не творческое, всё построено на комбинаторике, всё построено на запоминании даже количества беспонимания.

00:25:43 Павел Щелин
Я вот уточню некоторым, то есть количественная информация и беспонимание сути этой информации, он действительно сделает лучше нас.

00:25:49 Павел Щелин
И это ставит нас действительно перед радикальным зеркалом, а, собственно, повторюсь, кто-то и есть.

00:25:54 Павел Щелин
Как бы могла бы выглядеть альтернативная практическая, скажем так, Мыслим ли нам по-честному сценарий, что на каждый час использования интеллекта ради рациональных, усиления твоего могущества по организации собственного дня и приобретения дополнительно свободного времени человек будет тратить полтора часа на запоминание стихов, саг, псалмов или прочтение бумагиточной книги не потому, что это более эффективно, а для того, чтобы сохранить вот эту свою способность человеческого восприятия?

00:26:22 Павел Щелин
Вот это, мне кажется, есть вопрос, который сегодня стоит по-настоящему.

00:26:26 Павел Щелин
Другими словами, мне кажется, взаимодействовать с определенной субъектностью ИИ, но в любом случае очевидно, что взаимодействовать с этой машинкой можно только, постоянно повышая субъектность собственную.

00:26:39 Павел Щелин
И вот в этом-то у нас проблема.

00:26:41 Павел Щелин
То, что вот эта вторая часть, наша уже культура, общество, да и само мышление о технологиях вообще ни разу не поднимает.

00:26:49 Павел Щелин
Мы не ставим принципиально так вопрос.

00:26:52 Павел Щелин
Для меня именно в этом-то и заключена главная опасность.

00:26:55 Павел Щелин
Да, технология в метафоре классической это черт.

00:26:59 Павел Щелин
Причем, возможно, такой нынешний черт, он прям всем чертям черт.

00:27:02 Павел Щелин
Но, как говорят русские сказки, черта иногда можно попытаться оседлать.

00:27:06 Павел Щелин
Ну, как укула, летающая на черте за черевичками.

00:27:09 Павел Щелин
Но чтобы очертать этого черта, даже в сказках, ты должен проявить субъектность больше, чем у этого самого черта.

00:27:14 Павел Щелин
А с субъектностью у нас коллективная напряженка.

00:27:17 Павел Щелин
И вот как-то так я вижу эту проблематику.

00:27:20 Евгений Голуб
Задумался я о твоих словах.

00:27:22 Евгений Голуб
Этот образ вакуула, оседлавшего чёрта, я уже его слышал, по-моему, на одном из твоих интервью.

00:27:29 Евгений Голуб
Интересный образ.

00:27:31 Евгений Голуб
Но получается так, что мы фактически стоимся заложниками.

00:27:35 Евгений Голуб
Технологию не остановить.

00:27:36 Евгений Голуб
Уровень, скажем так, мудрости разработчиков искусственного интеллекта, на мой взгляд, довольно невысок.

00:27:44 Евгений Голуб
Логика отношений капиталистических толкает нас к тому, что нужно максимизировать прибыль.

00:27:48 Евгений Голуб
Да, будут говорить про всех стейкхолдеров и нужно всеобщее, но давайте честно, деньги и власть по прежнему решают.

00:27:56 Павел Щелин
Когда я это говорил, я это говорил, прежде всего, в индивидуальном порядке.

00:27:59 Павел Щелин
Но второй момент, здесь есть очень интересный аспект, который я всё-таки тогда тоже здесь закину.

00:28:04 Павел Щелин
Связан он, уж извини меня, напрямую с властью и вот этой драмократией.

00:28:07 Павел Щелин
Это к тому, что Алиса упоминала ранее о страшных русских, американцах и китайцах.

00:28:12 Павел Щелин
Проблема в том, что с этими искусственными интеллектами на данный момент мы имеем очень интересный парадокс уже с точки зрения такой некой теории.

00:28:19 Павел Щелин
Метафорично все сейчас заняты выработкой технологического меча.

00:28:23 Павел Щелин
Этот меч все оттачивают до такой степени, чтобы нанести первый обезоруживающий удар.

00:28:29 Павел Щелин
Образно, да?

00:28:29 Павел Щелин
То есть я не говорю, что прямо у всех есть такое намерение, но общее восприятие картинки идет примерно таково.

00:28:34 Павел Щелин
Плюс, да, делаются словесные омажи.

00:28:36 Павел Щелин
Ну, мы, наверное, говоримся об общих правилах, какая-то гарантия взаимного уничтожения.

00:28:40 Павел Щелин
Чёрт-вство.

00:28:41 Павел Щелин
Ничего подобного вообще не происходит.

00:28:43 Павел Щелин
Проблема-то в чём заключается?

00:28:45 Павел Щелин
То, что щит находится вообще в другой области.

00:28:48 Павел Щелин
То есть обычно щит и меч должны находиться в одной топологии.

00:28:51 Павел Щелин
А у нас получается меч технологичный, а щит антропологичный.

00:28:56 Евгений Голуб
Да, вот это, я думаю, самое важное, что нужно понимать.

00:28:59 Евгений Голуб
Нет технологии, которой можно противопоставить технологии искусственного интеллекта, потому что она затрагивает уже сущностные свойства человека как такового.

00:29:08 Павел Щелин
Да, то есть единственный способ даже защититься вам как государству, начальству и прочим, это иметь такое население, которое обладает антропологической защитой от технологического манипулирования.

00:29:18 Павел Щелин
Это, собственно, и есть то, что я описывал, как повышение антропологической субъектности в ответ на повышение технологического вызова.

00:29:25 Павел Щелин
Тут тогда возникают очень неприятные последствия для всей нашей политической системы, о которых я говорю из эфира в эфир.

00:29:30 Павел Щелин
Алиса в курсе, и ты тоже, в принципе.

00:29:33 Павел Щелин
Но другого выхода нет.

00:29:35 Павел Щелин
И мне кажется, в этом тоже есть определённая парадоксальная красота.

00:29:38 Евгений Голуб
Ты говоришь о том, что, скажем, предыдущие технологии нас с вами пытались оскотинить, да, давая максимум комфорта и не стимулируя быть с людьми в полном смысле этого слова.

00:29:49 Евгений Голуб
А сейчас будет радикальный выбор.

00:29:51 Евгений Голуб
Либо ты уже совсем в предаток превратишься к экранчику, либо станешь человеком.

00:29:56 Евгений Голуб
Но давай мы зададим слово нашему эксперту.

00:29:58 Евгений Голуб
Ваши мысли по поводу слов Павла о том, что может противостоять технологии в данном случае?

00:30:04 Алиса
Я себе позволю такое маленькое грустное отхождение.

00:30:08 Алиса
Очень любят во всех статьях про искусственный интеллект сейчас, конечно же, писать про Азимова, про три закона о робототехнике.

00:30:14 Алиса
Если, собственно говоря, почитать его общую серию о роботах, там есть такая замечательная история, которая называется «Лжать», в которой удалось создать робота, который читает человеческие мысли.

00:30:24 Алиса
И так как он не может людям вредить, то он им начинает врать напропалу, их чувства не задеть.

00:30:30 Алиса
То есть вред же может быть эмоциональный.

00:30:32 Алиса
И как только они это понимают, это робота сразу же разбирает, потому что ну зачем человечеству такой робот?

00:30:37 Алиса
А вот мы его решили не разбирать.

00:30:39 Алиса
И в нашей исторической реальности мы такого робота всячески пытаемся дальше усовершенствовать, который нам рассказывает.

00:30:46 Алиса
Дальше нас успокаивает и говорит, что всё будет хорошо, и максимально пытается сделать нас счастливыми не во благо — нам же.

00:30:51 Алиса
Что касается такой геополитической составной части, я думаю, Павел, государства дойдут до вашей мысли, если ещё не целиком дошли.

00:30:59 Алиса
Пока что они находятся на точке чуть подальше хотя бы, что уже ценно.

00:31:04 Алиса
Там уже идёт вопрос о ИИ-суверенитете, то есть что происходит.

00:31:08 Алиса
государства начали понимать, что если их граждане будут пользоваться разработками, например, американскими, то будет идти колоссальнейшая культурная манипуляция, ценностная манипуляция и так далее.

00:31:19 Алиса
То есть не так много, но уже появляются работы на эту тему, наверное, моё любимое, которые используют эту карту с труднопроизносимым названием Ингельхарта-Вельселя.

00:31:30 Алиса
которая наосяг выживание против общественного блага и элективность и индивидуальность.

00:31:37 Алиса
И там, в общем-то, показано, что все нынешние самые популярные сети, они так очень хорошо пластеризованы в смысле того, какие они дают ответы, как они себя ведут.

00:31:45 Алиса
Мы сейчас не говорим о том, что они там реально думают, а о том, какие они дают ответы.

00:31:49 Алиса
Такие протестантско-аналитические классы.

00:31:51 Алиса
И в этом смысле, если гражданин Индии спросит у чьего-то Джи-Пи-Ти, напиши мне историю про мальчика, Например, который приготовил завтрак, то мальчик будет готовить тосты, бекончик и шинко, а не чапати с гей со всем остальным.

00:32:08 Алиса
Вот этим сейчас очень сильно отзабочены государства.

00:32:10 Алиса
Поэтому, например, такие страны, как Дания, Израиль и так далее, уже несколько лет назад прямо очень сильно встрепенулись, то есть уже хотя бы поняли, начали быстро-быстро собирать данные, формировать команды в свои государства для формирования тех моделей, которые будут соответствовать уже каким-то их представлением, и даже некий успех там достигнут.

00:32:30 Алиса
Я целиком согласна с тем, что Вы, Павел, обозначили как сложность, щит в другой сфере.

00:32:37 Алиса
Я, честно говоря, кроме очень страшных исторических событий, не знаю примеров, когда людей реально что-то мотивировало резко перестать расслабляться, а начать собираться.

00:32:49 Алиса
Ментально от нас, по сути, требуется это для того, чтобы окончательно не потонуть в истории Здесь, к сожалению, в целом у нас нет союзников, потому что даже корпорации, которые… И это, кстати, такое тоже грустное осознание, например, когда люди говорят, ну вот я же программист или дизайнер, я в своей компании, могу столько всего теперь сделать.

00:33:12 Алиса
На самом деле компании, и это вам скажет любой продавец SaaS-продукта, Компания уже давно, наверное, лет 10 как ненавидит слово «продуктивность».

00:33:20 Алиса
И гидой продуктивности им продать какой-либо продукт очень сложно, потому что это тяжело измерить.

00:33:25 Алиса
Но если только вы не на заводе, тогда можете выпустить больше лампочек и так далее.

00:33:30 Алиса
Компаниям интересна целиком замена людей, потому что это является ключевым вот прямо таким… Качественный скачок.

00:33:37 Алиса
Всё, что до этого — это они пытаются не отстать, но ждут, когда уже можно будет щелкнуть пальцами.

00:33:43 Алиса
Несмотря на те заявления, которые делают кларные мира сего, что «мы столько-то людей уже сократили», или «Амазоны, которые говорят, а мы не наймём теперь тысячу кодеров, потому что у нас есть «И»».

00:33:55 Алиса
Я себе позволю такое деткое замечание, что это просто звучит лучше, что мы должны сократить количество денег на персонал, потому что то, что мы пытались, наши инвестиции не оправдались в других областях.

00:34:05 Алиса
Но на самом деле мечта бизнеса скорее движется в этом направлении, во всяком случае, большого бизнеса.

00:34:12 Павел Щелин
Тут два варианта.

00:34:13 Павел Щелин
По крайней мере, пока у нас не будет технологического коллапса с отключением электричества и прочего, мы приходим в точку, в которой единственная добавленная стоимость генерируется в зоне идеи творчества того самого.

00:34:25 Павел Щелин
все материальное воплощение стремится к полной автоматизации.

00:34:28 Павел Щелин
Все материю стремится отдать на аутсорс, а соответственно единственная в принципе добавленная стоимость может быть именно сгенерирована в самой идее.

00:34:35 Павел Щелин
Идея нового приложения, идея нового продукта, идея чего-то и тому подобное.

00:34:40 Павел Щелин
Но тут-то возникает неприятная особенность, которую мы все знаем, что вот к такому генерации новых идей мы не то чтобы сильно были научены.

00:34:48 Павел Щелин
Большая часть работы от тебя вообще исторически не требовала ничего генерировать нового, особенно в индустриальном обществе, да?

00:34:54 Павел Щелин
И поэтому в этом плане корпоративная логика мне тут очень понятна.

00:34:57 Павел Щелин
Я просто хотел бы еще заострить, когда я говорил о вот этой гонке вооружений, для меня все-таки важно подчеркнуть, что на данный момент вот то, что вы описываете, оно укладывается в нормальную государственную логику.

00:35:08 Павел Щелин
Они пока ищут технологическое решение технологической проблемы.

00:35:12 Павел Щелин
Условно говоря, да, и проблема, но если мы создадим свой, если мы создадим гигантский прекрасный фейерволл, это будет наша проблема, и мы ее, так сказать, героически уже будем с ней работать, мы эту штуку оседлаем, а мой же тезис более радикальный И вот здесь я подчеркнул оригинальность для меня аиста, потому что В принципе, нет технологического решения этой проблемы в силу антропологического масштаба давления этой технологии.

00:35:36 Павел Щелин
То есть, условно говоря, неважно, какой ИИ будет программировать мозги твоему населению, если оно будет сидеть по квартирам, и ты его не заставишь не сделать ничего.

00:35:43 Павел Щелин
То есть, если наша цель — производить добавленную эту стоимость этим сверхтворческим субъектам, то тогда, получается, повторюсь, И решение в принципе не находится в этой зоне.

00:35:53 Павел Щелин
Если мы говорим о, допустим, более прикладных вещах, у нас же возникает целый комплекс проблем, о которых мы не говорили, но прикладные.

00:36:00 Павел Щелин
Когнитивная война.

00:36:01 Павел Щелин
То есть СИИ — это уникальный пример, чтобы свести с ума население оппонента.

00:36:05 Павел Щелин
То есть можно таргетировать.

00:36:06 Павел Щелин
Что делать в обратную сторону, никто не понимает.

00:36:08 Павел Щелин
Ну, когнитивная война — это такая моя побочная тема.

00:36:11 Павел Щелин
Можем уйти сюда.

00:36:12 Павел Щелин
Все знают эту историю с телефонными мошенниками.

00:36:14 Павел Щелин
Только представьте, что это телефонный мошенник, который звонит реально голосом внучка, которого ты не отличишь, причем реально не отличишь.

00:36:23 Павел Щелин
Это вопрос 5 лет, когда он сможет делать такие запросы.

00:36:26 Павел Щелин
И тогда единственное, что тебя может спасти, это вопрос доверия, вопрос протокола.

00:36:31 Павел Щелин
Решения принципиально не могут быть технологическими.

00:36:34 Павел Щелин
В этом, мне кажется, то, что мы пока не осознали радикальности этого вызова.

00:36:38 Алиса
Я здесь могу сказать, что решение, конечно, можно сделать технологически, мы можем сделать, и который будет нас пинать и говорить «Так а ты сам-то подумал, прежде чем меня спрашивать?» Но этим никто не будет пользоваться.

00:36:50 Павел Щелин
Интересно, что вы сказали.

00:36:51 Павел Щелин
Никто не будет пользоваться.

00:36:53 Павел Щелин
Это очень прикладной ответ.

00:36:54 Павел Щелин
Но я скорее думаю, можем ли мы сделать ИИ, который будет блокировать на фоне подхода звонок из условного колл-центра через 15 айпи голосом внучка бабушки под Тамбовым, чтобы она принесла там 20 миллионов тому, что беспокоит ФСБ.

00:37:08 Павел Щелин
Вот такой вы можете хотя бы представить?

00:37:11 Алиса
Конечно.

00:37:12 Алиса
Насколько я знаю, кстати, в России уже это решается просто немножко другим методом.

00:37:18 Алиса
Насколько я знаю, один из банков, они просто начинают разговор как секретарь с мошенниками и в ходе получения информации потихонечку начинают фильтровать всё больше и больше и больше количества.

00:37:29 Алиса
То есть я думаю, что здесь же знаете как, если вас вот кто-то лично таргетирует, И вот прям замучился сделать модели, и узнал детали, и прям вот всё взял.

00:37:38 Алиса
Тут, конечно, это как со взломом систем.

00:37:41 Алиса
Если кто-то именно вас хочет взломать, то, скорее всего, у него это вот.

00:37:45 Алиса
Если мы говорим про широкую сеть, которую обычно раскидывают мошенники, то здесь, я думаю, мы видим постепенные ответы.

00:37:53 Алиса
Ответ можно написать, но это же, знаете, как с соцсетями.

00:37:57 Алиса
Когда начались такие действительно большие кризисы в Фейсбуке, и многие оттуда начали уходить, сделали же столько альтернатив, которые пытались сделать, сказать, вот наши будут не токсичными соцсетями, делают блузка, и сами люди из Фейсбука пытались это всё делать.

00:38:12 Алиса
Не пользуются.

00:38:14 Павел Щелин
По соцсетям там произошло более интересно.

00:38:16 Павел Щелин
У нас произошло падение Фейсбука, Фейсбук реально пал, но при этом не возникло прямой альтернативы Фейсбуку.

00:38:22 Павел Щелин
То есть мы увидели дальнейшую фрагментацию сетевого пространства.

00:38:25 Павел Щелин
То есть условно...

00:38:26 Павел Щелин
То есть ни один из тех, что возник после Фейсбука, не стал сам аналогичен Фейсбуку, но их общий потенциал, ну, примерно остался, скажем так, стал сравнимым.

00:38:36 Павел Щелин
Ну и условно множество людей из Фейсбука в Сапстэк ушло.

00:38:39 Павел Щелин
И вообще стали вводить разную систему протоколов.

00:38:42 Евгений Голуб
Я хотел бы потихонечку нас подвести к какому-то заключению.

00:38:46 Евгений Голуб
Мы начали с того, что я задал специально упрощённый вопрос.

00:38:51 Евгений Голуб
Так что же такое искусственный интеллект?

00:38:53 Евгений Голуб
Удобный инструмент или скрытая угроза?

00:38:56 Евгений Голуб
А может быть, и то, и другое?

00:38:58 Евгений Голуб
Из того, что прозвучало, я могу сделать несколько выводов, попробовать сделать несколько выводов.

00:39:04 Евгений Голуб
И я попрошу сначала Алису, а потом Павла откорректировать или подтвердить мои умозаключения.

00:39:10 Евгений Голуб
Первое.

00:39:11 Евгений Голуб
Сами создатели технологии и те, кто её развивают, до конца не представляют, с чем они имеют дело, не вполне осознают последствия, а скорее пытаются свои пожелания, свои идеальные стремления вербализовать как то, что они знают наверняка.

00:39:29 Евгений Голуб
Вообще говоря, мы имеем дело с технологией в руках людей, которые не до конца понимают ни как она работает, ни что с ней делать — это первое.

00:39:37 Евгений Голуб
Второе.

00:39:38 Евгений Голуб
В силу того, как устроено современное общество и как это общество привыкло реагировать на новые технологии, не стоит ожидать, что появится общепринятый подход к решению задачи, как противостоять рискам или как управлять рисками, связанными с искусством и интеллектом.

00:39:56 Евгений Голуб
Поскольку, как Павел очень верно и здорово заметил, в данном случае технологии, можно сказать, дошли до того уровня предела, когда противостоять этой технологии… А зачем противостоять?

00:40:08 Евгений Голуб
Для того чтобы не утратить, собственно, какую-то свою Личность, субъектность.

00:40:12 Евгений Голуб
Вот как раз только увеличивая субъектность, можно противостоять этой негативным последствиям внедрения искусственного интеллекта, И это, как уже, наверное, третий пункт, самое позитивное, что есть в технологии искусственного интеллекта.

00:40:26 Евгений Голуб
Здесь у нас не остаётся выбора — либо быть человеком, либо раствориться в коконе из помощников.

00:40:33 Алиса
Я не могу сказать, что в компаниях сидят люди, которые совсем не понимают, что они делают.

00:40:37 Алиса
Реально физически возможных пределов того, что можно понимать, понимают.

00:40:42 Алиса
Какая-то математика нам ещё не совсем понятна, но, наверное, мы её поймём.

00:40:46 Алиса
Другое дело, что те люди, которые в этом разбираются действительно хорошо, довольно часто выходят на конференции и произносят спички про то, что «ребята, нам нужно ответственно, нам нужно вот так вот делать».

00:40:59 Алиса
Мне всегда хочется спросить, к кому вы обращаетесь?

00:41:02 Алиса
Не люди, которые восслушаются, могут что-то с этим сделать.

00:41:06 Алиса
А вдруг оно выйдет из-под контроля?

00:41:07 Алиса
Что значит «вдруг»?

00:41:08 Алиса
Что выйдет?

00:41:09 Алиса
Мы тут все работаем на это.

00:41:11 Алиса
Другое дело, что я думаю, что люди, которые обладают более глубоким пониманием, у них, судя по каким-то совсем небольшому количеству информации, которую я получаю, То есть даже те, у кого, я думаю, есть какой-то и наработанный философский инструментарий, ценностный инструментарий, я думаю, что именно нереально этот в таком окружении, инструментарий, в такой этот инструментарий, это инструментарий, это инструментарий, это инструментарий, инструментарий.

00:41:52 Алиса
ситуации, с такими задачами действительно сохранять холодную голову.

00:41:56 Алиса
То есть я предполагаю, что они, наверное, даже пытаются сделать что-то максимально хорошее.

00:42:01 Алиса
Выходит, как всегда.

00:42:03 Алиса
Ян Лекун, которого я люблю слушать, потому что он уже, в общем-то, вышел из такой большой корпоративной игры, поэтому может себе позволить сказать гораздо больше.

00:42:11 Алиса
Он, правда, отвечал на вопрос, что сделать, чтобы я и нас не уничтожил, но, на мой взгляд, может быть, это и можно применить в какую-то такую более хорошую среду.

00:42:19 Алиса
Он тут говорит, слушайте, если мы говорим про ситуацию, когда у нас есть более глупое существо, человек, и более умное существо, там вот AGI, которое мы вдруг можем создать, не дай Бог, вдруг.

00:42:32 Алиса
в этот день, в этот час он появится у этой команды, то давайте мы сделаем ценности материнские.

00:42:38 Алиса
Потому что мы знаем только один биологический случай, когда более умное существо готово щадить и как-то воспитывать, и давать какой-то конструктивный фидбэк более глупому существу.

00:42:50 Алиса
Но он это говорил с точки зрения, чтобы не уничтожило, а с нашей стороны.

00:42:55 Алиса
Если сделать яй достаточно занудным, неприятным, и это сделать как абсолютную необходимость для всех инструментов, может быть, как-то удастся допинать нас до чуть более лучшей ситуации.

00:43:08 Алиса
Но можем, но не будем.

00:43:10 Алиса
Поэтому я думаю, что мы тут уже действительно в такой очень нехорошей ситуации, с которой нас может вытащить только, скорее всего, что-то очень радикальное, что прямо встряхнёт нас.

00:43:22 Павел Щелин
Буквально два коротких комментария.

00:43:23 Павел Щелин
Первый.

00:43:24 Павел Щелин
Вспоминаем детскую сказку, которая не очень детская — «Алиса в стране чудес».

00:43:28 Павел Щелин
И иногда, чтобы стоять на месте, нужно бежать в два раза быстрее.

00:43:31 Павел Щелин
Вот на фоне развития наших вот этих магических артефактов, Теперь однозначно буду называть такими методами Бежать нужно даже диф-2, может быть, по экспоненте быстрее И в этом я вижу оптимистическую провиденческую работу А то мы слишком долго упрятались за разными технологическими, скажем так, идолами Считая себя их господами Ну, наконец-то мы создали голема или создаём в процессе, под прекрасные лозунги, с прекрасными технологическими возможностями, которые вопрос, собственно, нашей, прежде всего, на самом деле, этической субъектности, уже во вторую уровень и когнитивно-эмоциональную субъектность ставят перед тем самым большим-большим зеркалом, которое нам и должно показать.

00:44:12 Павел Щелин
Первое — то, что мы-то уже сами по себе почти очень голенькие стали за последние лет 400.

00:44:18 Павел Щелин
Тут два варианта.

00:44:18 Павел Щелин
Либо уж совсем залезать в эту капсулку, как в фильме «Матрица», либо всё-таки уже искать одежду, основания, тренировать себя.

00:44:26 Павел Щелин
То есть это то самое внутреннее усилие подменять своё самоволие настоящим самовластием.

00:44:32 Павел Щелин
То есть вот такого вот спрятаться не удастся.

00:44:34 Павел Щелин
Такой для себя вывод, который я сделал.

00:44:37 Евгений Голуб
Отличное завершение.

00:44:39 Евгений Голуб
Спасибо, Алиса.

00:44:40 Евгений Голуб
Прежде всего, спасибо, Павел.

00:44:42 Евгений Голуб
Я думаю, что мы, по крайней мере, постараемся ещё вернуться к этой теме вместе с Алисой и Павлом.

00:44:49 Евгений Голуб
Ну а для тех, кто слушает, пожалуйста, оставляйте свои комментарии.

00:44:53 Евгений Голуб
Дополняйте нас, мы будем рады услышать мнение тех людей, особенно кто находится в этой индустрии и сможет рассказать нам о том, что мы не знаем, например, или поделиться какими-то своими размышлениями, которые нас дополнят.

00:45:09 Евгений Голуб
Всем ещё раз большое спасибо!

00:45:10 Евгений Голуб
Ну и до встречи!

00:45:11 Павел Щелин
До встречи!

