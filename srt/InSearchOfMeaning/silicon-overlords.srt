1
00:00:08,938 --> 00:00:10,598
Здравствуйте, друзья!

2
00:00:10,598 --> 00:00:17,118
В эфире очередной выпуск подкаста «В поисках смысла». У микрофона Евгений Голуб и Павел Шерин.

3
00:00:17,118 --> 00:00:17,697
Здравствуйте!

4
00:00:17,697 --> 00:00:20,997
Итак, сегодня мы решили поговорить о тех.

5
00:00:20,997 --> 00:00:24,017
На феодалах, о тех людях, которые не.

6
00:00:24,017 --> 00:00:28,397
Стесняются заявлять о том, что они понимают.

7
00:00:28,397 --> 00:00:30,837
Как будет выглядеть мир в будущем.

8
00:00:30,837 --> 00:00:40,797
Они не только об этом заявляют, но они ещё фактически формируют эту картинку будущего, в которой у них есть определённая ведущая роль.

9
00:00:40,797 --> 00:00:45,635
Я хочу передать слово Павлу, чтобы он поразмышлял на эту тему, Ну давайте кратко.

10
00:00:45,635 --> 00:00:47,715
Из раздержания предыдущих серий.

11
00:00:47,715 --> 00:00:55,855
Вообще основная тема этого сезона, как вы могли заметить, искусственный интеллект, человек, человечность и вообще дивный новый мир во всех его проявлениях.

12
00:00:55,855 --> 00:01:07,795
И вот интересная часть этого дивного нового мира, конечно, сегодня это те люди, которые де-факто реально приобретают статус новой как бы аристократии.

13
00:01:07,933 --> 00:01:13,513
с очень большими оговорками. Почему новый? Во-первых, потому что есть аристократия старая, и.

14
00:01:13,513 --> 00:01:18,353
Она никуда не уходила. И вопрос, насколько новые аристократы по-настоящему являются.

15
00:01:18,353 --> 00:01:24,573
Самостоятельными субъектами, а в какой они являются болванчиками-исполнителями, вопрос открытый.

16
00:01:24,573 --> 00:01:27,693
Напоминаю всем легендарный вызов Цукерберга на ковер.

17
00:01:27,693 --> 00:01:36,213
В Сенат, где очень было видно, скажем так, пределы вот этой внутренней смелости, честности и силы этих самых новых аристократов, да?

18
00:01:36,216 --> 00:01:41,436
То есть, насколько они вытянут эту планку, для меня вопрос является пока не самоочевидным.

19
00:01:41,886 --> 00:01:49,566
Но то, что их внутреннее мироощущение, как новых аристократов, с этим спорить мне крайне сложно.

20
00:01:49,566 --> 00:01:51,066
Какие его характерные признаки?

21
00:01:51,066 --> 00:01:56,226
Ну, давайте, во-первых, сразу о каком идет речи. Речь идет, а вот повторюсь, тех на олигархах.

22
00:01:56,226 --> 00:02:00,926
Сэм Альтман, Безос, Цукерберг, Маск и Житель с ними.

23
00:02:00,926 --> 00:02:05,206
В общем, открывайте список всех этих корпоративных стратегов. Что мне интересно?

24
00:02:05,206 --> 00:02:13,636
Первое, вот на фоне общего, скажем так, напряжения, а мы в целом живем, в общем-то, мне кажется, напряженную эпоху, Эти люди прям фонтанируют оптимизмом.

25
00:02:13,636 --> 00:02:17,476
Вот, конечно, их поразительный оптимизм вызывает ощущение.

26
00:02:17,476 --> 00:02:19,636
Иногда даже легкой привидурковатости.

27
00:02:19,636 --> 00:02:23,396
Можно было бы возникнуть, можно было бы даже поставиться вопросом.

28
00:02:23,396 --> 00:02:28,576
Они понимают ли они чего-то, чего не понимаю я? Порадоваться, так сказать, за будущее человечества.

29
00:02:28,576 --> 00:02:31,016
Но после прочтения тех текстов, которые они.

30
00:02:31,016 --> 00:02:34,683
Пишут, за редкими исключениями. Выводы приводят самый обратно.

31
00:02:34,683 --> 00:02:42,163
К сожалению, это они не понимают базовых вещей относительно человеческой природы и демонстрируют вопиющую философскую неграмотность.

32
00:02:42,163 --> 00:02:44,083
Так что, когда, если вы думали, кто.

33
00:02:44,083 --> 00:02:46,143
Достигнет нас, одна постучались.

34
00:02:46,143 --> 00:02:49,183
А те философские работы, которые демонстрируют именно.

35
00:02:49,183 --> 00:02:54,543
Глубокую философскую подготовку, ну, я говорю здесь прежде всего о Питере Тиле, ну, скажем.

36
00:02:54,543 --> 00:03:00,483
Так, это тот вектор, от которого тоже волосы уже встают дыбом, потому что там становится совсем страшно.

37
00:03:00,507 --> 00:03:09,567
Так, минуточку, тут нас любой техно-оптимист остановит и скажет, если ты такой умный, Павел Щелин, где твои деньги?

38
00:03:09,567 --> 00:03:19,027
Ты смотри, ребята же, наверное, как-то умеют деньги зарабатывать, они что-то соображают, и критиковать их за то, что они как будто бы что-то не понимают, ну и что они не понимают?

39
00:03:19,027 --> 00:03:23,987
Это им не мешает хорошо жить, много очень денег зарабатывать, продвигать технологии.

40
00:03:24,013 --> 00:03:28,133
Вот это различие между интеллектом и умом.

41
00:03:28,133 --> 00:03:30,353
Мудростью, для многих не очевидно.

42
00:03:30,353 --> 00:03:31,873
Давай здесь сделаем паузу, потому что нас.

43
00:03:31,873 --> 00:03:35,373
Уже по первым выпускам начинают осуждать лёгкими.

44
00:03:35,373 --> 00:03:40,013
Такими комментариями относительно того, что вот и тот вам не нравится, и этого вы.

45
00:03:40,013 --> 00:03:42,293
Видите ли, критикуете высокомерно.

46
00:03:42,293 --> 00:03:46,044
Но ведь это совершенно разные домины знаний и умений.

47
00:03:46,044 --> 00:03:48,255
Тут есть несколько принципиальных вопросов.

48
00:03:48,255 --> 00:04:01,891
Первое, разумеется, я и близко не ставлю под сомнение канала на таланты и компетенции этих людей в максимизации прибыли их корпораций и осуществлении успешных бизнес-решений.

49
00:04:01,891 --> 00:04:09,747
Проблема заключается в том, что современный мир построен на гиперспециализации.

50
00:04:09,747 --> 00:04:22,985
Другими словами, в отличие от античности, в отличие от «страшного мрачного средневековья», Цельного человека сегодня найти практически невозможно, и я тоже к ним не принадлежу.

51
00:04:22,985 --> 00:04:27,985
Мои знания об вопросах физики, химии и биологии весьма и весьма ограничены.

52
00:04:27,985 --> 00:04:32,565
Скажем так, эту вещь признаю. В себе понимаю зоны своих ограничений.

53
00:04:32,565 --> 00:04:47,225
Проблема с уважаемыми бизнесменами в том, что они в 90% случаях позволяют себе рассуждать о вопросах философских, де-факто этических, моральных, простите, не владея ни малейшими знаниями об этой сфере.

54
00:04:47,578 --> 00:05:01,998
Обычная ситуация, когда глава успешной корпорации, необязательно IT, начинает представлять, что его успех позволяет ему содержательно рассуждать о разного рода вещах за пределами его непосредственной компетенции.

55
00:05:01,998 --> 00:05:12,782
Я вспоминаю случай из относительно недавнего прошлого, когда один из владельцев крупной компании «Новая почта» в Украине полемизировал с Андреем Олеговичем Беумейстером.

56
00:05:12,782 --> 00:05:17,665
Это кто-то метко назвал диалогом профессора с Википедией.

57
00:05:17,665 --> 00:05:19,745
Но при этом это никак не повлияло.

58
00:05:19,745 --> 00:05:21,485
На самооценку этого человека.

59
00:05:21,485 --> 00:05:28,805
Вот этот эффект больших денег, эффект значимости богатых людей в обществе, он в том числе имеет и такую сторону.

60
00:05:28,805 --> 00:05:38,265
То есть если я сумел организовать успешный бизнес, инновационный, ещё тем более высокотехнологичный, конечно же, я становлюсь лидером мнений, меня слушают.

61
00:05:38,265 --> 00:05:39,945
И как же тут не изречь какую-нибудь.

62
00:05:39,945 --> 00:05:42,685
Мудрость, чтобы люди внимали.

63
00:05:42,692 --> 00:05:44,872
Это, к сожалению, я не знаю, было.

64
00:05:44,872 --> 00:05:47,612
Ли такое несколько столетий назад, кажется, нет.

65
00:05:47,612 --> 00:05:49,572
Я, собственно, хотел рассказать, как это было.

66
00:05:49,572 --> 00:05:58,672
На самом деле, точно такой же процесс происходил в то время перехода от мира Средневековья к миру Просвещения.

67
00:05:58,672 --> 00:06:05,352
И, собственно, ты сказал ключевое слово, диалог философа с Википедией, но вспомни, кто создал первую энциклопедию.

68
00:06:05,352 --> 00:06:06,192
Просвещенцы.

69
00:06:06,435 --> 00:06:08,175
Но они создают такую иллюзию знаний.

70
00:06:08,175 --> 00:06:09,795
Её ради этого и создавали.

71
00:06:09,795 --> 00:06:20,275
То есть масштабы-то, конечно, там были заявки, что мы создаём компендиум всех знаний человечества, который всё это делает на просвещённом базовом фундаменте, свободном от предрассудков.

72
00:06:20,275 --> 00:06:26,559
Но в итоге качество этой энциклопедии объективное. Это вот аналог Википедии в худших её проявлениях.

73
00:06:26,559 --> 00:06:41,783
То есть это передёргивание некачественной информации, откровенно говоря, искажение, переворот, ну или просто высказывание банальностей с видом знания при полной потере неких фундаментальных даже философских принципов мышления и уж тем более всякой глубины.

74
00:06:41,783 --> 00:06:43,083
Но очень важный момент.

75
00:06:43,083 --> 00:06:51,723
Точно так же, как сегодня, владение, чтение этой Википедии позволяло её носителю ощущать себя очень образованным.

76
00:06:51,981 --> 00:06:57,101
Это же штука дорогая была, да? Книги в прекрасных переплетах, много.

77
00:06:57,101 --> 00:07:07,421
Вот богатый купец покупал себе этот набор книг, ставил на полочку и выглядел, в общем, компетентным, образованным человеком в глазах окружающих.

78
00:07:07,421 --> 00:07:12,327
В глазах окружающих. Эти люди с условными университетскими схоластами не спорили.

79
00:07:12,327 --> 00:07:16,627
Они не ходили на споры туда, ну или в твоей Метаф. Почему я так зацепил этот сюжет?

80
00:07:16,627 --> 00:07:17,707
Вот идеальный пример.

81
00:07:17,707 --> 00:07:28,027
То есть если бы когда они иногда оказывались в одной гостиной с человеком, который получил допрос в ученческое образование, они выглядели, откровенно говоря, некомпетентными идиотами.

82
00:07:28,060 --> 00:07:29,700
Но поэтому они с ними не спорили.

83
00:07:29,700 --> 00:07:36,940
Чаще всего они выбирали для самоутверждения какого-то действительно менее образованного, ну, условный паттерн сельского священника.

84
00:07:36,940 --> 00:07:42,380
Вот на читавшейся Википедии действительно можно очень хорошо оттоптаться на сельском священнике каком-нибудь или.

85
00:07:42,380 --> 00:07:44,160
На не очень образованном папе.

86
00:07:44,175 --> 00:07:45,335
Не имею ввиду не римский, а твой.

87
00:07:45,335 --> 00:07:53,875
Обычный там отец, дядя, вот он там всю жизнь там прослужил в полку, ходит по воскресеньям в церковь и, скажем так, при этом особо книжек не читал.

88
00:07:53,875 --> 00:08:00,735
У него есть четкое мировоззрение, он в нем уверен, но объяснить тебе на уровне силологизмов от него, в принципе, это никогда не требовалось.

89
00:08:00,735 --> 00:08:05,593
А тут ты приходишь, начитавшись этой инструкции, особенно если ты приехал с городу Парижу.

90
00:08:05,593 --> 00:08:10,913
В какой-нибудь провинциальный город Лион, и всё, и ты на коне, и ты лидер мнений.

91
00:08:10,913 --> 00:08:15,393
И вот эта фраза «лидер мнений» современная, она корнями уходит именно туда.

92
00:08:15,393 --> 00:08:18,873
Это то, что называется в историографии «салонная культура».

93
00:08:18,873 --> 00:08:26,753
То есть салонная культура — это на самом деле вопиющая необразованность, преподнесённая как моральное превосходство.

94
00:08:26,785 --> 00:08:34,665
Фактически с появлением социальных сетей эта салонная культура, в общем-то, утысячерилась именно в таком же формате.

95
00:08:34,665 --> 00:08:38,385
Начитались в Википедии, пошли спорить и отстаивать своё мнение.

96
00:08:38,385 --> 00:08:58,826
А тут получается какой-нибудь Альтман, который грамотно, последовательно развивал технологию, непосредственно относящаяся к экспертизе и к умению, может быть, в кавычках, мыслить, менять полностью парадигму исследований научных и так далее, ну, конечно, он должен считать себя человеком, который компетентен просто во всём.

97
00:08:58,826 --> 00:09:12,746
Если мы задаём вопрос через веб-интерфейс чата GPT, то он-то может задать вопрос с гораздо меньшими ограничениями на любую тему, и это наверняка у него уже давно родило такое внутреннее ощущение своего превосходства интеллектуального.

98
00:09:12,820 --> 00:09:13,640
Ну плюс деньги.

99
00:09:13,640 --> 00:09:14,640
Плюс деньги, конечно.

100
00:09:14,640 --> 00:09:15,180
Повторюсь.

101
00:09:15,180 --> 00:09:24,940
Принцип такой, и мне понравилась эта метафора, давай ее зафиксируем, то, что действительно вот эта салонная культура, социальные сети действительно просто стали такой же культурой, но в тотальном масштабе.

102
00:09:24,940 --> 00:09:33,982
И у салонной культуры есть несколько объективных признаков, которые мы можем наблюдать в прямом эфире и, скажем так, пожинать их плоды.

103
00:09:33,982 --> 00:09:37,824
Первое, это действительно, как ни крути, размытие компетенции.

104
00:09:37,824 --> 00:09:49,104
Пойми правильно, ты сам знаешь, мы с тобой в наших предыдущих сезонах постоянно критикуем, скажем так, вульгарный рационализм, типа наука превыше всего, бог науки, поэтому я не с этой позиции говорю.

105
00:09:49,104 --> 00:09:57,104
Но смысл в том, что действительно в условиях салона для неподготовленной аудитории крайне сложно оценить качество высказывания.

106
00:09:57,184 --> 00:10:01,864
На длинной дистанции это может всегда решаться феноменом репутации.

107
00:10:01,864 --> 00:10:04,804
Репутация создаётся, а потом репутация гибнет.

108
00:10:04,804 --> 00:10:12,222
Наша современная салонная культура, она же от предыдущей отличается ещё тем по форме, что она ещё более быстрая.

109
00:10:12,222 --> 00:10:19,340
Первая версия салонной культуры была на порядок более быстрее, чем, если тебе угодно, предшествующая эпоха.

110
00:10:19,340 --> 00:10:20,040
Ну, условно.

111
00:10:20,040 --> 00:10:26,200
До салонной культуры тебе надо не филитон было писать и некрасивую полемическую заметку, а трактат.

112
00:10:26,200 --> 00:10:30,674
Хочешь о чем-то поспорить, напиши трактат. Даже если ты споришь с какой-то позицией.

113
00:10:30,674 --> 00:10:32,354
Там, тот же Эраз в Роттердамске, ему.

114
00:10:32,354 --> 00:10:35,934
Приходилось писать, там, условно, вот этот «Корабль дураков». Да? Ну, это текст.

115
00:10:35,934 --> 00:10:37,894
Это большой такой текст и прочее.

116
00:10:37,894 --> 00:10:42,014
В 18 веке уже можно писать саркастические сфильтонские заметки, да?

117
00:10:42,014 --> 00:10:45,774
То есть это все равно ускорение текстового жанра. Пусть сегодня...

118
00:10:45,953 --> 00:10:52,453
Ускорение достигло такой степени, что, в принципе, отрефлексировать позицию человека практически невозможно.

119
00:10:52,453 --> 00:11:04,971
Ты имеешь в виду, что просто остановиться и попытаться понять логику и аргументацию, обоснованность высказывания Не хватает времени, надо уже отвечать на следующий тезис.

120
00:11:04,971 --> 00:11:10,931
И вообще люди разговаривают тезисами, утверждениями и забывают о том, что любое утверждение надо как-то обосновывать.

121
00:11:10,931 --> 00:11:18,011
Если оно звучит и подано хорошим, глубоким, правильным голосом, быстро и авторитетно, оно сразу считается как доказанное.

122
00:11:18,011 --> 00:11:20,091
Если донести вопрос том, это прикладная магия.

123
00:11:20,091 --> 00:11:24,811
Ну, я бы назвал это риторикой, ну, как бы такое, да, ну, допустим.

124
00:11:24,811 --> 00:11:32,931
Давай прямо говорить, есть много спикеров, которые, собственно, свою аудиторию собирают не содержание высказывания, а формы высказывания.

125
00:11:32,931 --> 00:11:41,191
Базовый смысл в том, что у людей идёт запрос на определённое, скажем так, эмоционально-психологическое воздействие от той или иной речи.

126
00:11:41,191 --> 00:11:45,589
И давай не скрывать, часть нашей аудитории тоже к нам относится примерно точно так же.

127
00:11:45,589 --> 00:11:49,749
Это всегда было, и есть объективная издержка, есть вопрос только в том, понимаешь ли.

128
00:11:49,749 --> 00:11:51,249
Ты этот риск и пытаешься ли ты.

129
00:11:51,249 --> 00:11:55,729
Условно не злоупотреблять, скажем так, этими особенностями современной культуры.

130
00:11:55,729 --> 00:11:56,749
Ну с чего мы начали?

131
00:11:56,749 --> 00:12:07,693
То, что в современной среде очень легко выглядеть образованным, очень легко выглядеть авторитетным, особенно если тому есть сопутствующие внешние признаки.

132
00:12:07,693 --> 00:12:14,013
Проблема в том, что на качество аргументов и на качество компетенции само по себе это все равно никак не влияет.

133
00:12:14,013 --> 00:12:30,315
Конкретно то, что мы обсуждали за кадром, можем немножко этого коснуться, это была вот эта эссе, знаменитая, написанная Сэмом Альтманом после его блога, где он показывает абсолютно некритическую в хорошем смысле этого слова, рефлексию относительно базовых вопросов.

134
00:12:30,315 --> 00:12:44,395
Ну, допустим, вопрос о том, что категория пользы, о которой он много говорит, что вот мы сейчас создаем дополнительную категорию пользы, дополнительную категорию счастья, невозможно осознать вне этического контекста, который он вообще не задает.

135
00:12:44,398 --> 00:12:46,638
Что значит «категория пользы»?

136
00:12:46,638 --> 00:12:50,458
К развитию искусственного интеллекта принесет огромную пользу человечеству.

137
00:12:50,458 --> 00:12:53,738
Высказывание такого рода. Понятное, нормальное высказывание.

138
00:12:53,738 --> 00:13:06,578
Проблема в том, что с философской точки зрения, если мы об этом пишем, то есть это нормальный текст для маркетолога, но с философской точки зрения утверждение является бессмысленным до тех пор, пока ты не определил, в какой системе координат ты свою пользу оцениваешь.

139
00:13:06,741 --> 00:13:14,281
Ну конечно, потому что любое «хорошо» или «плохо» имеет смысл только в системе координат, а польза — это априори что-то хорошее.

140
00:13:14,281 --> 00:13:17,441
Значит, нужно определить, что такое «хорошо» в этой системе координат.

141
00:13:17,441 --> 00:13:22,941
Например, больше денег — хорошо, меньше денег — плохо. Быть здоровым — хорошо, больным — плохо.

142
00:13:22,941 --> 00:13:27,061
Вот, например, если больше денег, но меньше здоровья, то как это сопоставить?

143
00:13:27,061 --> 00:13:28,821
Это разные сеточки координационные.

144
00:13:28,948 --> 00:13:37,108
Да, и те, кто так или иначе связан с философскими рассуждениями, они с такими категориями работают.

145
00:13:37,108 --> 00:13:38,968
То есть это та самая философская работа.

146
00:13:38,968 --> 00:13:42,088
Там есть разные школы, разные традиции, но.

147
00:13:42,088 --> 00:13:45,604
Тем не менее, эти вопросы задаются, эти вопросы ставятся на повестку.

148
00:13:45,604 --> 00:13:48,324
Да, он такое просто не ставит вообще, если я правильно понимаю.

149
00:13:48,324 --> 00:13:49,804
То есть у него все просто будет хорошо.

150
00:13:49,804 --> 00:13:56,724
Там есть очень много посылок, которые должны быть приняты, по сути, на веру без малейшей формулировки этих посылок.

151
00:13:56,724 --> 00:14:02,984
Ну, допустим, то, что рост сам по себе является абсолютным благом.

152
00:14:03,884 --> 00:14:07,930
Хочу зафиксировать наше внимание не на том, что мы тут ругаем Альтмана.

153
00:14:07,930 --> 00:14:10,750
Мне как раз кажется, что текст написанный.

154
00:14:10,750 --> 00:14:13,890
Очень искренний, и это меня по-настоящему и пугает.

155
00:14:13,890 --> 00:14:14,150
Да.

156
00:14:14,150 --> 00:14:19,070
Не то, что он злонамеренно не подевает и не задаётся философскими, этическими.

157
00:14:19,070 --> 00:14:20,990
В целом, такой вопрос у него не стоит.

158
00:14:20,990 --> 00:14:24,830
Ну вот ты склоняешься к тому, что он искренний, а я думаю, что он...

159
00:14:24,830 --> 00:14:37,466
Ну, я не верю, но человек, написавший такой блог, для которого проблема регулирования стоит в этой сфере очень острой, он пытается убедить, что не надо регулировать, что всё пойдёт само собой хорошо и так далее.

160
00:14:37,466 --> 00:14:46,581
Тут может быть небольшой этот элемент, о котором ты говоришь, но корневой, скажем так, ну, опять, у меня у тебя больше корпоративный взгляд, что, я думаю, имеет место и то, и другое.

161
00:14:46,581 --> 00:14:49,641
У меня философский. Я, повторюсь, с такими людьми очень общался.

162
00:14:49,641 --> 00:15:01,261
Ты сам прекрасно, наверное, знаешь, что чем выше поднимаешься на уровень этих техногигантов, тем поражаешься узость реальной их компетенции при ощущении почти божественности собственных возможностей.

163
00:15:01,261 --> 00:15:06,461
Техноаристократы с новой религией такого технологического детерминизма.

164
00:15:06,587 --> 00:15:15,167
Ну слушай, давай прямо сказать, вот кто умно об этом правильное название дал, как и ты к нему не относись, это не клан с его темным просвещением, просто параллели буквально.

165
00:15:15,167 --> 00:15:21,007
Если ты вспомнишь, вот мы с тобой довольно много обсуждали просвещенцев первой итерации, то есть 18 века.

166
00:15:21,007 --> 00:15:26,799
С философской точки зрения тексты просвещения на фоне предшествующей эпохи не выдерживают никакой критики.

167
00:15:26,799 --> 00:15:32,890
Я даже не говорю про восточных святых отцов, но даже с холастой любого просвещенца могут размазать по хлебушку.

168
00:15:32,890 --> 00:15:34,910
Просто по уровню качества аргументации.

169
00:15:34,910 --> 00:15:43,150
Что не мешало просвещенцам воплощать ровно такой же дух уверенности в том, что они несут общее благо, и они вообще знают, как весь мир устроен.

170
00:15:43,150 --> 00:15:46,832
Вот это страшное слово знаешь энциклопедистам. Она же в чём родилась?

171
00:15:46,832 --> 00:15:56,632
То есть, если раньше была ставка на цельное глубокое образование, то энциклопедист — это, по сути, была форма Википедии, где я прочитал пару статей Википедии, я эксперт по этому вопросу.

172
00:15:56,632 --> 00:15:58,932
Знаменитая энциклопедия Дидро и Вольтера.

173
00:15:58,932 --> 00:15:59,932
Интересно.

174
00:15:59,932 --> 00:16:01,672
Здесь есть какой-то параллелизм.

175
00:16:01,672 --> 00:16:05,692
То есть, он употребляет слова, используя, по сути, некий философский аппарат.

176
00:16:05,692 --> 00:16:11,212
Но откуда этот философский аппарат взялся вообще? На каких метафизических посылках он существует?

177
00:16:11,212 --> 00:16:14,028
Текст демонстрирует, что этот человек даже слова такого не слышал.

178
00:16:14,028 --> 00:16:21,063
Слушай, но я всё-таки попытаюсь аргументировать свою позицию или своё впечатление, что он действовал намеренно.

179
00:16:21,063 --> 00:16:28,203
Давай проанализируем качество текста и логически попробуем сделать анализ. Смотри, вот он что пишет?

180
00:16:28,203 --> 00:16:31,683
Он использует сознательно-пассивные конструкции.

181
00:16:31,683 --> 00:16:37,183
Появятся системы, могут появиться роботы, будет достигнут прогресс.

182
00:16:37,183 --> 00:16:43,840
Вопрос — а кто создаст эти системы? кто построит роботов, кто определит направление прогресса.

183
00:16:43,840 --> 00:16:50,040
Пассивный залог скрывает субъекта. Потом временная фальсификация. Есть такое понимание в риторике.

184
00:16:50,040 --> 00:16:54,840
25-й год увидел, 26-й вероятно увидит, 27-й может увидеть.

185
00:16:54,840 --> 00:16:59,760
Прошлое представлено как факт, настоящее как вероятность, будущее как возможность.

186
00:17:00,747 --> 00:17:05,807
К концу, в общем, читатель уже не различает, где там что произошло, что происходит.

187
00:17:05,807 --> 00:17:11,007
То есть это такое вот заклинание фактически, да? Вот то есть такое слово я поискал.

188
00:17:11,007 --> 00:17:14,827
Называется «эфемистический новояс».

189
00:17:14,827 --> 00:17:20,187
То есть применяют критики товарища Альтмана и говорят, что это же прекрасно.

190
00:17:20,187 --> 00:17:27,527
Мягкая сингулярность, широкий доступ к суперинтеллекту, новые политические идеи.

191
00:17:27,527 --> 00:17:37,227
Другими словами, потеря человеческого контроля над цивилизацией, монополия на познание и фактически отмены того, что так любят называть либералы, демократии.

192
00:17:37,227 --> 00:17:43,467
Потому что вот этот технофеодализм, о котором все так говорят, он здесь просто вот проступает.

193
00:17:43,467 --> 00:17:44,470
Что ты думаешь?

194
00:17:44,470 --> 00:17:50,370
Да, я думаю, он проступает, и ты правильно заметил, вот этот пассивный залог действительно очень важный.

195
00:17:50,370 --> 00:17:54,790
Это вот то, что в наших славянских языках, знаешь, вот такое выражение, ося.

196
00:17:54,790 --> 00:17:58,310
Оно как-то само сталося, или вот что-то, оно само.

197
00:17:58,310 --> 00:18:04,101
И ты прав в том, что в случае корпоративных форм, этот пассивный залог действительно скрывает субъекты, скрывает намерения.

198
00:18:04,101 --> 00:18:09,081
А кто все будет это делать? Ну смотри, он же прямо об этом пишет в конце. А делать это будем мы.

199
00:18:09,081 --> 00:18:17,601
Вот он прямо об этом пишет, что OpenAI — это множество, но сегодня, прежде всего, мы — компания по созданию сверхинтеллекта.

200
00:18:17,601 --> 00:18:25,381
Нам предстоит много работы, но основа пути перед нами сейчас освещена, и темные стороны быстренько уходят.

201
00:18:25,381 --> 00:18:29,721
И мы очень благодарны за то, что вот мы можем это все сделать. То есть... А, да.

202
00:18:29,796 --> 00:18:37,376
Мы строим мозг для всего мира. Он будет очень персонализирован и легок в использовании для всех.

203
00:18:37,376 --> 00:18:40,116
Нас будут ограничивать только наличие классных идей.

204
00:18:40,116 --> 00:18:43,296
Так что, видишь, он в конце-то говорит о том, что делать будем мы.

205
00:18:43,296 --> 00:18:47,509
Да, дальше действовать будем мы. Слушай, ну страшное дело, понимаешь, просто страшно.

206
00:18:47,509 --> 00:18:54,669
А страшнее для меня всего то, что эта вот пустышка, она будет очень привлекательна.

207
00:18:54,669 --> 00:18:56,969
Люди готовы будут поверить в эту сказку.

208
00:18:56,969 --> 00:19:01,729
Она удобная, снимает ответственность и за будущее, и за настоящее.

209
00:19:01,729 --> 00:19:03,309
Должен быть выбор у людей.

210
00:19:03,309 --> 00:19:06,129
А товарищ говорит, у нас это неизбежность.

211
00:19:06,162 --> 00:19:11,962
И этот ипот очень правильно поставил, то что текст построен на том, что у вас как бы и нет выбора.

212
00:19:11,962 --> 00:19:15,442
Мы все равно это сделаем. Очень важная постановка вопроса.

213
00:19:15,442 --> 00:19:29,782
Понятное дело, единственная надежда моя, это, собственно, позитивная новость, то что степень именно философской некомпетенции, собственно, и создает предпосылки, почему нас ждет впереди множество интересных сюрпризов, почему этот проект не реализуется так, как он мог бы реализоваться.

214
00:19:29,787 --> 00:19:40,047
А я здесь более пессимистично настроен, потому что в эпоху вот таких постмодернистского отсутствия каких-либо больших нарративов, вот вам нарратив.

215
00:19:40,047 --> 00:19:46,442
Он вообще нифига не новый, это тоже просвещение в старой оболочке, ничего не изменилось, даже его финальная метафора.

216
00:19:46,442 --> 00:20:00,062
Но это же самая сбитая, базовая, классическая, агностическая, просвещенческая метафора, пародия на первую главу Евангелия Таана «То, что был свет, и тьма не овладела им».

217
00:20:00,062 --> 00:20:01,222
Но это что же самое пародия?

218
00:20:01,222 --> 00:20:04,902
Ну видишь, я вот этого как раз не заметил. Хорошо, что мы с тобой вдвоем.

219
00:20:04,954 --> 00:20:08,234
Я считаю, что он абсолютно искренний фанатик.

220
00:20:08,234 --> 00:20:22,934
Но фанатик, который понимает, что для того, чтобы завербовать людей в свою веру, ему нужно немного срезать углы, сгладить противоречия, акцентировать на прекрасном новом будущем.

221
00:20:22,934 --> 00:20:29,934
Он верит в свою миссию. Вот что самое страшное — то, что он не захватывает власть, как фанатик.

222
00:20:29,934 --> 00:20:31,894
Он хочет получить её в подарок.

223
00:20:31,954 --> 00:20:37,694
То есть общество говорит, о, классно, да, давайте мы откажемся от способности думать о.

224
00:20:37,694 --> 00:20:40,274
Собственном будущем, потому что у нас есть супер-И, да?

225
00:20:40,274 --> 00:20:44,094
На самом деле мне не до конца понятно, где selling point.

226
00:20:44,094 --> 00:20:49,314
Ну, по сути, он прямо не пишет, но единственное, что я могу понять, это иллюзия бессмертия для избранных.

227
00:20:49,314 --> 00:20:51,694
Потому что все остальное, в принципе, и так непонятно.

228
00:20:51,694 --> 00:20:56,962
Что он продает-то этим людям, которые должны на это все с радостью согласиться? Свободу творчества?

229
00:20:56,962 --> 00:21:06,602
Ну, ты же сам пишешь уже в своем тексте, по сути, эту свободу творчества и надеется, что в перспективе творчества, по сути, будет не то, чтобы ненужным, но оно тоже будет вот это, сталося.

230
00:21:06,602 --> 00:21:09,882
То есть вот интеллект сам будет генерировать творческие идеи.

231
00:21:09,882 --> 00:21:18,722
Мне как раз очень, ты прав, фигуру умолчания, которая скрывается за этим классическим новоязом, тоже классическая схема, работает со времен, считайте, Левиафан Гоббса.

232
00:21:18,722 --> 00:21:23,442
Он прямо пишет инструкции, как надо создавать в университетах комиссаров, чтобы это работало.

233
00:21:23,442 --> 00:21:26,656
Так что схема тоже старая. Но там хоть понятно, что он им обещает.

234
00:21:26,656 --> 00:21:29,456
Хоббс хоть прямо пишет, я обещаю вам безопасность.

235
00:21:29,456 --> 00:21:33,676
Мне интересно, что Альтман даже четко не формулирует, а что, собственно, он продает.

236
00:21:33,676 --> 00:21:34,976
Не, он изобилие продает.

237
00:21:34,976 --> 00:21:45,296
Будет очень сложно, потому что исчезнут целые слои работ, но, с другой стороны, мы будем становиться богаче настолько быстрее, что мы сможем, в общем, все это позволить.

238
00:21:45,296 --> 00:21:47,076
Короче, безусловно, базовый доход.

239
00:21:47,082 --> 00:21:50,802
Я люблю приводить классический пример, по-моему, мы с тобой уже говорили об этом, что.

240
00:21:50,802 --> 00:21:52,402
Я уже в третий или четвёртый раз.

241
00:21:52,402 --> 00:21:59,782
Повторюсь, но освобождение человека от рутины домашнего труда не привело к взрывному росту поэтов.

242
00:21:59,782 --> 00:22:03,922
Художников и появлению каких-то хобби у тех.

243
00:22:03,922 --> 00:22:07,662
Кто теперь может часы проводить, не моя.

244
00:22:07,662 --> 00:22:10,302
Посуду и убирая, а заниматься творчеством.

245
00:22:10,302 --> 00:22:12,702
Люди смотрят сериалы, играют в игры.

246
00:22:12,702 --> 00:22:16,582
Ничего в этом самом себе плохого нет, но просто это время уходит в никуда.

247
00:22:16,582 --> 00:22:18,382
Фактически они отказываются жить.

248
00:22:18,382 --> 00:22:20,282
Как всегда, добавлю немного теологии.

249
00:22:20,282 --> 00:22:25,371
Можно сказать, что, конечно, любое наше подобное действие — это акт принесения жертвы.

250
00:22:25,371 --> 00:22:30,451
То есть главная жертва, которую мы приносим, — это пресловутое наше внимание, силы, ресурсы.

251
00:22:30,451 --> 00:22:33,011
И когда мы убиваем время в буквальном.

252
00:22:33,011 --> 00:22:36,831
Смысле, мы, конечно, осуществляем, по сути, идолопоклоннический акт.

253
00:22:36,831 --> 00:22:52,006
По сути, на самом деле, что Сэм Альтман намеренно или ненамеренно описывает будущее как такая тотальная машина жертвоприношения людей во всем широком смысле вот этому новому суперинтеллекту и тем, кто будет стоять за ним.

254
00:22:52,006 --> 00:22:52,720
Ну да.

255
00:22:52,720 --> 00:22:57,300
Это очень такая классическая библейская демоническая история, на самом деле.

256
00:22:57,300 --> 00:23:02,140
Каждый раз, когда вам обещают утопию, нужно поискать, а кто будет её администрировать.

257
00:23:02,140 --> 00:23:05,300
Если суммировать, наверное, то, что говорит Сэм.

258
00:23:05,300 --> 00:23:07,520
Альтман, это... Мир и безопасность, да?

259
00:23:07,520 --> 00:23:18,340
А вот нет, он пока говорит изобилие, пока предлагает изобилие и процветание, но мир и безопасность там очевидно, просто, наверное, нужна вторая часть эссе.

260
00:23:18,358 --> 00:23:23,598
Я прям все ждал, когда он будет написать, что ИИ будет прекрасно разрешать международные конфликты.

261
00:23:23,598 --> 00:23:27,298
Пока не написал, но явно предполагается, типа, все конфликты одни на понимание.

262
00:23:27,298 --> 00:23:33,098
Вот если у нас будет правильный искусственный интеллект в начальниках над всеми, то вот мы тогда установим глобальный мир.

263
00:23:33,098 --> 00:23:38,018
Ну, сразу скажу, вот это, кстати, причина, почему это не срастется, по крайней мере, я этого не ожидаю.

264
00:23:38,018 --> 00:23:42,858
Потому что для того, чтобы это срослось, нужно доверие между начальниками, а они друг другу доверять не могут.

265
00:23:42,858 --> 00:23:45,558
В данном случае это недоверие будет предохранителем.

266
00:23:45,595 --> 00:23:47,975
Да-да-да-да-да-да, я же не говорю, что это.

267
00:23:47,975 --> 00:23:51,215
Плохо, я просто показываю, скажем так, дырки в воровагументе.

268
00:23:51,215 --> 00:23:56,035
Но да, текст действительно впечатляет, это сочетание детской наивности.

269
00:23:56,035 --> 00:23:57,455
Если бы мне не сказали, кто этот.

270
00:23:57,455 --> 00:23:58,975
Текст написал, то действительно я бы сказал.

271
00:23:58,975 --> 00:24:08,195
Что он написан подростком, который открыл там первый закон физики или узнал, как это работает, и преобладает в полной уверенности, что он вот сейчас изменит мир, и он все знает.

272
00:24:08,258 --> 00:24:09,918
Всё будет телевидение.

273
00:24:09,918 --> 00:24:11,758
Да, да, слушай, Москва слезам не верит.

274
00:24:11,758 --> 00:24:16,278
В общем, да, вот этот разговор на кухне их, когда они молодые, вот очень тот же самый вайб.

275
00:24:16,278 --> 00:24:17,689
Всё будет телевидение.

276
00:24:17,689 --> 00:24:21,980
Казалось бы, но уже столько этого телевидения было, и сначала всех обучим.

277
00:24:21,980 --> 00:24:28,720
Потом электричество, потом радио, потом телевидение, потом у тебя социальные сети.

278
00:24:28,720 --> 00:24:33,680
И всегда есть громадный побочный эффект всех этих прелестей.

279
00:24:33,680 --> 00:24:37,720
Человек, тупо уставившийся в телевизор, прекращает читать.

280
00:24:37,720 --> 00:24:41,300
Он свою скуку убивает пассивность таким наблюдением.

281
00:24:41,300 --> 00:24:45,300
А тут нам говорят, что это было всё не то, но сейчас точно сработает.

282
00:24:45,366 --> 00:24:46,766
Ну смотри, давай просто суммируем.

283
00:24:46,766 --> 00:24:50,346
На самом деле здесь есть большая проблема, которую не только Альтман не понимает, а.

284
00:24:50,346 --> 00:24:53,526
Это вообще кажется темой всего нашего сезона.

285
00:24:53,526 --> 00:24:56,986
Потому что это философская проблема. Какое у нас есть заблуждение?

286
00:24:56,986 --> 00:25:06,646
Что мы не разделяем проблемы, то, что можно сказать антропологические, они же этические, они же философские, они же проблемы человеческого сердца.

287
00:25:06,662 --> 00:25:11,342
И технологически. И находятся они не в равной зависимости.

288
00:25:11,342 --> 00:25:15,642
Другими словами, как мне представляется, существует обратный закон.

289
00:25:15,642 --> 00:25:20,662
Иначе говоря, любую технологическую проблему можно дать антропологический ответ.

290
00:25:20,662 --> 00:25:25,618
Переводя на простой язык, нет той технологии, которая остановит святого к его пути к святости.

291
00:25:25,618 --> 00:25:31,613
Хоть 15 искусственных интеллектов изобрета, если сердце святого направлено к Богу, то он преодолеет эти вещи.

292
00:25:31,613 --> 00:25:34,853
То есть потенциал антропологического ответа, этического ответа.

293
00:25:34,853 --> 00:25:37,513
Духа бесконечно больше любой технологии.

294
00:25:37,513 --> 00:25:43,753
И наоборот, на любую проблему сердца Духа невозможно дать технический ответ.

295
00:25:43,753 --> 00:25:50,273
А все, что они предлагают, это, в принципе, вся наша цивилизация, это попытка дать технический ответ на антропологические проблемы.

296
00:25:53,862 --> 00:25:55,722
Всё-таки не могу не задать вопрос.

297
00:25:55,722 --> 00:26:13,862
Скажи, пожалуйста, я вот до сих пор колеблюсь, потому что то ли Сейм Альтман действительно настолько ограничен в понимании каких-то базовых, даже не философских, просто здравомыслия, что всё имеет обратную сторону, что нужно оценивать явления в комплексе.

298
00:26:13,862 --> 00:26:16,396
Кажется, это маловероятно, мне, по крайней мере.

299
00:26:16,396 --> 00:26:28,050
Или же он ведёт сознательную агитацию, имея в виду свои пряники, которые он должен получить в результате расширения влияния за счёт владения технологией развития искусственного интеллекта.

300
00:26:28,050 --> 00:26:31,210
Мой опыт показывает, что, скорее, первый.

301
00:26:31,210 --> 00:26:38,470
По крайней мере, в любой непонятной ситуации я вместо злонамеренности выберу искреннее, скажем так, вот это мировоззрение.

302
00:26:38,470 --> 00:26:39,450
Заблуждение, да.

303
00:26:39,450 --> 00:26:42,759
Но это нисколько даже заблуждение, понимаешь? Это мироощущение.

304
00:26:42,759 --> 00:26:45,648
Вот это вот есть мировоззрение, а есть мироощущение, да?

305
00:26:45,648 --> 00:26:52,608
Вот повторюсь, мироощущение, ну вот представь, ты молодой человек, относительно молодой, и ты один из богатейших людей планеты.

306
00:26:52,608 --> 00:26:57,348
Причем действительно создаёшь вещи, которые, ну, под твоим руководством.

307
00:26:57,348 --> 00:26:58,508
Лучше это понять, что не ты лично.

308
00:26:58,508 --> 00:27:06,364
Их создаёшь, но под твоим руководством создаются вещи, которые ни много ни мало, ну, ещё там 50 лет назад выглядели бы как магия.

309
00:27:06,364 --> 00:27:09,720
Психологически тот же самый феномен, что накануне про освещение.

310
00:27:09,720 --> 00:27:12,900
Мы там условно научились паровую машину создали.

311
00:27:12,900 --> 00:27:15,080
Или новые технологии там каналов рыть.

312
00:27:15,080 --> 00:27:16,000
Вау!

313
00:27:16,000 --> 00:27:17,060
Там или еще чего-то.

314
00:27:17,060 --> 00:27:18,560
Ну боги, боги, да.

315
00:27:18,560 --> 00:27:23,920
Как тут не поверить, что мы можем решить вообще все проблемы человечества и сразу.

316
00:27:23,920 --> 00:27:27,700
Тем более раньше они были вот... Тем более мы-то красивые люди.

317
00:27:27,700 --> 00:27:32,100
Там вот эти странные мракобесы сидят. Там они что-то ноют. Там они что-то ходят.

318
00:27:32,100 --> 00:27:34,943
Там они о чем-то говорят на своем высокоумном непонятном.

319
00:27:34,943 --> 00:27:38,823
Мы тут, конкретные пацаны, решаем конкретные задачи.

320
00:27:38,823 --> 00:27:41,063
У нас всё получается. Да?

321
00:27:41,063 --> 00:27:42,923
Да, ну... Поэтому весь XIX век —.

322
00:27:42,923 --> 00:27:47,323
Это, может быть, первый или, может быть, не первый, но второй эпоха технооптимизма.

323
00:27:47,323 --> 00:27:49,943
Ничего же нового в технооптимизме нет.

324
00:27:49,943 --> 00:27:55,180
Да, самому по себе нет. То есть был технооптимизм XIX века, он закончился Первым мировой.

325
00:27:55,180 --> 00:28:07,076
Первая версия техно-оптимизма очень умерла, потом был техно-оптимизм 50-х, 60-х, 70-х, волна техно-оптимизма, которая сменилась киберпанком в 80-х, но сейчас просто очередная волна техно-оптимизма.

326
00:28:07,076 --> 00:28:12,335
Структурно-то ничего, ты прав, абсолютно не изменилось, но масштаб другой, да? Но что пугает?

327
00:28:12,335 --> 00:28:17,935
Есть несколько признаков, которые все-таки именно эффект масштаба заставляют задуматься.

328
00:28:17,935 --> 00:28:27,379
Первый масштаб потенциально метафоричный джина, который эти товарищи выпускают из бутылки, не задаваясь ни на секунду вопросом.

329
00:28:27,379 --> 00:28:43,883
Я хочу здесь снова процитировать знаменитого нашего великого физиолога Бехтерева, который, изучая, правда, шизофреников, но, мне кажется, сказал гениальную фразу, которую каждому из нас просто жизненно необходимо выучить в эпоху социальных сетей, а именно, что власть — это торможение.

330
00:28:43,945 --> 00:28:49,205
Мы говорим о том, что в человеческой психике есть две функции — возбуждение и торможение.

331
00:28:49,205 --> 00:29:03,905
И именно в этом контексте Бектеров и сказал, что для того, чтобы обладать некоторой властью, нужно, чтобы функция торможения была развита, по крайней мере, не меньше, чем функция возбуждения, потому что только так мы можем контролировать свои импульсы.

332
00:29:03,905 --> 00:29:05,105
В этом смысле это имеет счёт?

333
00:29:05,207 --> 00:29:09,847
В этом смысле говорил Бектерев, а я применяю на, допустим, условно, социальной сети.

334
00:29:09,847 --> 00:29:11,907
Нас все время провоцируют на ускорение.

335
00:29:11,907 --> 00:29:13,387
Ну, это не то, что кто-то злой.

336
00:29:13,387 --> 00:29:16,567
А алгоритм социальных сетей построен на постоянном ускорении, да?

337
00:29:16,567 --> 00:29:21,087
То есть постоянное ускорение обмена информацией, постоянное ускорение потребляемого контента.

338
00:29:21,087 --> 00:29:26,787
Не длинная медиа, а рилсы. Твиттер, а не длинный пост, не книга, а длинный пост и так далее.

339
00:29:26,787 --> 00:29:28,287
Все идет по логике ускорения.

340
00:29:28,326 --> 00:29:37,726
Субъектность в эпоху социальных сетей, она во многом именно в способности отложить, закрыть, не смотреть, не слушать, не реагировать, не взаимодействовать.

341
00:29:37,726 --> 00:29:39,726
Вот это проявляется настоящая субъектность.

342
00:29:39,726 --> 00:29:42,406
Какое это отношение имеет ввиду к нашим новым технофеандалам?

343
00:29:42,406 --> 00:29:57,546
Наверное, самый радикальный момент, который как бы находится в слепом пятне во время чтения всех этих текстов, это то, что нигде не в тексте на секунду не ставится вопрос, что возможность что-то сделать не означает необходимость это сделать.

344
00:29:57,587 --> 00:30:04,927
Другими словами, раз мы можем сделать эту технологию, раз мы можем сделать то или иное решение, значит, мы будем это делать.

345
00:30:04,927 --> 00:30:17,427
То есть ни на секунду не задается вопросом, с какой скоростью, с какой последовательностью, с каким-то интенсивностью, на каком этапе, с какими подготовительными периодами для общества нужно интегрировать ту или иную технологию такого масштаба.

346
00:30:17,427 --> 00:30:19,487
Вот этот вопрос не ставится вообще.

347
00:30:19,487 --> 00:30:24,187
Просто общество ставится перед фактом, мы вам это сделаем, и вы будете счастливы.

348
00:30:24,351 --> 00:30:35,291
Мы с тобой часто приходим к тому, что вся логика развития событий, весь этот старт, который мы относим к XVI веку, просто неутомимо и неумолимо прибежал к нас к этой точке.

349
00:30:35,291 --> 00:30:56,573
Когда технологии развились настолько, что человек не в состоянии с ними конкурировать, когда технологические оптимисты нажимают на эту педальку ещё больше и больше, имея в виду, что они управляют этим транспортным средством, И они ведут куда-то, куда, по их разумению, мы обязаны прийти и получить там счастье.

350
00:30:56,573 --> 00:30:58,093
Ну и чем это закончится?

351
00:30:58,093 --> 00:31:03,153
Ну, как бы не хочется быть негативным, но похоже, что это должно закончиться неизбежно.

352
00:31:03,153 --> 00:31:04,713
Столкновение с какой-то стенкой.

353
00:31:04,713 --> 00:31:14,873
Здесь вот этот момент, о котором, я думаю, стоит будет сделать отдельный эфир, потому что вот самые умные из наших техно-оптимистов — это вот те самые экстериорционисты.

354
00:31:14,873 --> 00:31:18,178
Вот как раз те люди, которые уже получили философскую подготовку.

355
00:31:18,178 --> 00:31:24,798
Они поддерживают твой тезис, на самом деле, но вывод этический делают из него совсем другой.

356
00:31:24,798 --> 00:31:27,798
Другими словами, то, что это не стенка, это сингулярность.

357
00:31:27,798 --> 00:31:43,049
То, что, скажем так, кто-то намеренно, а кто-то ненамеренно из наших технофеодалов действительно приближает момент, который является, как они хотят верить, некой точкой качественного скачка, или перехода, или катастроф, это объективный процесс, в котором мы живем.

358
00:31:43,049 --> 00:31:50,869
Там, где мы говорим на протяжении наших эфиров то, что у технологических вопросов должно быть антропологическое решение, они продолжают, как это.

359
00:31:50,869 --> 00:31:53,149
Даблдаун, удваивать ставки на то, что на.

360
00:31:53,149 --> 00:31:57,949
Человеческую проблему мы дадим технологическое решение. Это как раз разные этики.

361
00:31:58,294 --> 00:32:15,017
Но мы и пытались с тобой до сих пор убедить наших слушателей в том, что ответа на технологический вызов в рамках технологий не может быть, что этот ответ должен быть за пределами этой системы технологических решений.

362
00:32:15,017 --> 00:32:23,797
Я думаю, что буквально, может быть, и следующий выпуск мы посвятим больше не технологическому вызову, а антропологическому ответу.

363
00:32:23,797 --> 00:32:32,417
Потому что для многих становится вопросом, ну и мы с тобой пытались ответить на этот вопрос, а что же значит этот антропологический ответ?

364
00:32:32,417 --> 00:32:37,377
Проще говоря, что значит быть человеком в эту эпоху технологических вызовов?

365
00:32:37,410 --> 00:32:42,870
И здесь, я думаю, мы пригласим человека, который… Ну я не думаю, я лукавлю, конечно.

366
00:32:42,870 --> 00:32:54,490
Я знаю, что мы собираемся пригласить человека, который согласился помочь нам рассмотреть вот этот вопрос о человечности с философской точки зрения, с точки зрения академической философии, скажем так.

367
00:32:54,490 --> 00:32:58,370
И я уверен, что этот разговор будет нам небезнолезнен.

368
00:33:02,402 --> 00:33:04,202
Ты знаешь, я о чём думаю?

369
00:33:04,202 --> 00:33:19,851
Вот этот антропологический ответ и в целом наша цивилизационная травма — попытка при помощи интеллекта, то есть технология — это же продукт интеллектуальных усилий, решить задачи, которые не решаются таким способом.

370
00:33:19,851 --> 00:33:28,371
попытка умом построить рай на земле, попытка… В конечном итоге человек — это же далеко не только интеллект и ум.

371
00:33:28,371 --> 00:33:36,471
Ведь очень многие, наверное, мы знаем людей, которые не обладают выдающимися интеллектуальными способностями, но они прекрасные люди.

372
00:33:36,471 --> 00:33:38,591
И в этом не надо смеяться, человек хороший.

373
00:33:38,591 --> 00:33:52,837
Бывает в каких-то далёких деревнях, крестьяне, которые, в общем, имеют смутное представление о технологиях и, наверное, не смогут тебе рассказать ничего о законах физики, математики и чего-то ещё.

374
00:33:52,837 --> 00:33:56,397
Их кругозор узок, но они, как люди, великолепны.

375
00:33:56,397 --> 00:34:03,057
Они добры, они открыты, они искренни, они доверчивы, но при этом очень просты.

376
00:34:03,057 --> 00:34:05,977
Не могу найти слов, наверное, каждый понимает, о чём я говорю.

377
00:34:05,977 --> 00:34:11,397
То есть человечность — это далеко не только и, может быть, не столько интеллект.

378
00:34:11,657 --> 00:34:18,837
Вот-вот-вот, это ты абсолютно прав. Это точно не интеллект. Можно сказать, что это Логос как имя.

379
00:34:18,837 --> 00:34:20,717
Но тут вот надо разбираться, чем Логос.

380
00:34:20,717 --> 00:34:22,797
Отличается от интеллекта, но я с тобой.

381
00:34:22,797 --> 00:34:26,677
Абсолютно прав. Я с тобой здесь абсолютно согласен, и это как раз, если мы.

382
00:34:26,677 --> 00:34:35,097
Смотрим философскую пред-пред-пред-пред посылку всего этого безумия, то, что мы сегодня обсуждали, это именно убеждение, что мы прежде всего интеллект.

383
00:34:35,097 --> 00:34:37,977
А на этом стоит ни много ни мало вся наша цивилизация.

384
00:34:38,185 --> 00:34:42,905
Да, мы же меряем людей по IQ. Да, у нас культ интеллекта.

385
00:34:42,905 --> 00:34:47,225
Принято восхищаться людьми незаурядных интеллектуальных способностей.

386
00:34:47,225 --> 00:34:51,005
Причем смотри, это же двойная итерация. У нас же как было, сначала у.

387
00:34:51,005 --> 00:34:57,645
Них был интеллект, поскольку там natural intellect и natural philosophy — это вот как раз просвещение первой итерации, но дальше пришла.

388
00:34:57,645 --> 00:35:00,005
Проблема, они сами себя, по сути говоря.

389
00:35:00,005 --> 00:35:06,325
Провергли постмодернизмом, а именно Дарвином, а именно Фрейдом, а именно проблемой предопределенности, проблемой предкоза.

390
00:35:06,325 --> 00:35:13,458
Другими словами, их же в кавычках наука, показала им, что, в общем, интеллект, human intellect, то есть человеческий интеллект, faulty.

391
00:35:13,458 --> 00:35:16,838
У него там эмоции, тонато, смортидо, либидо.

392
00:35:16,838 --> 00:35:22,838
То есть, ну, вместо того, чтобы переосмыслить базовую посылку, что, может быть, не в интеллекте только дело, условно-исамельную нам предлагать.

393
00:35:22,838 --> 00:35:24,507
Технологии добавим, да, да.

394
00:35:24,507 --> 00:35:34,987
Так вот получается, что искусственный интеллект или вот этот будущий генерализированный интеллект фактически как раз и доводит до логического конца это рассуждение.

395
00:35:34,987 --> 00:35:36,467
Ну вот вам интеллект.

396
00:35:36,467 --> 00:35:43,467
То, что они называют искусственным интеллектом, оно должно настолько превосходить человеческий интеллект, измеряемый.

397
00:35:43,467 --> 00:35:48,707
Вот этот интеллект будет измеряться теми мерками, которые подходили к интеллекту человеческому.

398
00:35:48,707 --> 00:35:53,267
Окажется, что самый большой интеллектуал — это не человек. А что остаётся человеку?

399
00:35:53,329 --> 00:35:57,196
что остается от человека? Вот возникают такие вопросы.

400
00:35:57,196 --> 00:36:02,583
То есть, по сути, он предлагает, пока мы ещё не до конца, давайте нам свои идеи, но вопрос остаётся открытым.

401
00:36:02,583 --> 00:36:03,823
А что остаётся от человека?

402
00:36:03,823 --> 00:36:05,543
То есть мы достигаем предела.

403
00:36:05,543 --> 00:36:18,163
И мы с тобой в каждом из выпусков приходим к одному и тожем выводу, что вот это технологическое развитие, эта сингулярность — это и катастрофа нового времени, катастрофа ставки на интеллект.

404
00:36:18,163 --> 00:36:26,063
Технология, которая призвана была при помощи интеллектуальных усилий, изобретений решать проблемы человека, создаёт новые проблемы.

405
00:36:26,235 --> 00:36:32,855
Но тут возникает уже проблема следующего порядка, что цена философского сначала отката к базовой.

406
00:36:32,855 --> 00:36:37,135
Проблеме с каждым технологическим витком возрастает.

407
00:36:37,135 --> 00:36:41,135
Называется sunking cost fallacy, если по-простому. Это классическая проблема.

408
00:36:41,135 --> 00:36:43,235
То есть теперь, отказавшись от этого, мы.

409
00:36:43,235 --> 00:36:46,515
Столько потеряем, что мы уже не можем от этого отказаться?

410
00:36:46,738 --> 00:36:50,038
Но мы думаем, что мы не можем. Да, и поэтому лучше даблдаун.

411
00:36:50,038 --> 00:36:54,258
Удвоить ставку и попытаться решить проблему за счет количественного скачка.

412
00:36:54,258 --> 00:37:02,418
Ага. Попробовали при помощи пара. Ну, что-то получилось, что-то нет. Там детский труд, то все, 5-10.

413
00:37:02,418 --> 00:37:06,818
Попробовали с помощью электричества. Улучшилось что-то, но все же не то.

414
00:37:06,818 --> 00:37:08,818
Попробовали при помощи атома.

415
00:37:09,148 --> 00:37:20,548
Но при этом каждый раз среда улучшалась, то есть все равно материальная среда радикально менялась, потому что, ты называй там, комфорт, возможности, власть росла, то есть все время.

416
00:37:20,548 --> 00:37:25,828
Теперь получается, что этот комфорт, он фактически делает человека заложником.

417
00:37:26,192 --> 00:37:38,232
мы становимся заложниками комфорта и тех решений, которые уже обеспечивают нам минимальные затраты энергии на решение тех задач, которых у наших предков требовало невероятное количество энергии.

418
00:37:38,232 --> 00:37:47,391
Теперь мы вынуждены наращивать мышцы искусственными упражнениями в зале, что, наверное, было бы странно для многих из наших прадедушек и прабабушек.

419
00:37:47,391 --> 00:38:01,430
Хотя нет, наверное, уже тогда для аристократии физкультура была не в новинку, но тем не менее мы фактически обречены на вот этот антропологический ответ, если не хотим исчезнуть как люди.

420
00:38:01,430 --> 00:38:03,090
Да, и в каком-то смысле, если искать.

421
00:38:03,090 --> 00:38:10,110
Эсхатологический оптимизм во всех этих историях, повторюсь, то что искусственный интеллект просто радикально нас ставит перед этим вызовом.

422
00:38:10,337 --> 00:38:19,077
Ты хотел прятаться за этим, но вот теперь мы действительно технологически создаем такую иллюзию, которая создает вот это воискушение твоей полной отмены.

423
00:38:19,077 --> 00:38:19,857
Что выберешь?

424
00:38:19,973 --> 00:38:23,633
И хочу сделать шаг назад. Многие говорят, слушайте, чего это вы тут паникуете?

425
00:38:23,633 --> 00:38:28,753
Ну, инструмент новый изобрели. Просто берём этот инструмент и пользуемся им.

426
00:38:28,753 --> 00:38:42,633
Но фундаментальное отличие ИИ или АИ от лопаты или молотка, что лопата и молоток сами себя не совершенствуют, не развивают сами себя, они не делают тебя менее субъектным.

427
00:38:42,633 --> 00:38:45,473
Как мы говорили ранее, книга сама себя не напишет.

428
00:38:45,572 --> 00:38:50,032
А вот теперь, да, напишет, снимет, нарисует и еще как.

429
00:38:50,032 --> 00:38:56,092
И еще за тебя, как вот мы в первом выпуске говорили, за тебя твоим же голосом расскажет то, что ты и не думал говорить.

430
00:38:56,092 --> 00:38:58,432
И пойди отличи, что тебя от фальшивки.

431
00:38:58,432 --> 00:39:02,672
Ну, в общем, да, веселые времена, на что надеемся, Павел Александрович.

432
00:39:02,852 --> 00:39:05,292
На антропологию, на ту самую, на этику.

433
00:39:05,292 --> 00:39:06,952
На вечную истину, на ту самую.

434
00:39:06,952 --> 00:39:07,852
Все туда.

435
00:39:07,852 --> 00:39:13,452
То есть лишний повод посмотреть честно себе в зеркало и спросить, а все-таки что делает меня человеком?

436
00:39:13,452 --> 00:39:16,852
Что есть человеческое в человеке?

437
00:39:16,852 --> 00:39:23,632
Повторюсь, для меня главный парадокс в том, что чем больше мы развиваем технологию, тем более остро встает антропологический вопрос.

438
00:39:23,828 --> 00:39:29,548
Хорошо, а я, ты знаешь, скажу немножко иначе, не так возвышенным и о другом.

439
00:39:29,548 --> 00:39:42,812
Всё время, что человечество движется по этому пути технического прогресса и утопического мышления, любая утопия противоречит самому характеру человека.

440
00:39:42,812 --> 00:39:48,052
«Ну не хочу, я хочу, как я хочу», — вот моя дочка говорила. «Давай так». «Нет, я хочу, как я хочу».

441
00:39:48,052 --> 00:39:55,703
Вот этот дух противоречия, который может быть очень деструктивным, но он может в то же самое время быть таким предохранителем.

442
00:39:55,703 --> 00:39:59,934
Все время напоминаю вот этот двойной перевод. У нас вот, понимаешь, все-таки нужно понимать.

443
00:39:59,934 --> 00:40:03,414
Это, кстати, интересно, что косвенно отражено в разных культурах.

444
00:40:03,414 --> 00:40:07,194
Мне ближе православная, она же с греческим подтекстом.

445
00:40:07,194 --> 00:40:10,694
Апокалипсис у нас воспринимается синонимом к слову «катастрофа».

446
00:40:10,694 --> 00:40:13,274
Но его дословный перевод — «откровение».

447
00:40:13,274 --> 00:40:18,594
То есть открытие истину, то есть более честный взгляд на мир, какой он есть, да, и на себя.

448
00:40:18,621 --> 00:40:25,261
То есть, с одной стороны, это, конечно, катастрофа, и можно делать акцент на катастрофу, но с другой стороны, это возможность для.

449
00:40:25,261 --> 00:40:28,141
Честности и правды, а это самоценность.

450
00:40:28,141 --> 00:40:38,341
Мне кажется неизбежным то, о чём говорит Альтман, и точно так же мне кажется неизбежным вот эта вот катастрофа апокалипсис в хорошем смысле слова.

451
00:40:38,341 --> 00:40:40,341
Апокалипсис в хорошем смысле слова.

452
00:40:40,341 --> 00:40:47,161
Те, кто останутся людьми, они, в общем, не смогут ими не быть, или те, кто захотят остаться людьми.

453
00:40:47,161 --> 00:40:53,560
Те, кто предпочут тут жить в резервации, ну, в общем, исчезнут. Просто исчезнут.

454
00:40:53,560 --> 00:40:58,180
Повторюсь, я рад, что в силу естественных причин я этого уже не увижу.

455
00:40:58,180 --> 00:41:00,504
Тебе вообще, возможно, ещё и придётся.

456
00:41:00,504 --> 00:41:08,528
Ну, во-первых, ты-то, как это, Альтман нам предрекает это уже к 30-м, а я надеюсь с тобой плотворно еще долго работать, так что ты тут это, не зарекайся особенно.

457
00:41:08,528 --> 00:41:20,148
Слушай, ну вот Алиса, наша собеседница из предыдущего подкаста, она часто говорит, ну ребята, ну вы посмотрите, насколько вот это распространение технологии на самом деле идет медленно.

458
00:41:20,148 --> 00:41:29,768
Да, там на кончике иглы или на вершине пирамиды все там уже в Сан-Франциско уже беспилотные такси приезжают, как совершенно обычное явление.

459
00:41:29,817 --> 00:41:40,217
А в остальном мире многие ещё воду из колодца набирают и не понимают, зачем им нужно то или другое.

460
00:41:40,217 --> 00:41:42,157
Ну вот не знаю, поглядим.

461
00:41:42,157 --> 00:41:43,737
Пока есть горы и лес.

462
00:41:43,737 --> 00:41:50,737
В общем, так хочу сказать вам, дорогие друзья, если вам кажется, что мир сходит с ума, в общем, это не паранойя.

463
00:41:50,742 --> 00:41:57,402
Это довольно адекватная реакция на то, что происходит вокруг, на, в общем, несколько неадекватную реальность.

464
00:41:57,402 --> 00:42:03,642
И выход не в том, чтобы становиться умнее, а в том, чтобы становиться человечнее.

465
00:42:03,642 --> 00:42:05,202
Прекрасно сказано.

466
00:42:05,202 --> 00:42:07,942
Хорошо. Спасибо, друзья. До новых встреч.

467
00:42:07,942 --> 00:42:15,082
Пишите, ругайте, находите несоответствие, делайте нас лучше, полируйте, шлифуйте наши несовершенства.

468
00:42:15,082 --> 00:42:17,702
Мы вам будем за это только благодарны. Всего вам доброго.
