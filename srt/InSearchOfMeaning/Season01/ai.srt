1
00:00:08,460 --> 00:00:13,340
Speaker 1: Нейросеть станет лучшим собеседником для эмоционально-чувствительного человека.

2
00:00:13,600 --> 00:00:21,380
Speaker 0: Среднеэмоциональная потребность, которая ожидается зачастую в отношениях, она стала такой, что удовлетворить её может только искусственный интеллект.

3
00:00:36,220 --> 00:00:37,060
Speaker 1: Здравствуйте, друзья!

4
00:00:37,480 --> 00:00:44,320
Speaker 1: В эфире очередной выпуск подкаста Евгения Голуба и Павла Щелина «В поисках смысла».

5
00:00:44,640 --> 00:00:55,060
Speaker 1: Сегодня темой или затравкой для нашего разговора послужит необычное произведение, необычная серия знаменитого мультсериала «Южный парк».

6
00:00:55,380 --> 00:00:57,140
Speaker 0: Приветствую вас, уважаемые зрители.

7
00:00:57,340 --> 00:01:03,340
Speaker 0: Действительно, сегодня затравкой для нашего эфира стала четвёртая серия 26 сезона этого мультсериала.

8
00:01:03,520 --> 00:01:08,220
Speaker 0: В силу той темы, которая в нём поднимается, для вас это, я думаю, не станет большим удивлением.

9
00:01:08,400 --> 00:01:20,980
Speaker 0: Потому что в своей ироничной манере этот, скажем так, сатирический титан американской мультипликационной индустрии поднимает проблематику чата GPT и его влияние на социальные отношения.

10
00:01:21,240 --> 00:01:27,140
Speaker 1: Нужно сказать, что этот сериал-то вообще на самом деле... Саркастический, развлекательный, юмористический.

11
00:01:27,280 --> 00:01:31,200
Speaker 1: Предполагается, что за кадром раздается хохот и все остальное.

12
00:01:31,260 --> 00:01:37,160
Speaker 1: Но я, честно говоря, когда посмотрел эту серию, мне было вообще совершенно не смешно, а наоборот очень-очень грустно.

13
00:01:37,400 --> 00:01:40,780
Speaker 0: Весь, скажем так, золотой фонд South Park — это именно пора подумать.

14
00:01:41,120 --> 00:01:45,560
Speaker 0: Но тем не менее, тема чата GTP сейчас обсуждается крайне активно, крайне сильно.

15
00:01:45,840 --> 00:01:50,460
Speaker 0: Мы, с одной стороны, не хотели просто... ловить хайп, как говорят современные блогеры.

16
00:01:50,900 --> 00:01:57,500
Speaker 0: Тем не менее, она действительно достаточно важная для будущего человечества и социальных отношений проблематика.

17
00:01:58,120 --> 00:02:14,160
Speaker 0: И мы решили вот с такой достаточно юмористического ключа подойти к этому вопросу и выйти на какие-то большие, глубинные, проблематичные, что называется, аспекты, которые, возможно, до сих пор не были обсуждены, по крайней мере, с той интенсивностью, как бы нам этого хотелось.

18
00:02:14,360 --> 00:02:22,400
Speaker 1: Точно, потому что основная дискуссия крутится вокруг... угроз искусственного интеллекта или того, что называют искусственным интеллектом.

19
00:02:22,800 --> 00:02:31,100
Speaker 1: То, что послужило для меня поводом тревожиться или огорчаться, то, о чём я не слышал ни разу в многочисленных бурных дискуссиях.

20
00:02:31,300 --> 00:02:35,240
Speaker 1: Давайте, наверное, начнём с того, что коротко перескажем сюжет этой серии.

21
00:02:35,680 --> 00:02:40,820
Speaker 1: Всё крутится там вокруг того, что одна из девочек хвастается подружкам.

22
00:02:41,240 --> 00:02:46,820
Speaker 1: тем, какие замечательные, эмоциональные, трогательные сообщения она получает от своего друга.

23
00:02:47,000 --> 00:02:49,500
Speaker 1: Ну и все начинают ей завидовать откровенно.

24
00:02:49,780 --> 00:02:57,840
Speaker 1: Заканчивается дело тем, что одна из её подружек жалуется своему молодому человеку, что от него таких сообщений не приходит.

25
00:02:58,000 --> 00:03:10,820
Speaker 1: И он уже в поисках решения приходит к тому самому герою, который умудряется писать такие проникновенные сообщения своей девочке, на что он открывает ему страшные тайны, что вообще-то он пользуется специальным приложением.

26
00:03:10,920 --> 00:03:16,660
Speaker 1: на основе чата GPT, которая позволяет ему не тратить много времени на всю эту ерунду, скажем так.

27
00:03:16,720 --> 00:03:27,900
Speaker 1: В мультфильме намного более грубые выражения используются, потому что его подружка задолбала этими смс-ками, а так он тратит буквально несколько секунд и отправляет им то, что генерирует чат.

28
00:03:28,120 --> 00:03:42,600
Speaker 1: Попрошающий, да, был страшно уизумлён, но, придя домой с некоторым неуверенностью, он начинает пользоваться этим чатом, приложением на основании чата, и оказывается, что это производит... волшебный эффект просто на отношения.

29
00:03:42,780 --> 00:03:50,060
Speaker 1: Показывает, как девушка начинает получать такие трогательные, такие глубокие, такие глубоко заинтересованные в ней тексты.

30
00:03:50,520 --> 00:03:51,760
Speaker 1: Она тут же радуется.

31
00:03:52,040 --> 00:03:54,400
Speaker 1: Она не может отрываться от этой переписки.

32
00:03:54,460 --> 00:03:55,500
Speaker 1: Она показывает всем.

33
00:03:55,720 --> 00:04:11,300
Speaker 1: В то время как мы видим... что молодой человек отправляет их одной рукой, не глядя, занимаясь своими делами, прям сидя в туалете, играя в баскетбол, играя в компьютерные игры, и тем самым, в общем-то, он себя снимает это всё тяготой общения со своей барышней.

34
00:04:11,540 --> 00:04:28,220
Speaker 1: Ну и, в конце концов, девушка просит его написать какую-то сказку на ночь для неё, на что он даёт это задание чату GPT, и тот присылает большую трогательную историю, и мы видим, как девушка засыпает с блаженной улыбкой от того, что она видит, насколько хорошо к ней относится молодой человек.

35
00:04:28,420 --> 00:04:33,120
Speaker 0: Параллельно в серии просматривается вторая линия, связанная с проблематикой домашних заданий.

36
00:04:33,280 --> 00:04:39,640
Speaker 0: Тот же главный герой, Стэн, начинает использовать чат GPT для того, чтобы делать домашние задания в школе.

37
00:04:39,900 --> 00:04:47,140
Speaker 0: Очень быстро выясняется, что, во-первых, они очень, получается, разумеется, качественные, стандартные вот эти эссе, которые генерируют ему чат.

38
00:04:47,320 --> 00:04:52,540
Speaker 0: И также выясняется то, что помимо него есть еще четыре парня, которые заняты той же самой деятельностью.

39
00:04:52,600 --> 00:04:54,320
Speaker 0: Это такая вторая конфликтная линия.

40
00:04:54,560 --> 00:05:05,540
Speaker 0: Она полна своей иронии, потому что впоследствии проверяющий эти задания учитель сам устает проверять эти задания, начинает генерировать фидбэк на то, что генерировала нейросеть.

41
00:05:06,120 --> 00:05:07,320
Speaker 0: И здесь очень много иронии.

42
00:05:07,740 --> 00:05:09,980
Speaker 0: Больше деталей я, наверное, вам рассказывать не буду.

43
00:05:10,420 --> 00:05:11,680
Speaker 0: Рекомендую самим посмотреть.

44
00:05:12,360 --> 00:05:13,940
Speaker 1: Серия называется Deep Learning.

45
00:05:14,620 --> 00:05:15,520
Speaker 0: Да, Deep Learning.

46
00:05:17,040 --> 00:05:20,060
Speaker 0: И, думаю, перейдем к тем темам, которые мы с тобой хотим обсудить.

47
00:05:20,140 --> 00:05:23,280
Speaker 0: В данном случае для нас это просто триггер к фундаментальной проблеме.

48
00:05:23,580 --> 00:05:31,040
Speaker 0: И вот первая фундаментальная проблема, которую высветила эта серия, высветила чат GPT, — это проблематика эмоционального интеллекта.

49
00:05:31,280 --> 00:05:42,140
Speaker 0: Это проблематика, с одной стороны, эмоционального запроса в современном развитом демократическом обществе, можно сказать, проблемы эмоциональных потребностей в отношениях в постмодерне.

50
00:05:42,540 --> 00:05:46,800
Speaker 0: С одной стороны, неспособность среднестатистического человека эту потребность заполнить.

51
00:05:47,180 --> 00:05:51,960
Speaker 0: А с другой стороны, как показывается, машина может справляться с этим гораздо более эффективно.

52
00:05:52,240 --> 00:05:59,400
Speaker 1: Ну потому что в её распоряжении весь опыт человечества за многие сотни лет, скорость к реакции, использование всего этого дела.

53
00:05:59,580 --> 00:06:03,500
Speaker 0: Я думаю, здесь именно важны все элементы, поднятые мной в видении.

54
00:06:03,660 --> 00:06:07,700
Speaker 0: Первое — это... качественное изменение потребностей в отношениях.

55
00:06:07,840 --> 00:06:11,240
Speaker 0: По-научному это называется романтизация повседневности.

56
00:06:11,500 --> 00:06:27,820
Speaker 0: То есть если классическая семейная модель предполагала прежде всего отношения скорее прагматические, то есть вы вступали в своего рода контракт с определенной лайф-целью на всю жизнь, с определенными экономическими компонентами, с определенными компонентами воспроизведения, ну то есть дети.

57
00:06:28,020 --> 00:06:38,200
Speaker 0: В рамках этой модели вот эта эмоциональная составляющая, она присутствовала, она важна, но в принципе даже если... если ее не будет, то есть более важные вещи, которые удерживают людей вместе.

58
00:06:38,600 --> 00:06:43,540
Speaker 1: Это было такое партнерство, скорее, союз для совместного проживания и выживания.

59
00:06:43,780 --> 00:06:50,380
Speaker 0: Не просто проживание, здесь именно слово выживание, мне кажется, более... Применимо, и партнерство здесь выглядит немножко потребительски.

60
00:06:50,460 --> 00:06:54,300
Speaker 0: Я бы здесь это смотрел все-таки именно в более историческом контексте.

61
00:06:54,360 --> 00:06:55,960
Speaker 0: То есть это не было именно про потребление.

62
00:06:56,020 --> 00:07:07,180
Speaker 0: Было довольно взрослое осознание то, что в одиночку решить вот эти большие социальные проектные элементы человеческой жизни невозможно, то есть планировать на 70 лет, особенно в контексте следующих поколений.

63
00:07:07,480 --> 00:07:12,860
Speaker 0: И, соответственно, у каждого члена семьи были определенные обязанности, ответственности и так далее.

64
00:07:13,300 --> 00:07:19,200
Speaker 0: А 70-е, в связи с изменением, кстати, в экономике тоже, но и психологии, то есть тут сложно сказать, что идет впереди.

65
00:07:19,800 --> 00:07:23,760
Speaker 0: В зависимости от вашей философии вы разные будете давать ответы на этот вопрос.

66
00:07:23,840 --> 00:07:30,500
Speaker 0: Происходит, с одной стороны, изменение экономической модели, то есть семья становится ненужной в плане экономики массово.

67
00:07:30,860 --> 00:07:33,360
Speaker 0: Человек может спокойно выражить в одиночку всю жизнь.

68
00:07:33,520 --> 00:07:36,180
Speaker 0: Это принципиальное изменение, такого не было никогда ранее.

69
00:07:36,600 --> 00:07:42,300
Speaker 1: То есть семья, получается, восполняет потребность только в эмоциональном общении?

70
00:07:42,900 --> 00:07:48,240
Speaker 0: Не только из семьи, из отношений, потому что отношения всегда являются проекцией вашей семейной модели.

71
00:07:48,460 --> 00:07:51,860
Speaker 0: Выкидывается всё, кроме вот этого эмоционального компонента.

72
00:07:51,920 --> 00:07:55,980
Speaker 0: То есть пребывание с этим человеком должно вам давать чувствовать себя эмоционально хорошо.

73
00:07:56,300 --> 00:07:59,480
Speaker 0: Это происходит вот на рубеже как раз нашего уже периода.

74
00:07:59,600 --> 00:08:02,580
Speaker 0: С последнего мы живем то, что называется постмодерном.

75
00:08:02,780 --> 00:08:05,980
Speaker 0: И здесь наблюдается просто проблема то, что люди в целом это не выводят.

76
00:08:06,060 --> 00:08:12,320
Speaker 0: Особенно это хорошо видится вот в серии «Недаром показано гендерное различие», потому что в целом мужчины не свойственны этим заниматься.

77
00:08:12,500 --> 00:08:20,880
Speaker 0: То есть мужчины традиционно ассоциируются, например, с прагматикой, они ассоциируются с некоторым экономической деятельностью, а оказывается, что этот навык не особо нужен.

78
00:08:21,080 --> 00:08:24,820
Speaker 0: И тогда возникает вопрос, как удовлетворить эмоциональные потребности партнера.

79
00:08:25,540 --> 00:08:31,440
Speaker 1: что ты, конечно, немножко преувеличиваешь, потому что все-таки и экономические навыки тоже важны.

80
00:08:31,740 --> 00:08:39,460
Speaker 1: И вот в той же Европе, насколько мы знаем, трудно выдержать жизнь, давление экономическое в семье, у которых нет двух работающих людей.

81
00:08:39,659 --> 00:08:40,799
Speaker 0: Там о другом идет речь.

82
00:08:41,039 --> 00:08:48,640
Speaker 0: Но при этом же в Европе проще жить в подвале у родителей, ну и в Америке тоже, чем создавать отношения, если вас интересует экономический вопрос.

83
00:08:48,960 --> 00:08:50,420
Speaker 0: Здесь можно долго уходить в детали.

84
00:08:50,560 --> 00:08:52,980
Speaker 0: Я просто подчеркнул, над чем немножко серия иронизирует.

85
00:08:53,040 --> 00:09:02,620
Speaker 0: Она иронизирует над тем, что... среднеэмоциональная потребность, которая ожидается зачастую в отношениях, она стала такой, что удовлетворить её может только искусственный интеллект.

86
00:09:02,840 --> 00:09:03,320
Speaker 1: Интересно.

87
00:09:03,620 --> 00:09:05,320
Speaker 1: Я как раз вот об этом не думал.

88
00:09:05,440 --> 00:09:11,340
Speaker 1: Я всегда думал, что испокон веков потребность в эмоциях, в отношениях была достаточно высокая.

89
00:09:11,400 --> 00:09:16,340
Speaker 1: Ну иначе откуда же вся поэзия, вся романтическая проза, всё вот это вот наше наследие?

90
00:09:16,640 --> 00:09:26,340
Speaker 0: На самом деле есть книжки, исследования, я сходу не скажу, но они подчеркивают, вот культ романтической любви, он возникает только в XIX веке по-настоящему, на массовом уровне.

91
00:09:26,420 --> 00:09:36,100
Speaker 0: До этого, конечно, были культ прекрасной дамы, культ трубадуров, но это очень локализовано и очень для конкретных социальных классов.

92
00:09:36,300 --> 00:09:38,760
Speaker 0: Это очень специфическая ниша в большой социальной модели.

93
00:09:38,920 --> 00:09:49,920
Speaker 0: А вот массовый культ романтической любви на высоком уровне возникает только в XIX веке, а на коммерциализированном... уровне только в 50-е и 60-е годы с эпохой потребления в США.

94
00:09:50,300 --> 00:09:55,280
Speaker 1: Мы говорим о том, что две тенденции или два явления, которые отличают наше время.

95
00:09:55,500 --> 00:10:05,300
Speaker 1: С одной стороны, бытовая экономическая независимость человека от семьи, отсутствие потребности в партнёре для выживания и воспитания детей.

96
00:10:05,560 --> 00:10:09,200
Speaker 1: Будем говорить так, что и в детях потребность тоже снизилась.

97
00:10:09,500 --> 00:10:13,300
Speaker 1: Но осталась потребность в эмоциональном комфорте, в общении.

98
00:10:13,680 --> 00:10:19,440
Speaker 0: Даже уточню, Жень, тут, наверное, важнее не просто в эмоциональном комфорте, а в нарциссическом эмоциональном комфорте.

99
00:10:19,540 --> 00:10:22,600
Speaker 1: То есть быть важным, быть в центре чего-то внимания, да?

100
00:10:22,820 --> 00:10:23,840
Speaker 0: Ну, как это же в этой серии.

101
00:10:23,880 --> 00:10:26,280
Speaker 0: То есть девочка хочет постоянного внимания к ней.

102
00:10:26,480 --> 00:10:36,920
Speaker 0: То есть не реального эмоционального контакта с молодым человеком в том мире, который они могут создать в этих условиях, а того, что она хочет вот в силу своего нарциссического представления о самой себе.

103
00:10:37,580 --> 00:10:41,660
Speaker 1: Да, и ей важно делиться этим с другими, показывать, что она важна.

104
00:10:41,880 --> 00:10:42,220
Speaker 1: Точно.

105
00:10:42,380 --> 00:10:43,280
Speaker 1: Теперь всё совпало.

106
00:10:43,600 --> 00:10:51,280
Speaker 1: Нарциссизм, как характерная черта последних, может быть, не знаю, ста лет возрастающих, нарциссическая компонента всего.

107
00:10:51,820 --> 00:10:58,240
Speaker 1: И как потребность в улетворении вот этих нарциссических всех дыр — эмоциональность.

108
00:10:58,820 --> 00:11:07,380
Speaker 1: завышенная эмоциональность и одновременно, о чём мы ещё не говорили, неспособность человека генерировать вот это эмоциональное содержание.

109
00:11:07,740 --> 00:11:10,640
Speaker 0: Я здесь даже уточню, это неадекватное, на мой взгляд, ожидание.

110
00:11:10,740 --> 00:11:15,480
Speaker 0: Потому что, на мой взгляд, вот этого нарциссического монстра нормальный человек удовлетворить не может.

111
00:11:15,660 --> 00:11:16,820
Speaker 0: В этом-то и сык парадокса.

112
00:11:17,140 --> 00:11:22,100
Speaker 0: То, что для удовлетворения этого нарциссического монстра чат GTP действительно подходит в разы лучше.

113
00:11:22,480 --> 00:11:33,780
Speaker 0: То есть это же главный парадокс получается, что степень нарциссической потребности среднестатистического человека в эпоху постмодерна достигла таких масштабов, что удовлетворить ее может только нейросеть.

114
00:11:34,000 --> 00:11:34,940
Speaker 0: По-моему, вот в этом суть.

115
00:11:35,520 --> 00:11:37,460
Speaker 1: Ты знаешь, я смотрел на это с другой стороны.

116
00:11:37,580 --> 00:11:39,740
Speaker 1: Я не воспринимал это как постоянную потребность.

117
00:11:39,820 --> 00:11:43,720
Speaker 1: Для меня вот этот эпизод был как некоторый всплеск потребности.

118
00:11:43,940 --> 00:11:44,940
Speaker 1: Скорее всего, ты прав.

119
00:11:45,200 --> 00:11:53,200
Speaker 1: Мне показалось грустным то, что в принципе человек оказывается не способен проявлять какую-то эмоцию, выраженную в тексте.

120
00:11:53,660 --> 00:12:00,180
Speaker 1: Для меня это следствие другого явления, о котором мы ещё пока не говорили, о снижении в целом когнитивной функции человека.

121
00:12:04,100 --> 00:12:09,660
Speaker 0: Вторая проблематика этого эпизода показывает проблему перспектив креативных профессий.

122
00:12:09,820 --> 00:12:20,660
Speaker 0: Вопреки всем опасениям футурологов и предсказаниям, оказалось, что на данный момент работа краснодеревщика или сантехника в разы более защищена, чем работа условного человека креативной профессии.

123
00:12:20,880 --> 00:12:23,840
Speaker 0: И в сериале очень хорошо показана причина этого процесса.

124
00:12:23,960 --> 00:12:38,000
Speaker 0: Причина заключается в том, то, что практически 90%, наверное, процентов работы того, что мы склонны считать креативной деятельностью, на самом деле не является креативной деятельностью, а просто является комбинаторикой уже совершенного.

125
00:12:38,180 --> 00:12:47,860
Speaker 0: И вот вместе комбинаторики, вместе склеивания просто различных кусочков информации, которые уже присутствуют, человеку конкурировать с нейросетью невозможно.

126
00:12:48,200 --> 00:12:53,140
Speaker 0: И вот в этом возникает фундаментальная проблема и на уровне социума, и на уровне экономики.

127
00:12:53,320 --> 00:13:07,360
Speaker 0: Потому что если мы движемся в эпоху, где единственной ценностью будет обладать способность генерировать что-то принципиально новое, то это требует совершенно других когнитивных способностей от человека.

128
00:13:07,660 --> 00:13:09,460
Speaker 1: Слушаю тебя и размышляю.

129
00:13:09,920 --> 00:13:17,640
Speaker 1: Мне не приходило в голову действительно, что потребность в эмоциональной компоненте общения значительно выросла за последнее время.

130
00:13:17,760 --> 00:13:23,960
Speaker 1: Ну, может быть, в силу той литературы или того общения, которое у меня есть, мне кажется, что всегда потребность в эмоциях была высока.

131
00:13:24,160 --> 00:13:32,000
Speaker 1: И мне казалось, что в начале 20-го, в конце 19-го века эта эмоциональность, может быть, даже была ещё выше, эта чувствительность к эмоциям.

132
00:13:32,460 --> 00:13:36,740
Speaker 1: Но, видимо, скорее можно объединить две вещи.

133
00:13:36,820 --> 00:14:06,240
Speaker 1: оппозиции в том смысле, что это было уделом очень небольшого количества людей, а сейчас в силу экономических причин или в силу того же благополучия, о котором мы говорили в первом выпуске нашего подкаста, гораздо большее количество людей достигли... такого состояния, когда для них эмоциональный комфорт и внимание к Личности, к своей персоне, что потребность — это тоже культивируется современной культурой, в общем-то, достигло того, что жадность или нелетворённая потребность постоянно растёт.

134
00:14:06,700 --> 00:14:08,560
Speaker 1: Размер этой дыры всё больше увеличивается.

135
00:14:08,780 --> 00:14:12,740
Speaker 1: Приходит время наилучшего мастера компиляции комбинаторики.

136
00:14:13,060 --> 00:14:20,340
Speaker 0: Вот это самое главное, то, что в области комбинаторики конкурировать с нейросетью уже через год-два будет невозможно.

137
00:14:20,520 --> 00:14:23,560
Speaker 0: И здесь к вам, уважаемым слушателям, я задаю очень простой вопрос.

138
00:14:23,620 --> 00:14:26,200
Speaker 0: Вы должны осознать, чем ваша работа является по сути.

139
00:14:26,380 --> 00:14:34,800
Speaker 0: И если ваша работа по сути является не более чем комбинаторикой, ну, допустим, вы берете стандартные образцы исковых заявлений, заполняете их под конкретный случай.

140
00:14:35,100 --> 00:14:37,240
Speaker 0: Нейросеть справится с этой работой в разы лучше.

141
00:14:37,280 --> 00:14:48,120
Speaker 0: Если вы что-то делаете стандартное в области текста, будь то написание новостей, даже гени... Оперирование контента, где вы просто пересказываете и комментируете действия других людей, у вас будут большие проблемы.

142
00:14:48,260 --> 00:14:58,700
Speaker 0: Потому что комбинация искусственного интеллекта с нейросетью, ну, допустим, еще добавим дипфейки, то есть можно будет создавать реалистичные видеоаватары, с ними действительно невозможно конкурировать.

143
00:14:58,860 --> 00:15:02,880
Speaker 0: По сути, это удар по вот так называемому креативному среднему классу.

144
00:15:04,060 --> 00:15:04,620
Speaker 0: Это будущее.

145
00:15:04,920 --> 00:15:11,700
Speaker 1: То есть сегодня все боятся, в кавычках, конечно, за судьбу программистов, которые могут заменить искусственный интеллект, нейросеть.

146
00:15:11,960 --> 00:15:13,000
Speaker 0: Это тоже вполне вероятно.

147
00:15:13,080 --> 00:15:22,200
Speaker 0: Огромное количество программистов занимается не генерированием нового, а либо поддержанием старого, либо из уже существующих кусочков собрать единое.

148
00:15:22,280 --> 00:15:25,720
Speaker 0: Вот если вы программист на этом уровне, то у вас тоже будут проблемы.

149
00:15:26,200 --> 00:15:28,860
Speaker 1: Скорость прогресса этой технологии изумляет.

150
00:15:29,020 --> 00:15:34,160
Speaker 1: Буквально за полгода-год достигнуты такие результаты, которые ошеломляют.

151
00:15:34,320 --> 00:15:45,840
Speaker 1: Я думаю, что вы легко найдёте в интернет последнее исследование, которое расскажет вам и о химических соединениях, и о том, как нейросеть обманывала человека, чтобы добиться нужного результата.

152
00:15:46,080 --> 00:15:47,340
Speaker 1: Историй всё больше и больше.

153
00:15:47,640 --> 00:15:56,100
Speaker 1: Видишь, я начал со своей грусти по поводу того, что нейросеть станет лучшим собеседником для эмоционально-чувствительного человека.

154
00:15:56,480 --> 00:16:01,540
Speaker 0: Она, с одной стороны, может дать эмоцию, а с другой стороны, сама вроде в эмоциях пока не нуждается.

155
00:16:01,580 --> 00:16:05,060
Speaker 0: То есть она может удовлетворять вот эту бесконечную энергетическую дыру.

156
00:16:05,420 --> 00:16:06,920
Speaker 1: Она не расходует свою энергию.

157
00:16:07,200 --> 00:16:11,480
Speaker 1: Человеку, чтобы сгенерировать эмоцию, нужно потратить энергию, собственно, психическую.

158
00:16:12,060 --> 00:16:12,980
Speaker 1: Она не бесконечна.

159
00:16:13,200 --> 00:16:19,380
Speaker 1: Нейросеть делает это комбинаторно, абсолютно ничего не тратя, ну, кроме электрической энергии.

160
00:16:19,680 --> 00:16:20,660
Speaker 0: И мы этого захотим.

161
00:16:20,860 --> 00:16:25,120
Speaker 0: И вот тоже очень важный момент, что среднестатистический человек, скорее всего, этого захочет.

162
00:16:25,360 --> 00:16:37,960
Speaker 0: Если он не проведёт радикальной философской трансформации внутри себя, некого радикального преображения, в который он волевым усилием убьёт в себе в той мере, в которой она есть сейчас, вот эту нарциссическую потребность, то он выберет нейросеть.

163
00:16:38,400 --> 00:16:49,100
Speaker 1: Значит, он выберет нейросеть, потому что волевой компонент современного человека не хватает на то, чтобы зарядку делать по утрам, а не говоря уже о том, чтобы отказаться от удовлетворения нарциссической потребности.

164
00:16:49,300 --> 00:16:54,320
Speaker 1: Я совершенно не сомневаюсь, что через некоторое время будет конкуренция двух нейросетей.

165
00:16:54,380 --> 00:17:01,100
Speaker 1: Одна нейросеть будет генерировать сообщения, а другая будет отслеживать, с кем именно сгенерировано это сообщение.

166
00:17:01,280 --> 00:17:06,220
Speaker 1: Какие-то будут значки, что вот это аутентичное, а это сгенерировано машиной, наверное.

167
00:17:06,540 --> 00:17:17,640
Speaker 1: И ещё та вещь, о которой я хотел поговорить, но ведь это означает такого рода применение инструмента, ослабление способности человека вообще генерировать какой-то творческий контент.

168
00:17:18,060 --> 00:17:23,220
Speaker 1: Творчество всегда в некоторой степени или в большой степени компиляция с какими-то своими добавлениями.

169
00:17:23,319 --> 00:17:27,700
Speaker 1: А если можно будет получать содержимое, не напрягаясь, почему бы этого не делать?

170
00:17:28,560 --> 00:17:37,960
Speaker 1: Мы сейчас ходим в спортзалы, чтобы развить свою мускулатуру и выносливость, в то время как нашим предкам не пришло бы это в голову, мышцы им были нужны для выживания.

171
00:17:38,200 --> 00:17:43,860
Speaker 1: Как ты думаешь, не приведёт ли развитие этих инструментов к деградации ещё одной сферы человеческой деятельности?

172
00:17:44,120 --> 00:17:48,080
Speaker 0: Я не знаю, какое у нас будущее, но это точно ставит фундаментальный вызов.

173
00:17:48,180 --> 00:17:58,540
Speaker 0: Потому что, повторюсь, мне кажется, на этот момент люди недооценивают, насколько комбинаторика является становым хребтом современной экономики в области креативной деятельности.

174
00:17:58,600 --> 00:18:02,820
Speaker 0: Поскольку мы с тобой занимаемся подобной деятельностью, мы чуть больше это видим.

175
00:18:02,980 --> 00:18:11,760
Speaker 0: Мы прекрасно с тобой понимаем, что 90% спикеров, даже официальных государственных, даже на очень чувствительных должностях, можно уже сейчас заменять на аэросети.

176
00:18:11,840 --> 00:18:20,900
Speaker 0: Они не произносят ничего нового, они просто генерируют слова, которые в них вложил кто-то другой, или они сами просто вложили, реагируя на действия вот этой системы.

177
00:18:21,080 --> 00:18:26,660
Speaker 0: Суть в том, что там нет вот этого радикального акта создания чего-то нового, творения чего-то нового.

178
00:18:27,080 --> 00:18:27,480
Speaker 1: Точно.

179
00:18:27,780 --> 00:18:32,480
Speaker 1: Я хотел сказать только, что каждый из наших слушателей может сам убедиться в этом.

180
00:18:32,720 --> 00:18:33,280
Speaker 1: Очень просто.

181
00:18:33,500 --> 00:18:38,980
Speaker 1: Вам нужно будет зайти по ссылочке на чат GPT и задать любой политический вопрос.

182
00:18:39,200 --> 00:18:41,200
Speaker 1: Любой вопрос, связанный с политической тематикой.

183
00:18:41,660 --> 00:18:48,980
Speaker 1: То, что вы получите в ответ, и нужно сказать, что на любом языке эта нейросеть вам может ответить, ничем не будет отличаться от ответа любого политика.

184
00:18:49,240 --> 00:18:51,460
Speaker 1: Настолько близко, что ошеломляет.

185
00:18:51,640 --> 00:19:02,000
Speaker 1: Понимаем, что первых, кого может заменить нейросеть, это спикеров политических деятелей, представителей политической элиты, которые пытаются заявлять своё мнение о любой проблеме.

186
00:19:02,220 --> 00:19:03,740
Speaker 0: И вот здесь наступает вот этот момент.

187
00:19:04,080 --> 00:19:12,680
Speaker 0: С одной стороны, единственным ценным в наступающем мире постчатов является способность к творчеству, способность к свободному мышлению.

188
00:19:12,940 --> 00:19:19,420
Speaker 0: А с другой стороны, все предыдущие десятилетия вся система образования была направлена на уничтожение этой способности.

189
00:19:19,500 --> 00:19:21,960
Speaker 0: Ну, по крайней мере, если не на уничтожение, то на подавление.

190
00:19:22,080 --> 00:19:27,780
Speaker 0: То есть мало того, что мы стоим перед вызовом, мы к этому вызову подступаем максимально неподготовленными.

191
00:19:27,960 --> 00:19:32,160
Speaker 0: То есть у нас все наши институты не готовы социально к этой реальности.

192
00:19:32,220 --> 00:19:33,380
Speaker 0: Вот это очень важный момент.

193
00:19:33,680 --> 00:19:41,060
Speaker 1: Да, мы говорим о том, что современное образование так или иначе родилось в эпоху развития капиталистического производства.

194
00:19:41,200 --> 00:19:45,820
Speaker 1: Необходимо было готовить массово специалистов, рабочих, работников.

195
00:19:46,100 --> 00:19:48,780
Speaker 1: Массовое образование, оно неизбежно шаблонно.

196
00:19:49,180 --> 00:19:51,960
Speaker 0: Давайте прямо говорить, не просто рабочих, а солдат.

197
00:19:52,200 --> 00:19:58,220
Speaker 0: То есть система современного образования, прусская модель, рождается после поражения Германии при Йене и Орштете.

198
00:19:58,300 --> 00:20:10,980
Speaker 0: И во многих наработках Фихта была создана идея в том, что новой армии нужен солдат, который будет готов выполнять приказы послушно и умирать в пропорциях, которые эпохи до XIX века были бы невообразимы.

199
00:20:11,380 --> 00:20:13,960
Speaker 0: То есть корень нашего современного образования очень интеллектуальный.

200
00:20:14,140 --> 00:20:22,020
Speaker 0: В нем по дизайну в исходном коде заложено стремление к ограничению... свободного творческого порыва человека, потому что его сложно контролировать.

201
00:20:22,180 --> 00:20:25,340
Speaker 0: А мы должны контролировать человека, чтобы получить ожидаемый результат.

202
00:20:25,400 --> 00:20:29,000
Speaker 0: Нам очень важно контролировать, чтобы средний результат был вот в пределах нормы.

203
00:20:29,300 --> 00:20:31,380
Speaker 0: И вот прямо поэтому чат GPT и бьет.

204
00:20:31,460 --> 00:20:34,200
Speaker 0: Вот именно поэтому я эту программу с тобой хотел записать.

205
00:20:34,520 --> 00:20:46,080
Speaker 0: Мы очень недооцениваем именно вот этого глубинно-психологических перемены в требованиях к когнитивным способностям не просто отдельного человека, а, я повторюсь, среднего человека.

206
00:20:46,260 --> 00:20:51,180
Speaker 0: Потому что, ну, допустим, какие-то творческие гении, творческая элита всегда существовала, будет существовать.

207
00:20:51,360 --> 00:20:54,540
Speaker 0: Но ее всегда было мало, а для других было чем заняться.

208
00:20:54,600 --> 00:20:54,900
Speaker 0: Вопрос.

209
00:20:55,220 --> 00:21:01,240
Speaker 0: Если вы сейчас убиваете все эти креативные профессии, в кавычках, креативный в кавычках, то куда вы этих людей денете?

210
00:21:01,520 --> 00:21:02,900
Speaker 1: Ну, вопрос риторический.

211
00:21:03,140 --> 00:21:12,560
Speaker 1: Мне пришло в голову, что наиболее подготовленные к технологиям люди — это были дворянские дети, которые получали домашнее образование с репетиторами.

212
00:21:12,980 --> 00:21:14,900
Speaker 0: А современная элита так и получает.

213
00:21:14,940 --> 00:21:23,300
Speaker 0: Если вы посмотрите на детей всех этих криптомиллионеров и миллиардеров в силиконовой долине, они образование получают примерно как дворянские дети 19 века.

214
00:21:23,520 --> 00:21:25,200
Speaker 1: Там уже ничего шаблонного нет.

215
00:21:25,580 --> 00:21:32,340
Speaker 1: Нет единой программы для 30 или 25 детей, утвержденной и разработанной по единому стандарту.

216
00:21:32,660 --> 00:21:39,100
Speaker 1: Индивидуальный подход к человеку и стремление научить его думать самостоятельно, встречаться с произведениями искусства и литературы.

217
00:21:39,360 --> 00:21:40,280
Speaker 0: Ну, тут два варианта.

218
00:21:40,700 --> 00:21:54,920
Speaker 0: Там либо это, либо там всё-таки требования к среднестатистическому школьнику, такие, как в дореволюционных гимназиях, когда есть, с одной стороны, стандартная программа, но степень сложности этой стандартной программы такова, что волей-неволей в человеке возникает эта способность генерировать новое.

219
00:21:55,140 --> 00:22:05,760
Speaker 0: Это изучение древних языков, это латынь древнегреческий, это и сочинение такого уровня, которое сегодня не напишет 99% журналистов и так далее и тому подобное.

220
00:22:06,220 --> 00:22:09,420
Speaker 1: Для того, чтобы убедиться в этом, достаточно открыть книгу.

221
00:22:09,920 --> 00:22:14,120
Speaker 1: Начало XX века или даже просто газетную статью прочитать?

222
00:22:14,540 --> 00:22:15,760
Speaker 0: Лучше газетную статью.

223
00:22:16,000 --> 00:22:22,440
Speaker 0: Очень видно, как изменился язык на уровне газеты и очень даже сильно изменился язык на уровне писем, которые люди друг другу писали.

224
00:22:22,680 --> 00:22:24,740
Speaker 0: То есть как они описывали окружающий мир.

225
00:22:24,820 --> 00:22:29,260
Speaker 0: Они условно могли описать пейзаж за окном, используя там 30-40 прилагательных.

226
00:22:29,420 --> 00:22:33,400
Speaker 0: Смотрите, сколько вы прилагательных в своей собственной речи используете, уважаемые слушатели.

227
00:22:33,860 --> 00:22:34,940
Speaker 0: Я здесь от вас не отделяю.

228
00:22:34,980 --> 00:22:38,280
Speaker 0: У меня гораздо беднее речь, чем она была в начале XX века.

229
00:22:38,460 --> 00:22:41,360
Speaker 1: Делаю вывод, что это следствие системы образования.

230
00:22:41,620 --> 00:22:42,520
Speaker 0: Ну всей целиком.

231
00:22:42,760 --> 00:22:44,720
Speaker 0: Система образования не возникает и в вакууме.

232
00:22:44,780 --> 00:22:48,500
Speaker 0: Она возникает как реакцию на определённый государственный и экономический запрос.

233
00:22:48,820 --> 00:22:57,380
Speaker 1: Завершая наш разговор, мы можем сказать, возникновение нейросетей — это вызов, масштаб которого ещё предстоит осмыслить.

234
00:22:57,720 --> 00:23:07,580
Speaker 1: Скорее всего, это то явление, которое, может быть, превзойдёт по степени влияния появления смартфонов или, может быть, интернета, или, по крайней мере, сопоставимо с этим.

235
00:23:07,820 --> 00:23:08,740
Speaker 0: Оно точно произойдёт.

236
00:23:08,860 --> 00:23:11,940
Speaker 0: Это сравнимо, наверное, с изобретением парового двигателя.

237
00:23:12,220 --> 00:23:24,240
Speaker 0: Если вот промышленная революция началась с изобретения парового двигателя и механической прялки в 18 веке и последствия, которые потом пошли в создание индустриальной эпохи и так далее, вот чат GPT — это вот такого рода масштаб перемен.

238
00:23:24,400 --> 00:23:26,420
Speaker 0: Это даже, мне кажется, не конвейер Форда.

239
00:23:26,620 --> 00:23:32,480
Speaker 0: Хотя конвейер Форда тоже был таким вот фундаментальным сдвигом, который создал по-настоящему современное массовое производство.

240
00:23:32,720 --> 00:23:34,140
Speaker 0: А это вот из такого масштаба.

241
00:23:34,460 --> 00:23:36,980
Speaker 0: Повторю, самое важное, что мы вообще к этому не готовы.

242
00:23:37,240 --> 00:23:40,240
Speaker 0: Мы с тобой как философы не особо к этому тоже готовы.

243
00:23:40,500 --> 00:23:47,180
Speaker 0: Главное, к этому не готовы социальные и государственные системы, системы образования, потому что скорость, время на адаптацию.

244
00:23:47,240 --> 00:23:52,220
Speaker 0: То есть чат GPT достигнет своей уже критической массы в течение ближайшего года полутора.

245
00:23:52,660 --> 00:23:56,900
Speaker 0: Год-полтора — это вообще никакой срок, чтобы менять не школьную систему, никакую систему.

246
00:23:57,360 --> 00:23:58,740
Speaker 0: То есть времени на адаптацию нет.

247
00:23:58,840 --> 00:24:12,080
Speaker 0: Получается, с чем вы сейчас в этот новый дивный мир входите, вот насколько у вас сейчас есть способность генерировать новые идеи, по-настоящему новые, не просто пересобирать, а что-то новое создавать, вот настолько вы в этом новом мире будете успешны.

248
00:24:12,440 --> 00:24:13,860
Speaker 0: Я почему начал с краснодеревщиков?

249
00:24:13,940 --> 00:24:21,700
Speaker 0: Если вы можете оригинальную фигурку из дерева выточить, вам в каком-то смысле в разы лучше, чем, повторюсь, какому-нибудь маркетологу или новостнику.

250
00:24:21,900 --> 00:24:23,580
Speaker 0: в среднестатистическом информагентстве.

251
00:24:23,920 --> 00:24:27,260
Speaker 1: Мы как бы стоим перед локомотивом, который движется прямо на нас.

252
00:24:27,560 --> 00:24:35,260
Speaker 1: И тут уже зависит от того, насколько хорошо ты умеешь прыгать в сторону или как быстро ты можешь соображать в этой ситуации.

253
00:24:35,520 --> 00:24:36,680
Speaker 1: Подготовиться невозможно.

254
00:24:36,980 --> 00:24:45,840
Speaker 1: То, с чем мы сейчас пришли, как ты говоришь, с тем, что пришли наши дети, то и определит судьбу и будущее на ближайшие 20 лет.

255
00:24:46,280 --> 00:24:46,660
Speaker 0: Думаю, да.

256
00:24:46,880 --> 00:24:47,880
Speaker 0: Возможно, и на больше.

257
00:24:48,440 --> 00:24:54,760
Speaker 0: Если такую какую-то подводить позитивную коду, но все-таки мы оказались в этом мире, какая вот практическая рекомендация всем?

258
00:24:55,100 --> 00:25:02,080
Speaker 0: Делать волевые усилия, направленные на формирование в ваших детях именно этой способности по творению нового.

259
00:25:02,260 --> 00:25:07,240
Speaker 0: То есть вот этот старый мир, где было важно прилежное исполнение, он в каком-то смысле уходит.

260
00:25:07,500 --> 00:25:11,920
Speaker 0: Важна именно способность к... творчеству, но к творчеству настоящему.

261
00:25:11,960 --> 00:25:12,720
Speaker 0: Вот здесь тонкий момент.

262
00:25:12,920 --> 00:25:21,560
Speaker 0: Сама проблематика творчества за последние 30 лет очень сильно в каком-то смысле деградировала и является очень своего рода такого, мне кажется, фейком.

263
00:25:21,720 --> 00:25:24,560
Speaker 0: А вот способность к настоящему генерацию новых идей.

264
00:25:24,840 --> 00:25:29,140
Speaker 0: она тоже достаточно сильно в мире позднего капитализма отвергалась.

265
00:25:29,320 --> 00:25:31,180
Speaker 0: А здесь внезапно она оказывается ценностью.

266
00:25:31,220 --> 00:25:33,840
Speaker 0: Поэтому читайте стихи, пишите стихи.

267
00:25:34,300 --> 00:25:40,560
Speaker 1: Занимайтесь самообразованием, прикасайтесь к классике, занимайтесь развитием себя, своей личности.

268
00:25:40,800 --> 00:25:44,040
Speaker 1: Таким образом вы станете способными на истинное творчество.

269
00:25:44,360 --> 00:25:54,240
Speaker 1: Шаблонное мышление может раздеть только шаблонные какие-то продукты, которые творчеству отнести будет нельзя и которые за вас нейросеть сделает тысячу раз быстрее.

270
00:25:54,460 --> 00:25:58,620
Speaker 0: к самообразованию, причём именно направленное на создание вот этой способности.

271
00:25:58,800 --> 00:26:07,420
Speaker 0: И здесь, к сожалению, без огромных волевых усилий не обойтись, потому что, повторюсь, это на 180 градусов разворот по сравнению с тем, что было вот всю нашу жизнь.

272
00:26:07,520 --> 00:26:08,540
Speaker 1: Так что серость вымрет?

273
00:26:08,800 --> 00:26:09,560
Speaker 1: Серость обречена?

274
00:26:09,960 --> 00:26:10,860
Speaker 0: Ну, не совсем.

275
00:26:10,940 --> 00:26:15,200
Speaker 0: Она обречена с точки зрения шансов на комфортную жизнь по-настоящему.

276
00:26:15,480 --> 00:26:20,500
Speaker 0: Но, с другой стороны, вполне возможно, что именно здесь будет подключена вот эта идея базового дохода.

277
00:26:20,820 --> 00:26:23,220
Speaker 0: Главное, вы потеряете право говорить что-либо.

278
00:26:23,300 --> 00:26:27,020
Speaker 0: мировой элите, потому что старый демократический контракт работал на чем?

279
00:26:27,220 --> 00:26:28,780
Speaker 0: То есть элите нужны были голоса.

280
00:26:29,100 --> 00:26:35,500
Speaker 0: Вы... имели право на эти голоса, потому что вы отвечали за кровь и движение экономики.

281
00:26:35,540 --> 00:26:38,620
Speaker 0: То есть, условно говоря, без этих рабочих реально не было бы экономики и действий.

282
00:26:38,800 --> 00:26:48,820
Speaker 0: Теперь вы потеряете возможность реально требовать, потому что в любой момент вам могут сказать, вы-то нам и так не нужны, то, что вы сейчас этой работой обладаете, исключительно плод нашего благого к вам отношения.

283
00:26:48,860 --> 00:26:49,940
Speaker 0: Вы еще и что-то требуете.

284
00:26:50,240 --> 00:26:58,240
Speaker 0: То есть, на самом деле, это вообще еще отдельная тема, но чат GPT убивает массовые демократии в том смысле, в каком они были последние 20-30 лет.

285
00:26:58,340 --> 00:27:04,740
Speaker 1: Что касается того, что нейросети захватят мир, починив себе электрические приборы.

286
00:27:04,960 --> 00:27:15,500
Speaker 1: Осознание того, о чём ты говоришь, что нейросети полностью изменят, вообще говоря, ландшафт жизни всей, и политической, и экономической, всей.

287
00:27:16,140 --> 00:27:18,320
Speaker 1: Этого почему-то пока никто не опасается.

288
00:27:18,700 --> 00:27:33,360
Speaker 0: Предсказание, которое я рискну делать, и с которым я практически более-менее уверен, что в будущем реальным голосом, то есть голос — это в данном случае способность реально влиять на принимаемое решение, будет пропорционально вашей творческой способности по генерации чего-то принципиального нового.

289
00:27:34,000 --> 00:27:37,440
Speaker 0: Вот такой мой философский прогноз на ближайшие 20 лет.

290
00:27:38,100 --> 00:27:39,440
Speaker 1: Я считаю его оптимистичным.

291
00:27:39,680 --> 00:27:48,980
Speaker 1: В какой-то степени даже испытываю торжество, потому что до сих пор приходилось объяснять, зачем людям знакомиться с творчеством Гомера или Шекспира.

292
00:27:49,580 --> 00:27:55,820
Speaker 1: Так получается, что те, кто не будет прилагать к этому усилий, останется за бортом и обречён прозябать.

293
00:27:56,560 --> 00:27:59,180
Speaker 0: Берегите себя, самообразуйтесь и до новых встреч.

294
00:27:59,220 --> 00:27:59,300
Speaker 0: Да.

295
00:28:01,160 --> 00:28:23,100
Speaker 1: А мы будем прилагать для этого все возможные усилия.

